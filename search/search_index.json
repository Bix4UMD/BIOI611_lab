{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BIOI611 lab Welcome to BIOI 611! I\u2019m excited to have you in this course, where we will delve into the fascinating world of transcriptomics and explore the intricacies of gene and transcript-level expression analysis. This course focuses on the analysis of transcriptomics data, and specifically on the analysis of gene and transcript-level expression. Material covered includes transcript and gene expression estimation from RNA-seq data (short and long-read), basic experimental design and statistical methods for differential expression analysis, discovery of novel transcripts via reference-guided and de novo assembly, and the analysis of single-cell gene expression data (e.g., single-cell expression quantification, dimensionality reduction, clustering, pseudotime analysis). Prerequisite: BIOI 604. Core.","title":"BIOI611 lab"},{"location":"#bioi611-lab","text":"Welcome to BIOI 611! I\u2019m excited to have you in this course, where we will delve into the fascinating world of transcriptomics and explore the intricacies of gene and transcript-level expression analysis. This course focuses on the analysis of transcriptomics data, and specifically on the analysis of gene and transcript-level expression. Material covered includes transcript and gene expression estimation from RNA-seq data (short and long-read), basic experimental design and statistical methods for differential expression analysis, discovery of novel transcripts via reference-guided and de novo assembly, and the analysis of single-cell gene expression data (e.g., single-cell expression quantification, dimensionality reduction, clustering, pseudotime analysis). Prerequisite: BIOI 604. Core.","title":"BIOI611 lab"},{"location":"BIOI611_DESeq2_analysis/","text":"Analysis of RNA-seq data using R Navigation in the file system and read the count files getwd() '/content' list.files() 'sample_data' # Define base URL and files to download base_url <- \"https://raw.githubusercontent.com/Bix4UMD/BIOI611_lab/refs/heads/main/data/bulkRNA_SE_tab/\" files <- c(\"N2_day1_rep1.ReadsPerGene.out.tab\", \"N2_day1_rep2.ReadsPerGene.out.tab\", \"N2_day1_rep3.ReadsPerGene.out.tab\", \"N2_day7_rep1.ReadsPerGene.out.tab\", \"N2_day7_rep2.ReadsPerGene.out.tab\", \"N2_day7_rep3.ReadsPerGene.out.tab\" ) # Download each file for (f in files) { download.file(paste0(base_url, f), destfile = f, method = \"libcurl\") } list.files() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1.ReadsPerGene.out.tab' 'N2_day1_rep2.ReadsPerGene.out.tab' 'N2_day1_rep3.ReadsPerGene.out.tab' 'N2_day7_rep1.ReadsPerGene.out.tab' 'N2_day7_rep2.ReadsPerGene.out.tab' 'N2_day7_rep3.ReadsPerGene.out.tab' 'sample_data' file_paths <- list.files(pattern = \"*.ReadsPerGene.out.tab\") file_paths .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1.ReadsPerGene.out.tab' 'N2_day1_rep2.ReadsPerGene.out.tab' 'N2_day1_rep3.ReadsPerGene.out.tab' 'N2_day7_rep1.ReadsPerGene.out.tab' 'N2_day7_rep2.ReadsPerGene.out.tab' 'N2_day7_rep3.ReadsPerGene.out.tab' # Function to read the STAR ReadsPerGene.out.tab file read_star_file <- function(file_path) { # Read the file df <- read.table(file_path, header = FALSE, stringsAsFactors = FALSE) # Keep only the first (gene) and second (unstranded counts) columns library(dplyr) df <- df %>% select(V1, V2) # Rename the columns for clarity (GeneID and counts for this sample) colnames(df) <- c(\"GeneID\", gsub(\".ReadsPerGene.out.tab\", \"\", basename(file_path))) return(df) } # Read all files into a list of data frames list_of_dfs <- lapply(file_paths, read_star_file) # Merge all data frames by the GeneID column merged_df <- Reduce(function(x, y) merge(x, y, by = \"GeneID\"), list_of_dfs) merged_df <- merged_df[-c(1:4), ] # Check the first few rows of the combined data frame head(merged_df) # Optionally, write the combined data frame to a CSV file write.csv(merged_df, \"combined_gene_counts.csv\", row.names = FALSE) Attaching package: \u2018dplyr\u2019 The following objects are masked from \u2018package:stats\u2019: filter, lag The following objects are masked from \u2018package:base\u2019: intersect, setdiff, setequal, union A data.frame: 6 \u00d7 7 GeneID N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <chr> <int> <int> <int> <int> <int> <int> 5 WBGene00000001 3227 2168 2589 5659 2619 5239 6 WBGene00000002 270 203 266 355 191 425 7 WBGene00000003 341 415 411 387 255 499 8 WBGene00000004 584 438 518 1028 541 888 9 WBGene00000005 383 395 483 119 65 189 10 WBGene00000006 343 344 334 206 114 220 class(list_of_dfs) 'list' head(list_of_dfs[[2]]) A data.frame: 6 \u00d7 2 GeneID N2_day1_rep2 <chr> <int> 1 N_unmapped 1400596 2 N_multimapping 1305129 3 N_noFeature 152183 4 N_ambiguous 439830 5 WBGene00000003 415 6 WBGene00000007 513 rownames(merged_df) = merged_df$GeneID head(merged_df) A data.frame: 6 \u00d7 7 GeneID N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <chr> <int> <int> <int> <int> <int> <int> WBGene00000001 WBGene00000001 3227 2168 2589 5659 2619 5239 WBGene00000002 WBGene00000002 270 203 266 355 191 425 WBGene00000003 WBGene00000003 341 415 411 387 255 499 WBGene00000004 WBGene00000004 584 438 518 1028 541 888 WBGene00000005 WBGene00000005 383 395 483 119 65 189 WBGene00000006 WBGene00000006 343 344 334 206 114 220 # NULL reserved word representing empty merged_df$GeneID = NULL head(merged_df) A data.frame: 6 \u00d7 6 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <int> <int> <int> <int> <int> <int> WBGene00000001 3227 2168 2589 5659 2619 5239 WBGene00000002 270 203 266 355 191 425 WBGene00000003 341 415 411 387 255 499 WBGene00000004 584 438 518 1028 541 888 WBGene00000005 383 395 483 119 65 189 WBGene00000006 343 344 334 206 114 220 subset_df4test <- merged_df[, c(\"N2_day1_rep1\", \"N2_day1_rep2\", \"N2_day1_rep3\")] head(subset_df4test) A data.frame: 6 \u00d7 3 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 <int> <int> <int> WBGene00000001 3227 2168 2589 WBGene00000002 270 203 266 WBGene00000003 341 415 411 WBGene00000004 584 438 518 WBGene00000005 383 395 483 WBGene00000006 343 344 334 Check count matrix Different samples have different total number of counts as.data.frame(colSums(merged_df)) A data.frame: 6 \u00d7 1 colSums(merged_df) <dbl> N2_day1_rep1 37398898 N2_day1_rep2 29488709 N2_day1_rep3 34593136 N2_day7_rep1 48275683 N2_day7_rep2 23204449 N2_day7_rep3 46005617 barplot(colSums(merged_df), las = 2, cex.names= 0.6) # inkscape: an open source software for editing the graph saved in pdf pdf(\"total_count_barplot.pdf\") barplot(colSums(merged_df), las = 2, cex.names= 0.6) dev.off() agg_record_854642287: 2 coldata <- colnames(merged_df) coldata_df <- cbind(group = gsub(\"_rep\\\\d\", \"\", coldata)) coldata_df A matrix: 6 \u00d7 1 of type chr group N2_day1 N2_day1 N2_day1 N2_day7 N2_day7 N2_day7 rownames(coldata_df) = coldata coldata_df A matrix: 6 \u00d7 1 of type chr group N2_day1_rep1 N2_day1 N2_day1_rep2 N2_day1 N2_day1_rep3 N2_day1 N2_day7_rep1 N2_day7 N2_day7_rep2 N2_day7 N2_day7_rep3 N2_day7 Instsall required R packages if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"DESeq2\") Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.22 (BiocManager 1.30.26), R 4.5.1 (2025-06-13) Installing package(s) 'BiocVersion', 'DESeq2' also installing the dependencies \u2018XVector\u2019, \u2018formatR\u2019, \u2018abind\u2019, \u2018SparseArray\u2019, \u2018lambda.r\u2019, \u2018futile.options\u2019, \u2018Seqinfo\u2019, \u2018S4Arrays\u2019, \u2018DelayedArray\u2019, \u2018futile.logger\u2019, \u2018snow\u2019, \u2018BH\u2019, \u2018S4Vectors\u2019, \u2018IRanges\u2019, \u2018GenomicRanges\u2019, \u2018SummarizedExperiment\u2019, \u2018BiocGenerics\u2019, \u2018Biobase\u2019, \u2018BiocParallel\u2019, \u2018matrixStats\u2019, \u2018locfit\u2019, \u2018MatrixGenerics\u2019, \u2018RcppArmadillo\u2019 Old packages: 'xfun' 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.22 (BiocManager 1.30.26), R 4.5.1 (2025-06-13) Installing package(s) 'EnhancedVolcano' Warning message: \u201cpackage \u2018EnhancedVolcano\u2019 is not available for Bioconductor version '3.22' A version of this package for your version of R might be available elsewhere, see the ideas at https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\u201d Old packages: 'xfun' if (!requireNamespace(\"remotes\", quietly = TRUE)) install.packages(\"remotes\") remotes::install_github(\"kevinblighe/EnhancedVolcano\") Downloading GitHub repo kevinblighe/EnhancedVolcano@HEAD ggrepel (NA -> 0.9.6) [CRAN] Installing 1 packages: ggrepel Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) \u001b[36m\u2500\u2500\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m * checking for file \u2018/tmp/RtmpDRoCry/remotes3121fb93b3/kevinblighe-EnhancedVolcano-ab0428e/DESCRIPTION\u2019 ... OK * preparing \u2018EnhancedVolcano\u2019: * checking DESCRIPTION meta-information ... OK * checking for LF line-endings in source and make files and shell scripts * checking for empty or unneeded directories * building \u2018EnhancedVolcano_1.13.2.tar.gz\u2019 Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) Load R packages library(DESeq2) library(EnhancedVolcano) Loading required package: ggplot2 Loading required package: ggrepel Run DESeq2 to identify DEG dds <- DESeqDataSetFromMatrix(countData = merged_df, colData = coldata_df, design =~ group) Warning message in DESeqDataSet(se, design = design, ignoreRank): \u201csome variables in design formula are characters, converting to factors\u201d class(dds) 'DESeqDataSet' The DESeq() function normalizes the read counts,estimates dispersions, and fits the linear model, all in one go. dds <- DESeq(dds) estimating size factors estimating dispersions gene-wise dispersion estimates mean-dispersion relationship final dispersion estimates fitting model and testing Dispersion is a measure of spread or variability in the data. Variance, standard deviation, IQR, among other measures, can all be used to measure dispersion. DESeq2 uses a specific measure of dispersion (\u03b1) related to the mean (\u03bc) and variance of the data: Var = \u03bc + \u03b1*\u03bc^2. sizeFactors(dds) .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} N2_day1_rep1 1.00236113145741 N2_day1_rep2 0.810736816029527 N2_day1_rep3 0.944781672438598 N2_day7_rep1 1.31189917666838 N2_day7_rep2 0.71546097217711 N2_day7_rep3 1.42600915363567 head(counts(dds, normalized = TRUE)) A matrix: 6 \u00d7 6 of type dbl N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 WBGene00000001 3219.3986 2674.1107 2740.3156 4313.59368 3660.57703 3673.8895 WBGene00000002 269.3640 250.3895 281.5465 270.60006 266.96075 298.0346 WBGene00000003 340.1968 511.8800 435.0211 294.99218 356.41357 349.9276 WBGene00000004 582.6243 540.2493 548.2748 783.59680 756.15585 622.7169 WBGene00000005 382.0978 487.2111 511.2292 90.70819 90.85052 132.5377 WBGene00000006 342.1920 424.3054 353.5208 157.02426 159.33783 154.2767 The function plotDispEsts shows the dispersion by mean of normalized counts. We expect the dispersion to decrease as the mean of normalized counts increases. The functions shows: black per-gene dispersion estimates a red trend line representing the global relationship between dispersion and normalized count blue 'shrunken' values moderating individual dispersion estimates by the global relationship blue-circled dispersion outliers with high gene-wise dispersion that were not adjusted. plotDispEsts(dds) Plot normalized genes The function plotCounts is used to plot normalized counts plus a pseudocount of 0.5 by default. vsd <- vst(dds, blind=FALSE) class(vsd) 'DESeqTransform' plotPCA(vsd, intgroup = c(\"group\")) using ntop=500 top features by variance Extract DEG results using results function res <- results(dds) res log2 fold change (MLE): group N2 day7 vs N2 day1 Wald test p-value: group N2 day7 vs N2 day1 DataFrame with 46926 rows and 6 columns baseMean log2FoldChange lfcSE stat pvalue <numeric> <numeric> <numeric> <numeric> <numeric> WBGene00000001 3380.314 0.4320800 0.136502 3.165370 1.54886e-03 WBGene00000002 272.816 0.0620929 0.165747 0.374626 7.07939e-01 WBGene00000003 381.405 -0.3623262 0.199673 -1.814594 6.95864e-02 WBGene00000004 638.936 0.3698102 0.151232 2.445312 1.44727e-02 WBGene00000005 282.439 -2.1244976 0.227771 -9.327337 1.08564e-20 ... ... ... ... ... ... WBGene00306078 0.566369 0.947326 3.076775 0.307896 7.58162e-01 WBGene00306080 0.243919 1.429602 4.042905 0.353608 7.23633e-01 WBGene00306081 27.265033 -3.108820 0.627823 -4.951747 7.35501e-07 WBGene00306121 14.219195 -0.210100 0.691162 -0.303981 7.61142e-01 WBGene00306122 0.000000 NA NA NA NA padj <numeric> WBGene00000001 4.06703e-03 WBGene00000002 7.84660e-01 WBGene00000003 1.17161e-01 WBGene00000004 2.96896e-02 WBGene00000005 1.92160e-19 ... ... WBGene00306078 NA WBGene00306080 NA WBGene00306081 3.70005e-06 WBGene00306121 8.26621e-01 WBGene00306122 NA class(res) 'DESeqResults' mcols(res)$description .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'mean of normalized counts for all samples' 'log2 fold change (MLE): group N2 day7 vs N2 day1' 'standard error: group N2 day7 vs N2 day1' 'Wald statistic: group N2 day7 vs N2 day1' 'Wald test p-value: group N2 day7 vs N2 day1' 'BH adjusted p-values' baseMean : mean of normalized counts for all samples log2FoldChange : log2 fold change lfcSE : standard error stat : Wald statistic pvalue : Wald test p-value padj : BH adjusted p-values If we used the p-value directly from the Wald test with a significance cut-off of p < 0.05, that means there is a 5% chance it is a false positives. Each p-value is the result of a single test (single gene). The more genes we test, the more we inflate the false positive rate. This is the multiple testing problem. For example, if we test 20,000 genes for differential expression, at p < 0.05 we would expect to find 1,000 genes by chance. If we found 3000 genes to be differentially expressed total, roughly one third of our genes are false positives. We would not want to sift through our \u201csignificant\u201d genes to identify which ones are true positives. DESeq2 helps reduce the number of genes tested by removing those genes unlikely to be significantly DE prior to testing, such as those with low number of counts and outlier samples (gene-level QC). However, we still need to correct for multiple testing to reduce the number of false positives, and there are a few common approaches: Bonferroni: The adjusted p-value is calculated by: p-value * m (m = total number of tests). This is a very conservative approach with a high probability of false negatives, so is generally not recommended. FDR/Benjamini-Hochberg: Benjamini and Hochberg (1995) defined the concept of FDR and created an algorithm to control the expected FDR below a specified level given a list of independent p-values. An interpretation of the BH method for controlling the FDR is implemented in DESeq2 in which we rank the genes by p-value, then multiply each ranked p-value by m/rank. Q-value / Storey method: The minimum FDR that can be attained when calling that feature significant. For example, if gene X has a q-value of 0.013 it means that 1.3% of genes that show p-values at least as small as gene X are false positives In DESeq2, the p-values attained by the Wald test are corrected for multiple testing using the Benjamini and Hochberg method by default. There are options to use other methods in the results() function. The p-adjusted values should be used to determine significant genes. The significant genes can be output for visualization and/or functional analysis. So what does FDR < 0.05 mean? By setting the FDR cutoff to < 0.05, we\u2019re saying that the proportion of false positives we expect amongst our differentially expressed genes is 5%. For example, if you call 500 genes as differentially expressed with an FDR cutoff of 0.05, you expect 25 of them to be false positives. Note on p-values set to NA : some values in the results table can be set to NA for one of the following reasons: If within a row, all samples have zero counts, the baseMean column will be zero, and the log2 fold change estimates, p value and adjusted p value will all be set to NA. If a row contains a sample with an extreme count outlier then the p value and adjusted p value will be set to NA. These outlier counts are detected by Cook\u2019s distance. Customization of this outlier filtering and description of functionality for replacement of outlier counts and refitting is described below If a row is filtered by automatic independent filtering, for having a low mean normalized count, then only the adjusted p value will be set to NA. Description and customization of independent filtering is described below plotMA(res, ylim=c(-2,2)) write.csv(res, file = \"BIOI_bulkRNAseq_SE_DESeq2_res.csv\") d <- plotCounts(dds, gene=which.min(res$padj), intgroup=\"group\", returnData=TRUE) d A data.frame: 6 \u00d7 2 count group <dbl> <fct> N2_day1_rep1 37716.448 N2_day1 N2_day1_rep2 46554.449 N2_day1 N2_day1_rep3 45402.524 N2_day1 N2_day7_rep1 1544.064 N2_day7 N2_day7_rep2 1564.527 N2_day7 N2_day7_rep3 1489.270 N2_day7 which.min(res$padj) 465 library(\"ggplot2\") ggplot(d, aes(x=group, y=count)) + geom_point(position=position_jitter(w=0.1,h=0)) + scale_y_log10(breaks=c(25,100,400)) EnhancedVolcano(res, lab = rownames(res), x = 'log2FoldChange', y = 'pvalue') Warning message: \u201c\u001b[1m\u001b[22mUsing `size` aesthetic for lines was deprecated in ggplot2 3.4.0. \u001b[36m\u2139\u001b[39m Please use `linewidth` instead. \u001b[36m\u2139\u001b[39m The deprecated feature was likely used in the \u001b[34mEnhancedVolcano\u001b[39m package. Please report the issue to the authors.\u201d Warning message: \u201c\u001b[1m\u001b[22mThe `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0. \u001b[36m\u2139\u001b[39m Please use the `linewidth` argument instead. \u001b[36m\u2139\u001b[39m The deprecated feature was likely used in the \u001b[34mEnhancedVolcano\u001b[39m package. Please report the issue to the authors.\u201d Understand normalized count in DESeq2 (Optional) Create a pseudo-reference sample (row-wise geometric mean) The code below creates a new column called pseudo_reference that contains the average log-transformed expression value for each gene across all samples. This pseudo-reference is similar to calculating a \"reference sample\" to compare other samples. log_data = log(merged_df) head(log_data) A data.frame: 6 \u00d7 6 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> WBGene00000001 8.079308 7.681560 7.859027 8.641002 7.870548 8.563886 WBGene00000002 5.598422 5.313206 5.583496 5.872118 5.252273 6.052089 WBGene00000003 5.831882 6.028279 6.018593 5.958425 5.541264 6.212606 WBGene00000004 6.369901 6.082219 6.249975 6.935370 6.293419 6.788972 WBGene00000005 5.948035 5.978886 6.180017 4.779123 4.174387 5.241747 WBGene00000006 5.837730 5.840642 5.811141 5.327876 4.736198 5.393628 library(dplyr) library(tibble) # rownames_to_column log_data = log_data %>% rownames_to_column('gene') %>% mutate (pseudo_reference = rowMeans(log_data)) head(log_data) A data.frame: 6 \u00d7 8 gene N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 pseudo_reference <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> 1 WBGene00000001 8.079308 7.681560 7.859027 8.641002 7.870548 8.563886 8.115889 2 WBGene00000002 5.598422 5.313206 5.583496 5.872118 5.252273 6.052089 5.611934 3 WBGene00000003 5.831882 6.028279 6.018593 5.958425 5.541264 6.212606 5.931841 4 WBGene00000004 6.369901 6.082219 6.249975 6.935370 6.293419 6.788972 6.453309 5 WBGene00000005 5.948035 5.978886 6.180017 4.779123 4.174387 5.241747 5.383699 6 WBGene00000006 5.837730 5.840642 5.811141 5.327876 4.736198 5.393628 5.491203 table(log_data$pseudo_reference == \"-Inf\") FALSE TRUE 16951 29975 filtered_log_data = log_data %>% filter(pseudo_reference != \"-Inf\") head(filtered_log_data) A data.frame: 6 \u00d7 8 gene N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 pseudo_reference <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> 1 WBGene00000001 8.079308 7.681560 7.859027 8.641002 7.870548 8.563886 8.115889 2 WBGene00000002 5.598422 5.313206 5.583496 5.872118 5.252273 6.052089 5.611934 3 WBGene00000003 5.831882 6.028279 6.018593 5.958425 5.541264 6.212606 5.931841 4 WBGene00000004 6.369901 6.082219 6.249975 6.935370 6.293419 6.788972 6.453309 5 WBGene00000005 5.948035 5.978886 6.180017 4.779123 4.174387 5.241747 5.383699 6 WBGene00000006 5.837730 5.840642 5.811141 5.327876 4.736198 5.393628 5.491203 filtered_log_data$pseudo_reference = exp(filtered_log_data$pseudo_reference) head(filtered_log_data) A data.frame: 6 \u00d7 8 gene N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 pseudo_reference <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> 1 WBGene00000001 8.079308 7.681560 7.859027 8.641002 7.870548 8.563886 3347.2307 2 WBGene00000002 5.598422 5.313206 5.583496 5.872118 5.252273 6.052089 273.6730 3 WBGene00000003 5.831882 6.028279 6.018593 5.958425 5.541264 6.212606 376.8478 4 WBGene00000004 6.369901 6.082219 6.249975 6.935370 6.293419 6.788972 634.7996 5 WBGene00000005 5.948035 5.978886 6.180017 4.779123 4.174387 5.241747 217.8266 6 WBGene00000006 5.837730 5.840642 5.811141 5.327876 4.736198 5.393628 242.5487 dim(log_data) dim(filtered_log_data) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 46926 8 .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 16951 8 Calculate ratio between each sample and the pseudo-reference for each gene This step calculates the fold change between each sample and the pseudo-reference for each gene. ratio_data = sweep(exp(filtered_log_data[,2:7]), 1, filtered_log_data[,8], \"/\") head(ratio_data) A data.frame: 6 \u00d7 6 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> 1 0.9640805 0.6476996 0.7734752 1.6906513 0.7824378 1.5651745 2 0.9865787 0.7417610 0.9719628 1.2971683 0.6979131 1.5529480 3 0.9048746 1.1012403 1.0906259 1.0269398 0.6766657 1.3241420 4 0.9199753 0.6899815 0.8160055 1.6194086 0.8522374 1.3988666 5 1.7582795 1.8133692 2.2173603 0.5463062 0.2984025 0.8676627 6 1.4141490 1.4182718 1.3770430 0.8493139 0.4700087 0.9070343 Calculate scaling factor The code below computes the median fold change for each sample across all genes. scaling_factors = apply(ratio_data, 2, median, na.rm = TRUE) scaling_factors .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} N2_day1_rep1 1.00236113145741 N2_day1_rep2 0.810736816029527 N2_day1_rep3 0.944781672438598 N2_day7_rep1 1.31189917666838 N2_day7_rep2 0.71546097217711 N2_day7_rep3 1.42600915363567 The 2 indicates that the function is applied to columns, i.e., for each sample. Normalize the counts This step below normalizes each sample by its scaling factors, making the data comparable across samples. The result is a normalized gene expression matrix. manually_normalized = sweep(merged_df, 2, scaling_factors, \"/\") head(manually_normalized) A data.frame: 6 \u00d7 6 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> WBGene00000001 3219.3986 2674.1107 2740.3156 4313.59368 3660.57703 3673.8895 WBGene00000002 269.3640 250.3895 281.5465 270.60006 266.96075 298.0346 WBGene00000003 340.1968 511.8800 435.0211 294.99218 356.41357 349.9276 WBGene00000004 582.6243 540.2493 548.2748 783.59680 756.15585 622.7169 WBGene00000005 382.0978 487.2111 511.2292 90.70819 90.85052 132.5377 WBGene00000006 342.1920 424.3054 353.5208 157.02426 159.33783 154.2767 hist(manually_normalized$N2_day1_rep1) The code below shows that the size factors and the normalized read counts calculated by ourselves are the same as what DESeq2 function returns. head(counts(dds, normalized = TRUE)) A matrix: 6 \u00d7 6 of type dbl N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 WBGene00000001 3219.3986 2674.1107 2740.3156 4313.59368 3660.57703 3673.8895 WBGene00000002 269.3640 250.3895 281.5465 270.60006 266.96075 298.0346 WBGene00000003 340.1968 511.8800 435.0211 294.99218 356.41357 349.9276 WBGene00000004 582.6243 540.2493 548.2748 783.59680 756.15585 622.7169 WBGene00000005 382.0978 487.2111 511.2292 90.70819 90.85052 132.5377 WBGene00000006 342.1920 424.3054 353.5208 157.02426 159.33783 154.2767 sizeFactors(dds) .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} N2_day1_rep1 1.00236113145741 N2_day1_rep2 0.810736816029527 N2_day1_rep3 0.944781672438598 N2_day7_rep1 1.31189917666838 N2_day7_rep2 0.71546097217711 N2_day7_rep3 1.42600915363567 SessionInfo sessionInfo() R version 4.5.1 (2025-06-13) Platform: x86_64-pc-linux-gnu Running under: Ubuntu 22.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so; LAPACK version 3.10.0 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C time zone: Etc/UTC tzcode source: system (glibc) attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] tibble_3.3.0 EnhancedVolcano_1.13.2 [3] ggrepel_0.9.6 ggplot2_4.0.0 [5] DESeq2_1.50.0 SummarizedExperiment_1.40.0 [7] Biobase_2.70.0 MatrixGenerics_1.22.0 [9] matrixStats_1.5.0 GenomicRanges_1.62.0 [11] Seqinfo_1.0.0 IRanges_2.44.0 [13] S4Vectors_0.48.0 BiocGenerics_0.56.0 [15] generics_0.1.4 dplyr_1.1.4 loaded via a namespace (and not attached): [1] gtable_0.3.6 remotes_2.5.0 processx_3.8.6 [4] lattice_0.22-7 callr_3.7.6 vctrs_0.6.5 [7] tools_4.5.1 ps_1.9.1 curl_7.0.0 [10] parallel_4.5.1 pkgconfig_2.0.3 Matrix_1.7-4 [13] RColorBrewer_1.1-3 S7_0.2.0 desc_1.4.3 [16] uuid_1.2-1 lifecycle_1.0.4 compiler_4.5.1 [19] farver_2.1.2 textshaping_1.0.4 repr_1.1.7 [22] codetools_0.2-20 htmltools_0.5.8.1 pillar_1.11.1 [25] crayon_1.5.3 BiocParallel_1.44.0 DelayedArray_0.36.0 [28] abind_1.4-8 tidyselect_1.2.1 locfit_1.5-9.12 [31] digest_0.6.37 labeling_0.4.3 fastmap_1.2.0 [34] grid_4.5.1 cli_3.6.5 SparseArray_1.10.0 [37] magrittr_2.0.4 S4Arrays_1.10.0 base64enc_0.1-3 [40] pkgbuild_1.4.8 IRdisplay_1.1 withr_3.0.2 [43] scales_1.4.0 IRkernel_1.3.2 XVector_0.50.0 [46] pbdZMQ_0.3-14 ragg_1.5.0 evaluate_1.0.5 [49] rlang_1.1.6 Rcpp_1.1.0 glue_1.8.0 [52] BiocManager_1.30.26 jsonlite_2.0.0 R6_2.6.1 [55] systemfonts_1.3.1","title":"DEG analysis using DESeq2"},{"location":"BIOI611_DESeq2_analysis/#analysis-of-rna-seq-data-using-r","text":"","title":"Analysis of RNA-seq data using R"},{"location":"BIOI611_DESeq2_analysis/#navigation-in-the-file-system-and-read-the-count-files","text":"getwd() '/content' list.files() 'sample_data' # Define base URL and files to download base_url <- \"https://raw.githubusercontent.com/Bix4UMD/BIOI611_lab/refs/heads/main/data/bulkRNA_SE_tab/\" files <- c(\"N2_day1_rep1.ReadsPerGene.out.tab\", \"N2_day1_rep2.ReadsPerGene.out.tab\", \"N2_day1_rep3.ReadsPerGene.out.tab\", \"N2_day7_rep1.ReadsPerGene.out.tab\", \"N2_day7_rep2.ReadsPerGene.out.tab\", \"N2_day7_rep3.ReadsPerGene.out.tab\" ) # Download each file for (f in files) { download.file(paste0(base_url, f), destfile = f, method = \"libcurl\") } list.files() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1.ReadsPerGene.out.tab' 'N2_day1_rep2.ReadsPerGene.out.tab' 'N2_day1_rep3.ReadsPerGene.out.tab' 'N2_day7_rep1.ReadsPerGene.out.tab' 'N2_day7_rep2.ReadsPerGene.out.tab' 'N2_day7_rep3.ReadsPerGene.out.tab' 'sample_data' file_paths <- list.files(pattern = \"*.ReadsPerGene.out.tab\") file_paths .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1.ReadsPerGene.out.tab' 'N2_day1_rep2.ReadsPerGene.out.tab' 'N2_day1_rep3.ReadsPerGene.out.tab' 'N2_day7_rep1.ReadsPerGene.out.tab' 'N2_day7_rep2.ReadsPerGene.out.tab' 'N2_day7_rep3.ReadsPerGene.out.tab' # Function to read the STAR ReadsPerGene.out.tab file read_star_file <- function(file_path) { # Read the file df <- read.table(file_path, header = FALSE, stringsAsFactors = FALSE) # Keep only the first (gene) and second (unstranded counts) columns library(dplyr) df <- df %>% select(V1, V2) # Rename the columns for clarity (GeneID and counts for this sample) colnames(df) <- c(\"GeneID\", gsub(\".ReadsPerGene.out.tab\", \"\", basename(file_path))) return(df) } # Read all files into a list of data frames list_of_dfs <- lapply(file_paths, read_star_file) # Merge all data frames by the GeneID column merged_df <- Reduce(function(x, y) merge(x, y, by = \"GeneID\"), list_of_dfs) merged_df <- merged_df[-c(1:4), ] # Check the first few rows of the combined data frame head(merged_df) # Optionally, write the combined data frame to a CSV file write.csv(merged_df, \"combined_gene_counts.csv\", row.names = FALSE) Attaching package: \u2018dplyr\u2019 The following objects are masked from \u2018package:stats\u2019: filter, lag The following objects are masked from \u2018package:base\u2019: intersect, setdiff, setequal, union A data.frame: 6 \u00d7 7 GeneID N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <chr> <int> <int> <int> <int> <int> <int> 5 WBGene00000001 3227 2168 2589 5659 2619 5239 6 WBGene00000002 270 203 266 355 191 425 7 WBGene00000003 341 415 411 387 255 499 8 WBGene00000004 584 438 518 1028 541 888 9 WBGene00000005 383 395 483 119 65 189 10 WBGene00000006 343 344 334 206 114 220 class(list_of_dfs) 'list' head(list_of_dfs[[2]]) A data.frame: 6 \u00d7 2 GeneID N2_day1_rep2 <chr> <int> 1 N_unmapped 1400596 2 N_multimapping 1305129 3 N_noFeature 152183 4 N_ambiguous 439830 5 WBGene00000003 415 6 WBGene00000007 513 rownames(merged_df) = merged_df$GeneID head(merged_df) A data.frame: 6 \u00d7 7 GeneID N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <chr> <int> <int> <int> <int> <int> <int> WBGene00000001 WBGene00000001 3227 2168 2589 5659 2619 5239 WBGene00000002 WBGene00000002 270 203 266 355 191 425 WBGene00000003 WBGene00000003 341 415 411 387 255 499 WBGene00000004 WBGene00000004 584 438 518 1028 541 888 WBGene00000005 WBGene00000005 383 395 483 119 65 189 WBGene00000006 WBGene00000006 343 344 334 206 114 220 # NULL reserved word representing empty merged_df$GeneID = NULL head(merged_df) A data.frame: 6 \u00d7 6 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <int> <int> <int> <int> <int> <int> WBGene00000001 3227 2168 2589 5659 2619 5239 WBGene00000002 270 203 266 355 191 425 WBGene00000003 341 415 411 387 255 499 WBGene00000004 584 438 518 1028 541 888 WBGene00000005 383 395 483 119 65 189 WBGene00000006 343 344 334 206 114 220 subset_df4test <- merged_df[, c(\"N2_day1_rep1\", \"N2_day1_rep2\", \"N2_day1_rep3\")] head(subset_df4test) A data.frame: 6 \u00d7 3 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 <int> <int> <int> WBGene00000001 3227 2168 2589 WBGene00000002 270 203 266 WBGene00000003 341 415 411 WBGene00000004 584 438 518 WBGene00000005 383 395 483 WBGene00000006 343 344 334","title":"Navigation in the file system and read the count files"},{"location":"BIOI611_DESeq2_analysis/#check-count-matrix","text":"Different samples have different total number of counts as.data.frame(colSums(merged_df)) A data.frame: 6 \u00d7 1 colSums(merged_df) <dbl> N2_day1_rep1 37398898 N2_day1_rep2 29488709 N2_day1_rep3 34593136 N2_day7_rep1 48275683 N2_day7_rep2 23204449 N2_day7_rep3 46005617 barplot(colSums(merged_df), las = 2, cex.names= 0.6) # inkscape: an open source software for editing the graph saved in pdf pdf(\"total_count_barplot.pdf\") barplot(colSums(merged_df), las = 2, cex.names= 0.6) dev.off() agg_record_854642287: 2 coldata <- colnames(merged_df) coldata_df <- cbind(group = gsub(\"_rep\\\\d\", \"\", coldata)) coldata_df A matrix: 6 \u00d7 1 of type chr group N2_day1 N2_day1 N2_day1 N2_day7 N2_day7 N2_day7 rownames(coldata_df) = coldata coldata_df A matrix: 6 \u00d7 1 of type chr group N2_day1_rep1 N2_day1 N2_day1_rep2 N2_day1 N2_day1_rep3 N2_day1 N2_day7_rep1 N2_day7 N2_day7_rep2 N2_day7 N2_day7_rep3 N2_day7","title":"Check count matrix"},{"location":"BIOI611_DESeq2_analysis/#instsall-required-r-packages","text":"if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"DESeq2\") Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.22 (BiocManager 1.30.26), R 4.5.1 (2025-06-13) Installing package(s) 'BiocVersion', 'DESeq2' also installing the dependencies \u2018XVector\u2019, \u2018formatR\u2019, \u2018abind\u2019, \u2018SparseArray\u2019, \u2018lambda.r\u2019, \u2018futile.options\u2019, \u2018Seqinfo\u2019, \u2018S4Arrays\u2019, \u2018DelayedArray\u2019, \u2018futile.logger\u2019, \u2018snow\u2019, \u2018BH\u2019, \u2018S4Vectors\u2019, \u2018IRanges\u2019, \u2018GenomicRanges\u2019, \u2018SummarizedExperiment\u2019, \u2018BiocGenerics\u2019, \u2018Biobase\u2019, \u2018BiocParallel\u2019, \u2018matrixStats\u2019, \u2018locfit\u2019, \u2018MatrixGenerics\u2019, \u2018RcppArmadillo\u2019 Old packages: 'xfun' 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.22 (BiocManager 1.30.26), R 4.5.1 (2025-06-13) Installing package(s) 'EnhancedVolcano' Warning message: \u201cpackage \u2018EnhancedVolcano\u2019 is not available for Bioconductor version '3.22' A version of this package for your version of R might be available elsewhere, see the ideas at https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\u201d Old packages: 'xfun' if (!requireNamespace(\"remotes\", quietly = TRUE)) install.packages(\"remotes\") remotes::install_github(\"kevinblighe/EnhancedVolcano\") Downloading GitHub repo kevinblighe/EnhancedVolcano@HEAD ggrepel (NA -> 0.9.6) [CRAN] Installing 1 packages: ggrepel Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) \u001b[36m\u2500\u2500\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m * checking for file \u2018/tmp/RtmpDRoCry/remotes3121fb93b3/kevinblighe-EnhancedVolcano-ab0428e/DESCRIPTION\u2019 ... OK * preparing \u2018EnhancedVolcano\u2019: * checking DESCRIPTION meta-information ... OK * checking for LF line-endings in source and make files and shell scripts * checking for empty or unneeded directories * building \u2018EnhancedVolcano_1.13.2.tar.gz\u2019 Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified)","title":"Instsall required R packages"},{"location":"BIOI611_DESeq2_analysis/#load-r-packages","text":"library(DESeq2) library(EnhancedVolcano) Loading required package: ggplot2 Loading required package: ggrepel","title":"Load R packages"},{"location":"BIOI611_DESeq2_analysis/#run-deseq2-to-identify-deg","text":"dds <- DESeqDataSetFromMatrix(countData = merged_df, colData = coldata_df, design =~ group) Warning message in DESeqDataSet(se, design = design, ignoreRank): \u201csome variables in design formula are characters, converting to factors\u201d class(dds) 'DESeqDataSet' The DESeq() function normalizes the read counts,estimates dispersions, and fits the linear model, all in one go. dds <- DESeq(dds) estimating size factors estimating dispersions gene-wise dispersion estimates mean-dispersion relationship final dispersion estimates fitting model and testing Dispersion is a measure of spread or variability in the data. Variance, standard deviation, IQR, among other measures, can all be used to measure dispersion. DESeq2 uses a specific measure of dispersion (\u03b1) related to the mean (\u03bc) and variance of the data: Var = \u03bc + \u03b1*\u03bc^2. sizeFactors(dds) .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} N2_day1_rep1 1.00236113145741 N2_day1_rep2 0.810736816029527 N2_day1_rep3 0.944781672438598 N2_day7_rep1 1.31189917666838 N2_day7_rep2 0.71546097217711 N2_day7_rep3 1.42600915363567 head(counts(dds, normalized = TRUE)) A matrix: 6 \u00d7 6 of type dbl N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 WBGene00000001 3219.3986 2674.1107 2740.3156 4313.59368 3660.57703 3673.8895 WBGene00000002 269.3640 250.3895 281.5465 270.60006 266.96075 298.0346 WBGene00000003 340.1968 511.8800 435.0211 294.99218 356.41357 349.9276 WBGene00000004 582.6243 540.2493 548.2748 783.59680 756.15585 622.7169 WBGene00000005 382.0978 487.2111 511.2292 90.70819 90.85052 132.5377 WBGene00000006 342.1920 424.3054 353.5208 157.02426 159.33783 154.2767 The function plotDispEsts shows the dispersion by mean of normalized counts. We expect the dispersion to decrease as the mean of normalized counts increases. The functions shows: black per-gene dispersion estimates a red trend line representing the global relationship between dispersion and normalized count blue 'shrunken' values moderating individual dispersion estimates by the global relationship blue-circled dispersion outliers with high gene-wise dispersion that were not adjusted. plotDispEsts(dds)","title":"Run DESeq2 to identify DEG"},{"location":"BIOI611_DESeq2_analysis/#plot-normalized-genes","text":"The function plotCounts is used to plot normalized counts plus a pseudocount of 0.5 by default. vsd <- vst(dds, blind=FALSE) class(vsd) 'DESeqTransform' plotPCA(vsd, intgroup = c(\"group\")) using ntop=500 top features by variance","title":"Plot normalized genes"},{"location":"BIOI611_DESeq2_analysis/#extract-deg-results-using-results-function","text":"res <- results(dds) res log2 fold change (MLE): group N2 day7 vs N2 day1 Wald test p-value: group N2 day7 vs N2 day1 DataFrame with 46926 rows and 6 columns baseMean log2FoldChange lfcSE stat pvalue <numeric> <numeric> <numeric> <numeric> <numeric> WBGene00000001 3380.314 0.4320800 0.136502 3.165370 1.54886e-03 WBGene00000002 272.816 0.0620929 0.165747 0.374626 7.07939e-01 WBGene00000003 381.405 -0.3623262 0.199673 -1.814594 6.95864e-02 WBGene00000004 638.936 0.3698102 0.151232 2.445312 1.44727e-02 WBGene00000005 282.439 -2.1244976 0.227771 -9.327337 1.08564e-20 ... ... ... ... ... ... WBGene00306078 0.566369 0.947326 3.076775 0.307896 7.58162e-01 WBGene00306080 0.243919 1.429602 4.042905 0.353608 7.23633e-01 WBGene00306081 27.265033 -3.108820 0.627823 -4.951747 7.35501e-07 WBGene00306121 14.219195 -0.210100 0.691162 -0.303981 7.61142e-01 WBGene00306122 0.000000 NA NA NA NA padj <numeric> WBGene00000001 4.06703e-03 WBGene00000002 7.84660e-01 WBGene00000003 1.17161e-01 WBGene00000004 2.96896e-02 WBGene00000005 1.92160e-19 ... ... WBGene00306078 NA WBGene00306080 NA WBGene00306081 3.70005e-06 WBGene00306121 8.26621e-01 WBGene00306122 NA class(res) 'DESeqResults' mcols(res)$description .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'mean of normalized counts for all samples' 'log2 fold change (MLE): group N2 day7 vs N2 day1' 'standard error: group N2 day7 vs N2 day1' 'Wald statistic: group N2 day7 vs N2 day1' 'Wald test p-value: group N2 day7 vs N2 day1' 'BH adjusted p-values' baseMean : mean of normalized counts for all samples log2FoldChange : log2 fold change lfcSE : standard error stat : Wald statistic pvalue : Wald test p-value padj : BH adjusted p-values If we used the p-value directly from the Wald test with a significance cut-off of p < 0.05, that means there is a 5% chance it is a false positives. Each p-value is the result of a single test (single gene). The more genes we test, the more we inflate the false positive rate. This is the multiple testing problem. For example, if we test 20,000 genes for differential expression, at p < 0.05 we would expect to find 1,000 genes by chance. If we found 3000 genes to be differentially expressed total, roughly one third of our genes are false positives. We would not want to sift through our \u201csignificant\u201d genes to identify which ones are true positives. DESeq2 helps reduce the number of genes tested by removing those genes unlikely to be significantly DE prior to testing, such as those with low number of counts and outlier samples (gene-level QC). However, we still need to correct for multiple testing to reduce the number of false positives, and there are a few common approaches: Bonferroni: The adjusted p-value is calculated by: p-value * m (m = total number of tests). This is a very conservative approach with a high probability of false negatives, so is generally not recommended. FDR/Benjamini-Hochberg: Benjamini and Hochberg (1995) defined the concept of FDR and created an algorithm to control the expected FDR below a specified level given a list of independent p-values. An interpretation of the BH method for controlling the FDR is implemented in DESeq2 in which we rank the genes by p-value, then multiply each ranked p-value by m/rank. Q-value / Storey method: The minimum FDR that can be attained when calling that feature significant. For example, if gene X has a q-value of 0.013 it means that 1.3% of genes that show p-values at least as small as gene X are false positives In DESeq2, the p-values attained by the Wald test are corrected for multiple testing using the Benjamini and Hochberg method by default. There are options to use other methods in the results() function. The p-adjusted values should be used to determine significant genes. The significant genes can be output for visualization and/or functional analysis. So what does FDR < 0.05 mean? By setting the FDR cutoff to < 0.05, we\u2019re saying that the proportion of false positives we expect amongst our differentially expressed genes is 5%. For example, if you call 500 genes as differentially expressed with an FDR cutoff of 0.05, you expect 25 of them to be false positives. Note on p-values set to NA : some values in the results table can be set to NA for one of the following reasons: If within a row, all samples have zero counts, the baseMean column will be zero, and the log2 fold change estimates, p value and adjusted p value will all be set to NA. If a row contains a sample with an extreme count outlier then the p value and adjusted p value will be set to NA. These outlier counts are detected by Cook\u2019s distance. Customization of this outlier filtering and description of functionality for replacement of outlier counts and refitting is described below If a row is filtered by automatic independent filtering, for having a low mean normalized count, then only the adjusted p value will be set to NA. Description and customization of independent filtering is described below plotMA(res, ylim=c(-2,2)) write.csv(res, file = \"BIOI_bulkRNAseq_SE_DESeq2_res.csv\") d <- plotCounts(dds, gene=which.min(res$padj), intgroup=\"group\", returnData=TRUE) d A data.frame: 6 \u00d7 2 count group <dbl> <fct> N2_day1_rep1 37716.448 N2_day1 N2_day1_rep2 46554.449 N2_day1 N2_day1_rep3 45402.524 N2_day1 N2_day7_rep1 1544.064 N2_day7 N2_day7_rep2 1564.527 N2_day7 N2_day7_rep3 1489.270 N2_day7 which.min(res$padj) 465 library(\"ggplot2\") ggplot(d, aes(x=group, y=count)) + geom_point(position=position_jitter(w=0.1,h=0)) + scale_y_log10(breaks=c(25,100,400)) EnhancedVolcano(res, lab = rownames(res), x = 'log2FoldChange', y = 'pvalue') Warning message: \u201c\u001b[1m\u001b[22mUsing `size` aesthetic for lines was deprecated in ggplot2 3.4.0. \u001b[36m\u2139\u001b[39m Please use `linewidth` instead. \u001b[36m\u2139\u001b[39m The deprecated feature was likely used in the \u001b[34mEnhancedVolcano\u001b[39m package. Please report the issue to the authors.\u201d Warning message: \u201c\u001b[1m\u001b[22mThe `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0. \u001b[36m\u2139\u001b[39m Please use the `linewidth` argument instead. \u001b[36m\u2139\u001b[39m The deprecated feature was likely used in the \u001b[34mEnhancedVolcano\u001b[39m package. Please report the issue to the authors.\u201d","title":"Extract DEG results using results function"},{"location":"BIOI611_DESeq2_analysis/#understand-normalized-count-in-deseq2-optional","text":"","title":"Understand normalized count in DESeq2 (Optional)"},{"location":"BIOI611_DESeq2_analysis/#create-a-pseudo-reference-sample-row-wise-geometric-mean","text":"The code below creates a new column called pseudo_reference that contains the average log-transformed expression value for each gene across all samples. This pseudo-reference is similar to calculating a \"reference sample\" to compare other samples. log_data = log(merged_df) head(log_data) A data.frame: 6 \u00d7 6 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> WBGene00000001 8.079308 7.681560 7.859027 8.641002 7.870548 8.563886 WBGene00000002 5.598422 5.313206 5.583496 5.872118 5.252273 6.052089 WBGene00000003 5.831882 6.028279 6.018593 5.958425 5.541264 6.212606 WBGene00000004 6.369901 6.082219 6.249975 6.935370 6.293419 6.788972 WBGene00000005 5.948035 5.978886 6.180017 4.779123 4.174387 5.241747 WBGene00000006 5.837730 5.840642 5.811141 5.327876 4.736198 5.393628 library(dplyr) library(tibble) # rownames_to_column log_data = log_data %>% rownames_to_column('gene') %>% mutate (pseudo_reference = rowMeans(log_data)) head(log_data) A data.frame: 6 \u00d7 8 gene N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 pseudo_reference <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> 1 WBGene00000001 8.079308 7.681560 7.859027 8.641002 7.870548 8.563886 8.115889 2 WBGene00000002 5.598422 5.313206 5.583496 5.872118 5.252273 6.052089 5.611934 3 WBGene00000003 5.831882 6.028279 6.018593 5.958425 5.541264 6.212606 5.931841 4 WBGene00000004 6.369901 6.082219 6.249975 6.935370 6.293419 6.788972 6.453309 5 WBGene00000005 5.948035 5.978886 6.180017 4.779123 4.174387 5.241747 5.383699 6 WBGene00000006 5.837730 5.840642 5.811141 5.327876 4.736198 5.393628 5.491203 table(log_data$pseudo_reference == \"-Inf\") FALSE TRUE 16951 29975 filtered_log_data = log_data %>% filter(pseudo_reference != \"-Inf\") head(filtered_log_data) A data.frame: 6 \u00d7 8 gene N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 pseudo_reference <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> 1 WBGene00000001 8.079308 7.681560 7.859027 8.641002 7.870548 8.563886 8.115889 2 WBGene00000002 5.598422 5.313206 5.583496 5.872118 5.252273 6.052089 5.611934 3 WBGene00000003 5.831882 6.028279 6.018593 5.958425 5.541264 6.212606 5.931841 4 WBGene00000004 6.369901 6.082219 6.249975 6.935370 6.293419 6.788972 6.453309 5 WBGene00000005 5.948035 5.978886 6.180017 4.779123 4.174387 5.241747 5.383699 6 WBGene00000006 5.837730 5.840642 5.811141 5.327876 4.736198 5.393628 5.491203 filtered_log_data$pseudo_reference = exp(filtered_log_data$pseudo_reference) head(filtered_log_data) A data.frame: 6 \u00d7 8 gene N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 pseudo_reference <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> 1 WBGene00000001 8.079308 7.681560 7.859027 8.641002 7.870548 8.563886 3347.2307 2 WBGene00000002 5.598422 5.313206 5.583496 5.872118 5.252273 6.052089 273.6730 3 WBGene00000003 5.831882 6.028279 6.018593 5.958425 5.541264 6.212606 376.8478 4 WBGene00000004 6.369901 6.082219 6.249975 6.935370 6.293419 6.788972 634.7996 5 WBGene00000005 5.948035 5.978886 6.180017 4.779123 4.174387 5.241747 217.8266 6 WBGene00000006 5.837730 5.840642 5.811141 5.327876 4.736198 5.393628 242.5487 dim(log_data) dim(filtered_log_data) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 46926 8 .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 16951 8","title":"Create a pseudo-reference sample (row-wise geometric mean)"},{"location":"BIOI611_DESeq2_analysis/#calculate-ratio-between-each-sample-and-the-pseudo-reference-for-each-gene","text":"This step calculates the fold change between each sample and the pseudo-reference for each gene. ratio_data = sweep(exp(filtered_log_data[,2:7]), 1, filtered_log_data[,8], \"/\") head(ratio_data) A data.frame: 6 \u00d7 6 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> 1 0.9640805 0.6476996 0.7734752 1.6906513 0.7824378 1.5651745 2 0.9865787 0.7417610 0.9719628 1.2971683 0.6979131 1.5529480 3 0.9048746 1.1012403 1.0906259 1.0269398 0.6766657 1.3241420 4 0.9199753 0.6899815 0.8160055 1.6194086 0.8522374 1.3988666 5 1.7582795 1.8133692 2.2173603 0.5463062 0.2984025 0.8676627 6 1.4141490 1.4182718 1.3770430 0.8493139 0.4700087 0.9070343","title":"Calculate ratio between each sample and the pseudo-reference for each gene"},{"location":"BIOI611_DESeq2_analysis/#calculate-scaling-factor","text":"The code below computes the median fold change for each sample across all genes. scaling_factors = apply(ratio_data, 2, median, na.rm = TRUE) scaling_factors .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} N2_day1_rep1 1.00236113145741 N2_day1_rep2 0.810736816029527 N2_day1_rep3 0.944781672438598 N2_day7_rep1 1.31189917666838 N2_day7_rep2 0.71546097217711 N2_day7_rep3 1.42600915363567 The 2 indicates that the function is applied to columns, i.e., for each sample.","title":"Calculate scaling factor"},{"location":"BIOI611_DESeq2_analysis/#normalize-the-counts","text":"This step below normalizes each sample by its scaling factors, making the data comparable across samples. The result is a normalized gene expression matrix. manually_normalized = sweep(merged_df, 2, scaling_factors, \"/\") head(manually_normalized) A data.frame: 6 \u00d7 6 N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> WBGene00000001 3219.3986 2674.1107 2740.3156 4313.59368 3660.57703 3673.8895 WBGene00000002 269.3640 250.3895 281.5465 270.60006 266.96075 298.0346 WBGene00000003 340.1968 511.8800 435.0211 294.99218 356.41357 349.9276 WBGene00000004 582.6243 540.2493 548.2748 783.59680 756.15585 622.7169 WBGene00000005 382.0978 487.2111 511.2292 90.70819 90.85052 132.5377 WBGene00000006 342.1920 424.3054 353.5208 157.02426 159.33783 154.2767 hist(manually_normalized$N2_day1_rep1) The code below shows that the size factors and the normalized read counts calculated by ourselves are the same as what DESeq2 function returns. head(counts(dds, normalized = TRUE)) A matrix: 6 \u00d7 6 of type dbl N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 WBGene00000001 3219.3986 2674.1107 2740.3156 4313.59368 3660.57703 3673.8895 WBGene00000002 269.3640 250.3895 281.5465 270.60006 266.96075 298.0346 WBGene00000003 340.1968 511.8800 435.0211 294.99218 356.41357 349.9276 WBGene00000004 582.6243 540.2493 548.2748 783.59680 756.15585 622.7169 WBGene00000005 382.0978 487.2111 511.2292 90.70819 90.85052 132.5377 WBGene00000006 342.1920 424.3054 353.5208 157.02426 159.33783 154.2767 sizeFactors(dds) .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} N2_day1_rep1 1.00236113145741 N2_day1_rep2 0.810736816029527 N2_day1_rep3 0.944781672438598 N2_day7_rep1 1.31189917666838 N2_day7_rep2 0.71546097217711 N2_day7_rep3 1.42600915363567","title":"Normalize the counts"},{"location":"BIOI611_DESeq2_analysis/#sessioninfo","text":"sessionInfo() R version 4.5.1 (2025-06-13) Platform: x86_64-pc-linux-gnu Running under: Ubuntu 22.04.4 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so; LAPACK version 3.10.0 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C time zone: Etc/UTC tzcode source: system (glibc) attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] tibble_3.3.0 EnhancedVolcano_1.13.2 [3] ggrepel_0.9.6 ggplot2_4.0.0 [5] DESeq2_1.50.0 SummarizedExperiment_1.40.0 [7] Biobase_2.70.0 MatrixGenerics_1.22.0 [9] matrixStats_1.5.0 GenomicRanges_1.62.0 [11] Seqinfo_1.0.0 IRanges_2.44.0 [13] S4Vectors_0.48.0 BiocGenerics_0.56.0 [15] generics_0.1.4 dplyr_1.1.4 loaded via a namespace (and not attached): [1] gtable_0.3.6 remotes_2.5.0 processx_3.8.6 [4] lattice_0.22-7 callr_3.7.6 vctrs_0.6.5 [7] tools_4.5.1 ps_1.9.1 curl_7.0.0 [10] parallel_4.5.1 pkgconfig_2.0.3 Matrix_1.7-4 [13] RColorBrewer_1.1-3 S7_0.2.0 desc_1.4.3 [16] uuid_1.2-1 lifecycle_1.0.4 compiler_4.5.1 [19] farver_2.1.2 textshaping_1.0.4 repr_1.1.7 [22] codetools_0.2-20 htmltools_0.5.8.1 pillar_1.11.1 [25] crayon_1.5.3 BiocParallel_1.44.0 DelayedArray_0.36.0 [28] abind_1.4-8 tidyselect_1.2.1 locfit_1.5-9.12 [31] digest_0.6.37 labeling_0.4.3 fastmap_1.2.0 [34] grid_4.5.1 cli_3.6.5 SparseArray_1.10.0 [37] magrittr_2.0.4 S4Arrays_1.10.0 base64enc_0.1-3 [40] pkgbuild_1.4.8 IRdisplay_1.1 withr_3.0.2 [43] scales_1.4.0 IRkernel_1.3.2 XVector_0.50.0 [46] pbdZMQ_0.3-14 ragg_1.5.0 evaluate_1.0.5 [49] rlang_1.1.6 Rcpp_1.1.0 glue_1.8.0 [52] BiocManager_1.30.26 jsonlite_2.0.0 R6_2.6.1 [55] systemfonts_1.3.1","title":"SessionInfo"},{"location":"BIOI611_analysis_10x_dataset_PBMC/","text":"Download the data You can download the data from the link here # https://www.10xgenomics.com/datasets/5k-human-pbmcs-3-v3-1-chromium-controller-3-1-standard wget https://cf.10xgenomics.com/samples/cell-exp/7.0.1/SC3pv3_GEX_Human_PBMC/SC3pv3_GEX_Human_PBMC_fastqs.tar tar xvf SC3pv3_GEX_Human_PBMC_fastqs.tar For this class, you can find a copy under the path: %%bash ls /scratch/zt1/project/bioi611/shared/raw_data/Chromium_3p_GEX_Human_PBMC_fastqs/ Chromium_3p_GEX_Human_PBMC_S1_L001_I1_001.fastq.gz Chromium_3p_GEX_Human_PBMC_S1_L001_I2_001.fastq.gz Chromium_3p_GEX_Human_PBMC_S1_L001_R1_001.fastq.gz Chromium_3p_GEX_Human_PBMC_S1_L001_R2_001.fastq.gz Check R1 and R2 Read Read 1 i7 Index i5 Index Read 2 Purpose Cell barcode & UMI Sample Index Sample Index Insert Length** 28 10 10 90 An Unique Molecular Identifier (UMI) is a short sequence tag (usually 8-12 nucleotides long) that is added to each RNA molecule during library preparation. UMIs are critical for accurately quantifying gene expression, as they help to distinguish between unique RNA molecules and technical duplicates that arise from PCR amplification. How ow UMIs work in the 10x scRNA-seq workflow: Library Preparation: Each RNA molecule is tagged with a UMI as well as cell-specific barcodes. This labeling occurs before PCR amplification, so each original RNA molecule within a single cell is uniquely identifiable. Eliminating Amplification Bias: When the tagged molecules are amplified by PCR, each original molecule (regardless of how many duplicates it creates) retains its unique UMI. Later, when sequencing reads are aligned and counted, duplicate reads with the same UMI and gene alignment are considered as representing a single molecule. Accurate Quantification: Using UMIs allows for a more accurate measure of gene expression by avoiding overcounting due to PCR duplicates, providing a closer representation of the actual RNA molecules present in each cell. %%bash zcat /scratch/zt1/project/bioi611/shared/raw_data/Chromium_3p_GEX_Human_PBMC_fastqs/Chromium_3p_GEX_Human_PBMC_S1_L001_R1_001.fastq.gz |head -12 @A00836:523:HJH22DSXY:1:1101:1823:1016 1:N:0:ATGGAGGGAG+AATGGGTTAT TNATGGACAAACAGGCCGTTGCACTAAA + F#FFFFFFFFFFF:FFFFFFFFFFFFFF @A00836:523:HJH22DSXY:1:1101:1841:1016 1:N:0:ATGGAGGGAG+AATGGGTTAT TNGTGATGTTCTTGTTCTCACTCGAGGT + F#FFFFFFFFFFFFFFFFFFFFFFFFFF @A00836:523:HJH22DSXY:1:1101:1949:1016 1:N:0:ATGGAGGGAG+AATGGGTTAT ANACAGGGTCCTACGGTTCATCTTTGTG + F#FFFFFFFFFFFFFFFFFFFFFFFFFF %%bash zcat /scratch/zt1/project/bioi611/shared/raw_data/Chromium_3p_GEX_Human_PBMC_fastqs/Chromium_3p_GEX_Human_PBMC_S1_L001_R2_001.fastq.gz |head -12 @A00836:523:HJH22DSXY:1:1101:1823:1016 2:N:0:ATGGAGGGAG+AATGGGTTAT GGCTCACACCTGTAATCCCAGCACTTTGGGAGGCCAAGACAGGTGAACTGCTCGAGGCCGGGAGTTTGAGACCAGCCTGGACAACATGGC + FFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFF,F,FFF:FFFFFFFFFF @A00836:523:HJH22DSXY:1:1101:1841:1016 2:N:0:ATGGAGGGAG+AATGGGTTAT CAGGGCCTGTTGGGGGTTGGGGGCAAGGAGAGGGAGAGCATTAGGACAAATACCTAATGTGTGTGGGGCTTAAAACCTAGATGACGGGTT + FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFF @A00836:523:HJH22DSXY:1:1101:1949:1016 2:N:0:ATGGAGGGAG+AATGGGTTAT TTTTTTTTGTTCAAATGATTTTAATTATTGGAATGCACAATTTTTTTAATATGCAAATAAAAAGTTTAAAAACCAAAAAAAAAAAAAAGA + FFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFF,:,: Run Cellranger Cell Ranger is a software suite developed by 10x Genomics for processing and analyzing data from their single-cell RNA-seq (scRNA-seq), single-cell ATAC-seq (scATAC-seq), and other single-cell assays. Cell Ranger performs tasks such as alignment, filtering, UMI counting, and data aggregation, streamlining the analysis of single-cell datasets generated by 10x Genomics platforms. Key Functions of cellranger count : Preprocessing and Alignment: Cell Ranger aligns the reads to a reference genome and uses cell and UMI barcodes to assign each read to a specific cell and RNA molecule. It leverages the STAR aligner for RNA-seq data. UMI Counting: Once the reads are aligned, Cell Ranger aggregates UMIs per gene per cell, providing an accurate gene expression count that minimizes PCR amplification bias. Gene Expression Quantification: For scRNA-seq data, Cell Ranger creates a gene expression matrix with rows for genes, columns for cells, and values representing UMI counts. This matrix is foundational for downstream analysis, including cell clustering, differential expression, and pathway analysis. Cell Clustering and Visualization: Cell Ranger includes tools to cluster cells based on gene expression patterns and create basic visualizations (e.g., t-SNE or UMAP plots) for exploratory data analysis. %%bash sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_illumina_demo_cellranger.sub Submitted batch job 8653857 %%bash cat /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_illumina_demo_cellranger.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH -n 1 #SBATCH -c 26 #SBATCH --mem=250g #SBATCH --job-name=scRNA_10x_illumina_demo_cellranger #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out ## Prepare the input folder WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER/scRNA_10x_illumina_demo/\" REFERENCE=\"/scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A\" FASTQ_DIR=/scratch/zt1/project/bioi611/shared/raw_data/Chromium_3p_GEX_Human_PBMC_fastqs/ mkdir -p $WORKDIR cd $WORKDIR export PATH=/scratch/zt1/project/bioi611/shared/software/cellranger-8.0.1/bin:$PATH cellranger count --id GEX3p_Human_PBMC \\ --transcriptome $REFERENCE \\ --create-bam true \\ --fastqs $FASTQ_DIR Input files/folder for cellranger count : Raw fastq files Reference In this class, the pre-built reference has been downloaded from 10x website: https://www.10xgenomics.com/support/software/cell-ranger/downloads %%bash ls /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A ls /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A/fasta/ ls /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A/genes/ ls /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A/star/ cat /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A/reference.json fasta genes reference.json star genome.fa genome.fa.fai genes.gtf.gz chrLength.txt chrNameLength.txt chrName.txt chrStart.txt exonGeTrInfo.tab exonInfo.tab geneInfo.tab Genome genomeParameters.txt SA SAindex sjdbInfo.txt sjdbList.fromGTF.out.tab sjdbList.out.tab transcriptInfo.tab { \"fasta_hash\": \"b6f131840f9f337e7b858c3d1e89d7ce0321b243\", \"genomes\": [ \"GRCh38\" ], \"gtf_hash.gz\": \"432db3ab308171ef215fac5dc4ca40096099a4c6\", \"input_fasta_files\": [ \"Homo_sapiens.GRCh38.dna.primary_assembly.fa.modified\" ], \"input_gtf_files\": [ \"gencode.v44.primary_assembly.annotation.gtf.filtered\" ], \"mem_gb\": 16, \"mkref_version\": \"8.0.0\", \"threads\": 2, \"version\": \"2024-A\" } Output folder The job you submitted will generate an output folder: %%bash ls /scratch/zt1/project/bioi611/user/$USER/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/* /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_cmdline /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_filelist /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_finalstate /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/GEX3p_Human_PBMC.mri.tgz /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_invocation /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_jobmode /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_log /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_mrosource /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_perf /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_perf._truncated_ /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_sitecheck /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_tags /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_timestamp /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_uuid /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_vdrkill /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_versions /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/outs: analysis cloupe.cloupe filtered_feature_bc_matrix filtered_feature_bc_matrix.h5 metrics_summary.csv molecule_info.h5 possorted_genome_bam.bam possorted_genome_bam.bam.bai raw_feature_bc_matrix raw_feature_bc_matrix.h5 web_summary.html /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/SC_RNA_COUNTER_CS: CELLRANGER_PREFLIGHT CELLRANGER_PREFLIGHT_LOCAL COPY_CHEMISTRY_SPEC fork0 FULL_COUNT_INPUTS GET_AGGREGATE_BARCODES_OUT SC_MULTI_CORE _STRUCTIFY WRITE_GENE_INDEX You can also find a copy here: /scratch/zt1/project/bioi611/shared/output/scRNA_10x_illumina_demo The summary file in html format is the first file you will check: /scratch/zt1/project/bioi611/shared/output/scRNA_10x_illumina_demo/outs/web_summary.html A detailed documentation can be found here to help you interpret the summary file. If there is any metrics that is not within the expectation, a warning or an error message will be shown on the top of the summary. The three files below are usually used as input for downstream analysis. %%bash ls /scratch/zt1/project/bioi611/shared/output/scRNA_10x_illumina_demo/outs/filtered_feature_bc_matrix barcodes.tsv.gz features.tsv.gz matrix.mtx.gz The folder above contains only detected cell-associated barcodes. Each element of the matrix is the number of UMIs associated with a feature (row) and a barcode (column. It can be input into third-party packages and allows users to wrangle the barcodefeature matrix (e.g. to filter outlier cells, run dimensionality reduction, normalize gene expression).","title":"Initial analysis of 10x scRNA-seq data for human PBMC using cellranger"},{"location":"BIOI611_analysis_10x_dataset_PBMC/#_1","text":"","title":""},{"location":"BIOI611_analysis_10x_dataset_PBMC/#download-the-data","text":"You can download the data from the link here # https://www.10xgenomics.com/datasets/5k-human-pbmcs-3-v3-1-chromium-controller-3-1-standard wget https://cf.10xgenomics.com/samples/cell-exp/7.0.1/SC3pv3_GEX_Human_PBMC/SC3pv3_GEX_Human_PBMC_fastqs.tar tar xvf SC3pv3_GEX_Human_PBMC_fastqs.tar For this class, you can find a copy under the path: %%bash ls /scratch/zt1/project/bioi611/shared/raw_data/Chromium_3p_GEX_Human_PBMC_fastqs/ Chromium_3p_GEX_Human_PBMC_S1_L001_I1_001.fastq.gz Chromium_3p_GEX_Human_PBMC_S1_L001_I2_001.fastq.gz Chromium_3p_GEX_Human_PBMC_S1_L001_R1_001.fastq.gz Chromium_3p_GEX_Human_PBMC_S1_L001_R2_001.fastq.gz","title":"Download the data"},{"location":"BIOI611_analysis_10x_dataset_PBMC/#check-r1-and-r2","text":"Read Read 1 i7 Index i5 Index Read 2 Purpose Cell barcode & UMI Sample Index Sample Index Insert Length** 28 10 10 90 An Unique Molecular Identifier (UMI) is a short sequence tag (usually 8-12 nucleotides long) that is added to each RNA molecule during library preparation. UMIs are critical for accurately quantifying gene expression, as they help to distinguish between unique RNA molecules and technical duplicates that arise from PCR amplification. How ow UMIs work in the 10x scRNA-seq workflow: Library Preparation: Each RNA molecule is tagged with a UMI as well as cell-specific barcodes. This labeling occurs before PCR amplification, so each original RNA molecule within a single cell is uniquely identifiable. Eliminating Amplification Bias: When the tagged molecules are amplified by PCR, each original molecule (regardless of how many duplicates it creates) retains its unique UMI. Later, when sequencing reads are aligned and counted, duplicate reads with the same UMI and gene alignment are considered as representing a single molecule. Accurate Quantification: Using UMIs allows for a more accurate measure of gene expression by avoiding overcounting due to PCR duplicates, providing a closer representation of the actual RNA molecules present in each cell. %%bash zcat /scratch/zt1/project/bioi611/shared/raw_data/Chromium_3p_GEX_Human_PBMC_fastqs/Chromium_3p_GEX_Human_PBMC_S1_L001_R1_001.fastq.gz |head -12 @A00836:523:HJH22DSXY:1:1101:1823:1016 1:N:0:ATGGAGGGAG+AATGGGTTAT TNATGGACAAACAGGCCGTTGCACTAAA + F#FFFFFFFFFFF:FFFFFFFFFFFFFF @A00836:523:HJH22DSXY:1:1101:1841:1016 1:N:0:ATGGAGGGAG+AATGGGTTAT TNGTGATGTTCTTGTTCTCACTCGAGGT + F#FFFFFFFFFFFFFFFFFFFFFFFFFF @A00836:523:HJH22DSXY:1:1101:1949:1016 1:N:0:ATGGAGGGAG+AATGGGTTAT ANACAGGGTCCTACGGTTCATCTTTGTG + F#FFFFFFFFFFFFFFFFFFFFFFFFFF %%bash zcat /scratch/zt1/project/bioi611/shared/raw_data/Chromium_3p_GEX_Human_PBMC_fastqs/Chromium_3p_GEX_Human_PBMC_S1_L001_R2_001.fastq.gz |head -12 @A00836:523:HJH22DSXY:1:1101:1823:1016 2:N:0:ATGGAGGGAG+AATGGGTTAT GGCTCACACCTGTAATCCCAGCACTTTGGGAGGCCAAGACAGGTGAACTGCTCGAGGCCGGGAGTTTGAGACCAGCCTGGACAACATGGC + FFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFF,F,FFF:FFFFFFFFFF @A00836:523:HJH22DSXY:1:1101:1841:1016 2:N:0:ATGGAGGGAG+AATGGGTTAT CAGGGCCTGTTGGGGGTTGGGGGCAAGGAGAGGGAGAGCATTAGGACAAATACCTAATGTGTGTGGGGCTTAAAACCTAGATGACGGGTT + FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFF @A00836:523:HJH22DSXY:1:1101:1949:1016 2:N:0:ATGGAGGGAG+AATGGGTTAT TTTTTTTTGTTCAAATGATTTTAATTATTGGAATGCACAATTTTTTTAATATGCAAATAAAAAGTTTAAAAACCAAAAAAAAAAAAAAGA + FFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFF,:,:","title":"Check R1 and R2"},{"location":"BIOI611_analysis_10x_dataset_PBMC/#run-cellranger","text":"Cell Ranger is a software suite developed by 10x Genomics for processing and analyzing data from their single-cell RNA-seq (scRNA-seq), single-cell ATAC-seq (scATAC-seq), and other single-cell assays. Cell Ranger performs tasks such as alignment, filtering, UMI counting, and data aggregation, streamlining the analysis of single-cell datasets generated by 10x Genomics platforms. Key Functions of cellranger count : Preprocessing and Alignment: Cell Ranger aligns the reads to a reference genome and uses cell and UMI barcodes to assign each read to a specific cell and RNA molecule. It leverages the STAR aligner for RNA-seq data. UMI Counting: Once the reads are aligned, Cell Ranger aggregates UMIs per gene per cell, providing an accurate gene expression count that minimizes PCR amplification bias. Gene Expression Quantification: For scRNA-seq data, Cell Ranger creates a gene expression matrix with rows for genes, columns for cells, and values representing UMI counts. This matrix is foundational for downstream analysis, including cell clustering, differential expression, and pathway analysis. Cell Clustering and Visualization: Cell Ranger includes tools to cluster cells based on gene expression patterns and create basic visualizations (e.g., t-SNE or UMAP plots) for exploratory data analysis. %%bash sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_illumina_demo_cellranger.sub Submitted batch job 8653857 %%bash cat /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_illumina_demo_cellranger.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH -n 1 #SBATCH -c 26 #SBATCH --mem=250g #SBATCH --job-name=scRNA_10x_illumina_demo_cellranger #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out ## Prepare the input folder WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER/scRNA_10x_illumina_demo/\" REFERENCE=\"/scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A\" FASTQ_DIR=/scratch/zt1/project/bioi611/shared/raw_data/Chromium_3p_GEX_Human_PBMC_fastqs/ mkdir -p $WORKDIR cd $WORKDIR export PATH=/scratch/zt1/project/bioi611/shared/software/cellranger-8.0.1/bin:$PATH cellranger count --id GEX3p_Human_PBMC \\ --transcriptome $REFERENCE \\ --create-bam true \\ --fastqs $FASTQ_DIR Input files/folder for cellranger count : Raw fastq files Reference In this class, the pre-built reference has been downloaded from 10x website: https://www.10xgenomics.com/support/software/cell-ranger/downloads %%bash ls /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A ls /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A/fasta/ ls /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A/genes/ ls /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A/star/ cat /scratch/zt1/project/bioi611/shared/reference/refdata-gex-GRCh38-2024-A/reference.json fasta genes reference.json star genome.fa genome.fa.fai genes.gtf.gz chrLength.txt chrNameLength.txt chrName.txt chrStart.txt exonGeTrInfo.tab exonInfo.tab geneInfo.tab Genome genomeParameters.txt SA SAindex sjdbInfo.txt sjdbList.fromGTF.out.tab sjdbList.out.tab transcriptInfo.tab { \"fasta_hash\": \"b6f131840f9f337e7b858c3d1e89d7ce0321b243\", \"genomes\": [ \"GRCh38\" ], \"gtf_hash.gz\": \"432db3ab308171ef215fac5dc4ca40096099a4c6\", \"input_fasta_files\": [ \"Homo_sapiens.GRCh38.dna.primary_assembly.fa.modified\" ], \"input_gtf_files\": [ \"gencode.v44.primary_assembly.annotation.gtf.filtered\" ], \"mem_gb\": 16, \"mkref_version\": \"8.0.0\", \"threads\": 2, \"version\": \"2024-A\" }","title":"Run Cellranger"},{"location":"BIOI611_analysis_10x_dataset_PBMC/#output-folder","text":"The job you submitted will generate an output folder: %%bash ls /scratch/zt1/project/bioi611/user/$USER/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/* /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_cmdline /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_filelist /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_finalstate /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/GEX3p_Human_PBMC.mri.tgz /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_invocation /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_jobmode /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_log /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_mrosource /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_perf /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_perf._truncated_ /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_sitecheck /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_tags /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_timestamp /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_uuid /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_vdrkill /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/_versions /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/outs: analysis cloupe.cloupe filtered_feature_bc_matrix filtered_feature_bc_matrix.h5 metrics_summary.csv molecule_info.h5 possorted_genome_bam.bam possorted_genome_bam.bam.bai raw_feature_bc_matrix raw_feature_bc_matrix.h5 web_summary.html /scratch/zt1/project/bioi611/user/xie186/scRNA_10x_illumina_demo/GEX3p_Human_PBMC/SC_RNA_COUNTER_CS: CELLRANGER_PREFLIGHT CELLRANGER_PREFLIGHT_LOCAL COPY_CHEMISTRY_SPEC fork0 FULL_COUNT_INPUTS GET_AGGREGATE_BARCODES_OUT SC_MULTI_CORE _STRUCTIFY WRITE_GENE_INDEX You can also find a copy here: /scratch/zt1/project/bioi611/shared/output/scRNA_10x_illumina_demo The summary file in html format is the first file you will check: /scratch/zt1/project/bioi611/shared/output/scRNA_10x_illumina_demo/outs/web_summary.html A detailed documentation can be found here to help you interpret the summary file. If there is any metrics that is not within the expectation, a warning or an error message will be shown on the top of the summary. The three files below are usually used as input for downstream analysis. %%bash ls /scratch/zt1/project/bioi611/shared/output/scRNA_10x_illumina_demo/outs/filtered_feature_bc_matrix barcodes.tsv.gz features.tsv.gz matrix.mtx.gz The folder above contains only detected cell-associated barcodes. Each element of the matrix is the number of UMIs associated with a feature (row) and a barcode (column. It can be input into third-party packages and allows users to wrangle the barcodefeature matrix (e.g. to filter outlier cells, run dimensionality reduction, normalize gene expression).","title":"Output folder"},{"location":"BIOI611_ballgown_example/","text":"Isoform-level differential expression analysis with Ballgown. Install R package if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"ballgown\") 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.19 (BiocManager 1.30.25), R 4.4.1 (2024-06-14) Warning message: \u201cpackage(s) not installed when version(s) same as or greater than current; use `force = TRUE` to re-install: 'ballgown'\u201d Old packages: 'Matrix' Understand the folder with example data library(ballgown) data_directory = system.file('extdata', package='ballgown') # automatically finds ballgown's installation directory # examine data_directory: data_directory Attaching package: \u2018ballgown\u2019 The following object is masked from \u2018package:base\u2019: structure '/usr/local/lib/R/site-library/ballgown/extdata' list.files(data_directory) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'annot.gtf.gz' 'hg19_genes_small.gtf.gz' 'sample01' 'sample02' 'sample03' 'sample04' 'sample05' 'sample06' 'sample07' 'sample08' 'sample09' 'sample10' 'sample11' 'sample12' 'sample13' 'sample14' 'sample15' 'sample16' 'sample17' 'sample18' 'sample19' 'sample20' 'tiny.genes.results.gz' 'tiny.isoforms.results.gz' 'tiny2.genes.results.gz' 'tiny2.isoforms.results.gz' # make the ballgown object: bg = ballgown(dataDir=data_directory, samplePattern='sample', meas='all') bg Mon Oct 21 17:42:05 2024 Mon Oct 21 17:42:05 2024: Reading linking tables Mon Oct 21 17:42:05 2024: Reading intron data files Mon Oct 21 17:42:05 2024: Merging intron data Mon Oct 21 17:42:05 2024: Reading exon data files Mon Oct 21 17:42:05 2024: Merging exon data Mon Oct 21 17:42:05 2024: Reading transcript data files Mon Oct 21 17:42:05 2024: Merging transcript data Wrapping up the results Mon Oct 21 17:42:05 2024 ballgown instance with 100 transcripts and 20 samples Accessing assembly data A ballgown object has six slots: structure, expr, indexes, dirs, mergedDate, and meas. Exon, intron, and transcript structures are easily extracted from the main ballgown object: Structure structure(bg)$exon GRanges object with 633 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 18 24412069-24412331 * | 12 10 [2] 22 17308271-17308950 + | 55 25 [3] 22 17309432-17310226 + | 56 25 [4] 22 18121428-18121652 + | 88 35 [5] 22 18138428-18138598 + | 89 35 ... ... ... ... . ... ... [629] 22 51221929-51222113 - | 3777 1294 [630] 22 51221319-51221473 - | 3782 1297 [631] 22 51221929-51222162 - | 3783 1297 [632] 22 51221929-51222168 - | 3784 1301 [633] 6 31248149-31248334 * | 3794 1312 ------- seqinfo: 3 sequences from an unspecified genome; no seqlengths structure(bg)$intron GRanges object with 536 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 22 17308951-17309431 + | 33 25 [2] 22 18121653-18138427 + | 57 35 [3] 22 18138599-18185008 + | 58 35 [4] 22 18185153-18209442 + | 59 35 [5] 22 18385514-18387397 - | 72 41 ... ... ... ... . ... ... [532] 22 51216410-51220615 - | 2750 c(1294, 1297, 1301) [533] 22 51220776-51221928 - | 2756 1294 [534] 22 51220780-51221318 - | 2757 1297 [535] 22 51221474-51221928 - | 2758 1297 [536] 22 51220780-51221928 - | 2759 1301 ------- seqinfo: 1 sequence from an unspecified genome; no seqlengths structure(bg)$trans GRangesList object of length 100: $`10` GRanges object with 1 range and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 18 24412069-24412331 * | 12 10 ------- seqinfo: 3 sequences from an unspecified genome; no seqlengths $`25` GRanges object with 2 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 22 17308271-17308950 + | 55 25 [2] 22 17309432-17310226 + | 56 25 ------- seqinfo: 3 sequences from an unspecified genome; no seqlengths $`35` GRanges object with 4 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 22 18121428-18121652 + | 88 35 [2] 22 18138428-18138598 + | 89 35 [3] 22 18185009-18185152 + | 90 35 [4] 22 18209443-18212080 + | 91 35 ------- seqinfo: 3 sequences from an unspecified genome; no seqlengths ... <97 more elements> expr The expr slot is a list that contains tables of expression data for the genomic features. These tables are very similar to the *_data.ctab Tablemaker output files. Ballgown implements the following syntax to access components of the expr slot: *expr(ballgown_object_name, <EXPRESSION_MEASUREMENT>) where * is either e for exon, i for intron, t for transcript, or g for gene, and is an expression-measurement column name from the appropriate .ctab file. Gene-level measurements are calculated by aggregating the transcript-level measurements for that gene. All of the following are valid ways to extract expression data from the bg ballgown object: transcript_fpkm = texpr(bg, 'FPKM') transcript_cov = texpr(bg, 'cov') whole_tx_table = texpr(bg, 'all') exon_mcov = eexpr(bg, 'mcov') junction_rcount = iexpr(bg) whole_intron_table = iexpr(bg, 'all') gene_expression = gexpr(bg) Indexes pData(bg) = data.frame(id=sampleNames(bg), group=rep(c(1,0), each=10)) pData(bg) A data.frame: 20 \u00d7 2 id group <chr> <dbl> sample01 1 sample02 1 sample03 1 sample04 1 sample05 1 sample06 1 sample07 1 sample08 1 sample09 1 sample10 1 sample11 0 sample12 0 sample13 0 sample14 0 sample15 0 sample16 0 sample17 0 sample18 0 sample19 0 sample20 0 Plotting transcript structures plotTranscripts(gene='XLOC_000454', gown=bg, samples='sample12', meas='FPKM', colorby='transcript', main='transcripts from gene XLOC_000454: sample 12, FPKM') It is also possible to plot several samples at once: plotTranscripts('XLOC_000454', bg, samples=c('sample01', 'sample06', 'sample12', 'sample19'), meas='FPKM', colorby='transcript') You can also make side-by-side plots comparing mean abundances between groups (here, 0 and 1): plotMeans('XLOC_000454', bg, groupvar='group', meas='FPKM', colorby='transcript') Differential expression analysis Ballgown provides a wide selection of simple, fast statistical methods for testing whether transcripts are differentially expressed between experimental conditions or across a continuous covariate (such as time). stat_results = stattest(bg, feature='transcript', meas='FPKM', covariate='group', getFC=TRUE) results_transcripts <- data.frame(geneNames = geneNames(bg), geneIDs = geneIDs(bg), transcriptNames = transcriptNames(bg), stat_results) head(results_transcripts) A data.frame: 6 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 10 XLOC_000010 TCONS_00000010 transcript 10 3.193499 0.01381576 0.10521233 25 XLOC_000014 TCONS_00000017 transcript 25 1.549093 0.26773622 0.79114975 35 XLOC_000017 TCONS_00000020 transcript 35 4.388626 0.01085070 0.08951825 41 XLOC_000246 TCONS_00000598 transcript 41 1.440519 0.47108019 0.90253747 45 XLOC_000019 TCONS_00000024 transcript 45 1.714340 0.08402948 0.48934813 67 XLOC_000255 TCONS_00000613 transcript 67 2.518524 0.27317385 0.79114975 results_transcripts <- results_transcripts[order(results_transcripts$qval), ] head(results_transcripts, 10) A data.frame: 10 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 1225 XLOC_000440 TCONS_00001129 transcript 1225 5.67437122 1.035753e-05 0.001025395 980 XLOC_000179 TCONS_00000452 transcript 980 6.25344921 2.514632e-05 0.001244743 469 XLOC_000101 TCONS_00000244 transcript 469 119.29999938 2.398681e-04 0.007915648 695 XLOC_000354 TCONS_00000883 transcript 695 0.21950959 3.302059e-04 0.008172596 1012 XLOC_000409 TCONS_00001041 transcript 1012 0.24664434 1.527175e-03 0.030238073 123 XLOC_000029 TCONS_00000059 transcript 123 0.01603345 2.097875e-03 0.034614939 961 XLOC_000176 TCONS_00000435 transcript 961 4.96074399 2.736075e-03 0.038695918 880 XLOC_000531 TCONS_00001277 transcript 880 29.40485236 3.272859e-03 0.040501628 1063 XLOC_000197 TCONS_00000487 transcript 1063 3.12988187 4.555313e-03 0.050108442 35 XLOC_000017 TCONS_00000020 transcript 35 4.38862590 1.085070e-02 0.089518247 results_transcripts[results_transcripts$geneIDs == \"XLOC_000101\", ] A data.frame: 2 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 469 XLOC_000101 TCONS_00000244 transcript 469 119.299999 0.0002398681 0.007915648 477 XLOC_000101 TCONS_00000252 transcript 477 3.128184 0.4511803632 0.902537469 plotMeans('XLOC_000101', bg, groupvar='group', meas='FPKM', colorby='transcript') Reference https://www.bioconductor.org/packages/release/bioc/vignettes/ballgown/inst/doc/ballgown.html","title":"DE analysis at isoform-leve using ballgown (example data)"},{"location":"BIOI611_ballgown_example/#isoform-level-differential-expression-analysis-with-ballgown","text":"","title":"Isoform-level differential expression analysis with Ballgown."},{"location":"BIOI611_ballgown_example/#install-r-package","text":"if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"ballgown\") 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.19 (BiocManager 1.30.25), R 4.4.1 (2024-06-14) Warning message: \u201cpackage(s) not installed when version(s) same as or greater than current; use `force = TRUE` to re-install: 'ballgown'\u201d Old packages: 'Matrix'","title":"Install R package"},{"location":"BIOI611_ballgown_example/#understand-the-folder-with-example-data","text":"library(ballgown) data_directory = system.file('extdata', package='ballgown') # automatically finds ballgown's installation directory # examine data_directory: data_directory Attaching package: \u2018ballgown\u2019 The following object is masked from \u2018package:base\u2019: structure '/usr/local/lib/R/site-library/ballgown/extdata' list.files(data_directory) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'annot.gtf.gz' 'hg19_genes_small.gtf.gz' 'sample01' 'sample02' 'sample03' 'sample04' 'sample05' 'sample06' 'sample07' 'sample08' 'sample09' 'sample10' 'sample11' 'sample12' 'sample13' 'sample14' 'sample15' 'sample16' 'sample17' 'sample18' 'sample19' 'sample20' 'tiny.genes.results.gz' 'tiny.isoforms.results.gz' 'tiny2.genes.results.gz' 'tiny2.isoforms.results.gz' # make the ballgown object: bg = ballgown(dataDir=data_directory, samplePattern='sample', meas='all') bg Mon Oct 21 17:42:05 2024 Mon Oct 21 17:42:05 2024: Reading linking tables Mon Oct 21 17:42:05 2024: Reading intron data files Mon Oct 21 17:42:05 2024: Merging intron data Mon Oct 21 17:42:05 2024: Reading exon data files Mon Oct 21 17:42:05 2024: Merging exon data Mon Oct 21 17:42:05 2024: Reading transcript data files Mon Oct 21 17:42:05 2024: Merging transcript data Wrapping up the results Mon Oct 21 17:42:05 2024 ballgown instance with 100 transcripts and 20 samples","title":"Understand the folder with example data"},{"location":"BIOI611_ballgown_example/#accessing-assembly-data","text":"A ballgown object has six slots: structure, expr, indexes, dirs, mergedDate, and meas. Exon, intron, and transcript structures are easily extracted from the main ballgown object:","title":"Accessing assembly data"},{"location":"BIOI611_ballgown_example/#structure","text":"structure(bg)$exon GRanges object with 633 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 18 24412069-24412331 * | 12 10 [2] 22 17308271-17308950 + | 55 25 [3] 22 17309432-17310226 + | 56 25 [4] 22 18121428-18121652 + | 88 35 [5] 22 18138428-18138598 + | 89 35 ... ... ... ... . ... ... [629] 22 51221929-51222113 - | 3777 1294 [630] 22 51221319-51221473 - | 3782 1297 [631] 22 51221929-51222162 - | 3783 1297 [632] 22 51221929-51222168 - | 3784 1301 [633] 6 31248149-31248334 * | 3794 1312 ------- seqinfo: 3 sequences from an unspecified genome; no seqlengths structure(bg)$intron GRanges object with 536 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 22 17308951-17309431 + | 33 25 [2] 22 18121653-18138427 + | 57 35 [3] 22 18138599-18185008 + | 58 35 [4] 22 18185153-18209442 + | 59 35 [5] 22 18385514-18387397 - | 72 41 ... ... ... ... . ... ... [532] 22 51216410-51220615 - | 2750 c(1294, 1297, 1301) [533] 22 51220776-51221928 - | 2756 1294 [534] 22 51220780-51221318 - | 2757 1297 [535] 22 51221474-51221928 - | 2758 1297 [536] 22 51220780-51221928 - | 2759 1301 ------- seqinfo: 1 sequence from an unspecified genome; no seqlengths structure(bg)$trans GRangesList object of length 100: $`10` GRanges object with 1 range and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 18 24412069-24412331 * | 12 10 ------- seqinfo: 3 sequences from an unspecified genome; no seqlengths $`25` GRanges object with 2 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 22 17308271-17308950 + | 55 25 [2] 22 17309432-17310226 + | 56 25 ------- seqinfo: 3 sequences from an unspecified genome; no seqlengths $`35` GRanges object with 4 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] 22 18121428-18121652 + | 88 35 [2] 22 18138428-18138598 + | 89 35 [3] 22 18185009-18185152 + | 90 35 [4] 22 18209443-18212080 + | 91 35 ------- seqinfo: 3 sequences from an unspecified genome; no seqlengths ... <97 more elements>","title":"Structure"},{"location":"BIOI611_ballgown_example/#expr","text":"The expr slot is a list that contains tables of expression data for the genomic features. These tables are very similar to the *_data.ctab Tablemaker output files. Ballgown implements the following syntax to access components of the expr slot: *expr(ballgown_object_name, <EXPRESSION_MEASUREMENT>) where * is either e for exon, i for intron, t for transcript, or g for gene, and is an expression-measurement column name from the appropriate .ctab file. Gene-level measurements are calculated by aggregating the transcript-level measurements for that gene. All of the following are valid ways to extract expression data from the bg ballgown object: transcript_fpkm = texpr(bg, 'FPKM') transcript_cov = texpr(bg, 'cov') whole_tx_table = texpr(bg, 'all') exon_mcov = eexpr(bg, 'mcov') junction_rcount = iexpr(bg) whole_intron_table = iexpr(bg, 'all') gene_expression = gexpr(bg)","title":"expr"},{"location":"BIOI611_ballgown_example/#indexes","text":"pData(bg) = data.frame(id=sampleNames(bg), group=rep(c(1,0), each=10)) pData(bg) A data.frame: 20 \u00d7 2 id group <chr> <dbl> sample01 1 sample02 1 sample03 1 sample04 1 sample05 1 sample06 1 sample07 1 sample08 1 sample09 1 sample10 1 sample11 0 sample12 0 sample13 0 sample14 0 sample15 0 sample16 0 sample17 0 sample18 0 sample19 0 sample20 0","title":"Indexes"},{"location":"BIOI611_ballgown_example/#plotting-transcript-structures","text":"plotTranscripts(gene='XLOC_000454', gown=bg, samples='sample12', meas='FPKM', colorby='transcript', main='transcripts from gene XLOC_000454: sample 12, FPKM') It is also possible to plot several samples at once: plotTranscripts('XLOC_000454', bg, samples=c('sample01', 'sample06', 'sample12', 'sample19'), meas='FPKM', colorby='transcript') You can also make side-by-side plots comparing mean abundances between groups (here, 0 and 1): plotMeans('XLOC_000454', bg, groupvar='group', meas='FPKM', colorby='transcript')","title":"Plotting transcript structures"},{"location":"BIOI611_ballgown_example/#differential-expression-analysis","text":"Ballgown provides a wide selection of simple, fast statistical methods for testing whether transcripts are differentially expressed between experimental conditions or across a continuous covariate (such as time). stat_results = stattest(bg, feature='transcript', meas='FPKM', covariate='group', getFC=TRUE) results_transcripts <- data.frame(geneNames = geneNames(bg), geneIDs = geneIDs(bg), transcriptNames = transcriptNames(bg), stat_results) head(results_transcripts) A data.frame: 6 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 10 XLOC_000010 TCONS_00000010 transcript 10 3.193499 0.01381576 0.10521233 25 XLOC_000014 TCONS_00000017 transcript 25 1.549093 0.26773622 0.79114975 35 XLOC_000017 TCONS_00000020 transcript 35 4.388626 0.01085070 0.08951825 41 XLOC_000246 TCONS_00000598 transcript 41 1.440519 0.47108019 0.90253747 45 XLOC_000019 TCONS_00000024 transcript 45 1.714340 0.08402948 0.48934813 67 XLOC_000255 TCONS_00000613 transcript 67 2.518524 0.27317385 0.79114975 results_transcripts <- results_transcripts[order(results_transcripts$qval), ] head(results_transcripts, 10) A data.frame: 10 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 1225 XLOC_000440 TCONS_00001129 transcript 1225 5.67437122 1.035753e-05 0.001025395 980 XLOC_000179 TCONS_00000452 transcript 980 6.25344921 2.514632e-05 0.001244743 469 XLOC_000101 TCONS_00000244 transcript 469 119.29999938 2.398681e-04 0.007915648 695 XLOC_000354 TCONS_00000883 transcript 695 0.21950959 3.302059e-04 0.008172596 1012 XLOC_000409 TCONS_00001041 transcript 1012 0.24664434 1.527175e-03 0.030238073 123 XLOC_000029 TCONS_00000059 transcript 123 0.01603345 2.097875e-03 0.034614939 961 XLOC_000176 TCONS_00000435 transcript 961 4.96074399 2.736075e-03 0.038695918 880 XLOC_000531 TCONS_00001277 transcript 880 29.40485236 3.272859e-03 0.040501628 1063 XLOC_000197 TCONS_00000487 transcript 1063 3.12988187 4.555313e-03 0.050108442 35 XLOC_000017 TCONS_00000020 transcript 35 4.38862590 1.085070e-02 0.089518247 results_transcripts[results_transcripts$geneIDs == \"XLOC_000101\", ] A data.frame: 2 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 469 XLOC_000101 TCONS_00000244 transcript 469 119.299999 0.0002398681 0.007915648 477 XLOC_000101 TCONS_00000252 transcript 477 3.128184 0.4511803632 0.902537469 plotMeans('XLOC_000101', bg, groupvar='group', meas='FPKM', colorby='transcript')","title":"Differential expression analysis"},{"location":"BIOI611_ballgown_example/#reference","text":"https://www.bioconductor.org/packages/release/bioc/vignettes/ballgown/inst/doc/ballgown.html","title":"Reference"},{"location":"BIOI611_bulkRNA_SE_ballgown/","text":"Isoform-level differential expression analysis with Ballgown. Install R package if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"ballgown\") Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.19 (BiocManager 1.30.25), R 4.4.1 (2024-06-14) Installing package(s) 'BiocVersion', 'ballgown' also installing the dependencies \u2018plogr\u2019, \u2018png\u2019, \u2018formatR\u2019, \u2018abind\u2019, \u2018SparseArray\u2019, \u2018RSQLite\u2019, \u2018KEGGREST\u2019, \u2018lambda.r\u2019, \u2018futile.options\u2019, \u2018S4Arrays\u2019, \u2018DelayedArray\u2019, \u2018MatrixGenerics\u2019, \u2018AnnotationDbi\u2019, \u2018annotate\u2019, \u2018futile.logger\u2019, \u2018snow\u2019, \u2018BH\u2019, \u2018locfit\u2019, \u2018bitops\u2019, \u2018Rhtslib\u2019, \u2018SummarizedExperiment\u2019, \u2018RCurl\u2019, \u2018rjson\u2019, \u2018BiocGenerics\u2019, \u2018XVector\u2019, \u2018genefilter\u2019, \u2018BiocParallel\u2019, \u2018matrixStats\u2019, \u2018edgeR\u2019, \u2018statmod\u2019, \u2018XML\u2019, \u2018Biostrings\u2019, \u2018zlibbioc\u2019, \u2018Rsamtools\u2019, \u2018GenomicAlignments\u2019, \u2018BiocIO\u2019, \u2018restfulr\u2019, \u2018UCSC.utils\u2019, \u2018GenomeInfoDbData\u2019, \u2018GenomicRanges\u2019, \u2018IRanges\u2019, \u2018S4Vectors\u2019, \u2018sva\u2019, \u2018limma\u2019, \u2018rtracklayer\u2019, \u2018Biobase\u2019, \u2018GenomeInfoDb\u2019 Old packages: 'gtable' library(ballgown) Attaching package: \u2018ballgown\u2019 The following object is masked from \u2018package:base\u2019: structure Please upload your data generated by `tablemaker. Please refer to the section Running Tablemaker the link here for details. You can also download a copy from the path below: /scratch/zt1/project/bioi611/shared/output/bulkRNA_SE_tablemaker.tar.gz Or you can download a copy via the link below: https://umd0-my.sharepoint.com/:u:/g/personal/xie186_umd_edu/EYLz8khnMeRCmyK_YFDDXaQBP_4hzpAgs_nN-TNXghdQMQ?e=5By9ct getwd() '/content' system(\"tar zxvf bulkRNA_SE_tablemaker.tar.gz\") data_directory = file.path(getwd(), \"bulkRNA_SE_tablemaker\") data_directory '/content/bulkRNA_SE_tablemaker' # make the ballgown object: bg = ballgown(dataDir = data_directory, samplePattern='N2_day', meas='all') bg Mon Oct 28 10:28:23 2024 Mon Oct 28 10:28:23 2024: Reading linking tables Mon Oct 28 10:28:24 2024: Reading intron data files Mon Oct 28 10:28:27 2024: Merging intron data Mon Oct 28 10:28:27 2024: Reading exon data files Mon Oct 28 10:28:33 2024: Merging exon data Mon Oct 28 10:28:34 2024: Reading transcript data files Mon Oct 28 10:28:38 2024: Merging transcript data Wrapping up the results Mon Oct 28 10:28:38 2024 ballgown instance with 60032 transcripts and 6 samples Accessing assembly data A ballgown object has six slots: structure, expr, indexes, dirs, mergedDate, and meas. Exon, intron, and transcript structures are easily extracted from the main ballgown object: structure(bg)$exon GRanges object with 178766 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 3747-3909 - | 1 1 [2] I 4116-4358 - | 2 2 [3] I 5195-5296 - | 3 2 [4] I 6037-6327 - | 4 2 [5] I 9727-9846 - | 5 2 ... ... ... ... . ... ... [178762] MtDNA 10348-10401 + | 178762 60028 [178763] MtDNA 10403-11354 + | 178763 60029 [178764] MtDNA 11356-11691 + | 178764 60030 [178765] MtDNA 11691-13272 + | 178765 60031 [178766] MtDNA 13275-13327 + | 178766 60032 ------- seqinfo: 7 sequences from an unspecified genome; no seqlengths structure(bg)$intron GRanges object with 116284 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 4359-5194 - | 1 2 [2] I 5297-6036 - | 2 2 [3] I 6328-9726 - | 3 2 [4] I 9847-10094 - | 4 2 [5] I 11562-11617 + | 5 3:4 ... ... ... ... . ... ... [116280] X 17715112-17716973 + | 116280 59995:59996 [116281] X 17717088-17717170 + | 116281 59995:59996 [116282] X 17717279-17717327 + | 116282 59995:59996 [116283] X 17717444-17718427 + | 116283 59995 [116284] X 17717444-17718434 + | 116284 59996 ------- seqinfo: 6 sequences from an unspecified genome; no seqlengths structure(bg)$trans GRangesList object of length 60032: $`1` GRanges object with 1 range and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 3747-3909 - | 1 1 ------- seqinfo: 7 sequences from an unspecified genome; no seqlengths $`2` GRanges object with 5 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 4116-4358 - | 2 2 [2] I 5195-5296 - | 3 2 [3] I 6037-6327 - | 4 2 [4] I 9727-9846 - | 5 2 [5] I 10095-10230 - | 6 2 ------- seqinfo: 7 sequences from an unspecified genome; no seqlengths $`3` GRanges object with 5 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 11495-11561 + | 7 3:4 [2] I 11618-11689 + | 8 3:5 [3] I 14951-15160 + | 9 3:5 [4] I 16473-16585 + | 10 c(3, 6) [5] I 16702-16793 + | 11 3 ------- seqinfo: 7 sequences from an unspecified genome; no seqlengths ... <60029 more elements> expr The expr slot is a list that contains tables of expression data for the genomic features. These tables are very similar to the *_data.ctab Tablemaker output files. Ballgown implements the following syntax to access components of the expr slot: *expr(ballgown_object_name, <EXPRESSION_MEASUREMENT>) where * is either e for exon, i for intron, t for transcript, or g for gene, and is an expression-measurement column name from the appropriate .ctab file. Gene-level measurements are calculated by aggregating the transcript-level measurements for that gene. All of the following are valid ways to extract expression data from the bg ballgown object: transcript_fpkm = texpr(bg, 'FPKM') transcript_cov = texpr(bg, 'cov') whole_tx_table = texpr(bg, 'all') exon_mcov = eexpr(bg, 'mcov') junction_rcount = iexpr(bg) whole_intron_table = iexpr(bg, 'all') gene_expression = gexpr(bg) Warning message in .normarg_f(f, x): \u201c'NROW(x)' is not a multiple of split factor length\u201d Warning message in tlengths * tmeas: \u201clonger object length is not a multiple of shorter object length\u201d Indexes sampleNames(bg) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1' 'N2_day1_rep2' 'N2_day1_rep3' 'N2_day7_rep1' 'N2_day7_rep2' 'N2_day7_rep3' pData(bg) = data.frame(id=sampleNames(bg), group=rep(c(\"young\",\"old\"), each=3)) pData(bg) A data.frame: 6 \u00d7 2 id group <chr> <chr> N2_day1_rep1 young N2_day1_rep2 young N2_day1_rep3 young N2_day7_rep1 old N2_day7_rep2 old N2_day7_rep3 old Plotting transcript structures plotTranscripts(gene='WBGene00002054', gown=bg, samples='N2_day1_rep1', meas='FPKM', colorby='transcript', main='transcripts from gene XLOC_000454: sample 12, FPKM') It is also possible to plot several samples at once: plotTranscripts('WBGene00002054', bg, samples=c('N2_day1_rep1', 'N2_day7_rep1'), meas='FPKM', colorby='transcript') You can also make side-by-side plots comparing mean abundances between groups (here, 0 and 1): plotMeans('WBGene00002054', bg, groupvar='group', meas='FPKM', colorby='transcript') Differential expression analysis Ballgown provides a wide selection of simple, fast statistical methods for testing whether transcripts are differentially expressed between experimental conditions or across a continuous covariate (such as time). stat_results = stattest(bg, feature='transcript', meas='FPKM', covariate='group', getFC=TRUE) results_transcripts <- data.frame(geneNames = geneNames(bg), geneIDs = geneIDs(bg), transcriptNames = transcriptNames(bg), stat_results) head(results_transcripts) A data.frame: 6 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 1 Y74C9A.6 WBGene00023193 Y74C9A.6 transcript 1 0.3087935 0.313759448 0.52196762 2 homt-1 WBGene00022277 Y74C9A.3.1 transcript 2 0.6960674 0.006886113 0.08724496 3 nlp-40 WBGene00022276 Y74C9A.2a.3 transcript 3 0.9999961 0.948535319 0.96924051 4 nlp-40 WBGene00022276 Y74C9A.2a.1 transcript 4 0.4248382 0.040862773 0.16836530 5 nlp-40 WBGene00022276 Y74C9A.2a.2 transcript 5 4.8007011 0.050336942 0.18664213 6 nlp-40 WBGene00022276 Y74C9A.2b.1 transcript 6 0.6299300 0.112477785 0.29368625 results_transcripts <- results_transcripts[order(results_transcripts$qval), ] head(results_transcripts, 10) A data.frame: 10 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 1940 F48C1.8 WBGene00018600 F48C1.8.1 transcript 1940 2.1012606 5.213184e-06 0.01647351 3643 F32H2.15 WBGene00284858 F32H2.15 transcript 3643 0.1912040 1.087705e-06 0.01647351 3811 lin-41 WBGene00003026 C12C8.3a.1 transcript 3811 12.1472453 2.940965e-06 0.01647351 6887 WBGene00044425 F54D12.11 transcript 6887 0.8775027 7.411872e-06 0.01647351 8957 ifb-2 WBGene00002054 F10C1.7a.1 transcript 8957 4.5625027 1.180041e-06 0.01647351 20015 Y69A2AR.28 WBGene00022099 Y69A2AR.28.1 transcript 20015 0.6076403 7.905547e-06 0.01647351 20798 str-185 WBGene00006228 R08C7.7.1 transcript 20798 0.9668631 8.516315e-06 0.01647351 23441 unc-44 WBGene00006780 B0350.2a.1 transcript 23441 3.3319026 5.919439e-06 0.01647351 25280 plp-1 WBGene00004046 F45E4.2.1 transcript 25280 0.7053267 7.087841e-06 0.01647351 25710 WBGene00023488 T26A8.5 transcript 25710 0.9632862 8.470675e-06 0.01647351 results_transcripts[results_transcripts$geneIDs == \"WBGene00002054\", ] A data.frame: 3 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 8957 ifb-2 WBGene00002054 F10C1.7a.1 transcript 8957 4.562503 1.180041e-06 0.01647351 8956 ifb-2 WBGene00002054 F10C1.7c.1 transcript 8956 3.554543 3.838807e-04 0.04612121 8958 ifb-2 WBGene00002054 F10C1.7e.1 transcript 8958 1.009672 8.838138e-01 0.93058010 plotMeans('WBGene00002054', bg, groupvar='group', meas='FPKM', colorby='transcript') write.csv(results_transcripts, file = \"BIOI611_bulkRNA_SE_ballgown.csv\", row.names = FALSE) sessionInfo() R version 4.4.1 (2024-06-14) Platform: x86_64-pc-linux-gnu Running under: Ubuntu 22.04.3 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so; LAPACK version 3.10.0 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C time zone: Etc/UTC tzcode source: system (glibc) attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] ballgown_2.36.0 loaded via a namespace (and not attached): [1] IRdisplay_1.1 blob_1.2.4 [3] Biostrings_2.72.1 bitops_1.0-9 [5] fastmap_1.2.0 RCurl_1.98-1.16 [7] GenomicAlignments_1.40.0 XML_3.99-0.17 [9] digest_0.6.37 lifecycle_1.0.4 [11] survival_3.7-0 statmod_1.5.0 [13] KEGGREST_1.44.1 RSQLite_2.3.7 [15] genefilter_1.86.0 compiler_4.4.1 [17] rlang_1.1.4 tools_4.4.1 [19] utf8_1.2.4 yaml_2.3.10 [21] rtracklayer_1.64.0 S4Arrays_1.4.1 [23] bit_4.5.0 curl_5.2.3 [25] DelayedArray_0.30.1 repr_1.1.7 [27] RColorBrewer_1.1-3 abind_1.4-8 [29] BiocParallel_1.38.0 pbdZMQ_0.3-13 [31] BiocGenerics_0.50.0 grid_4.4.1 [33] stats4_4.4.1 fansi_1.0.6 [35] xtable_1.8-4 edgeR_4.2.2 [37] SummarizedExperiment_1.34.0 cli_3.6.3 [39] crayon_1.5.3 httr_1.4.7 [41] rjson_0.2.23 DBI_1.2.3 [43] cachem_1.1.0 zlibbioc_1.50.0 [45] splines_4.4.1 parallel_4.4.1 [47] AnnotationDbi_1.66.0 BiocManager_1.30.25 [49] XVector_0.44.0 restfulr_0.0.15 [51] matrixStats_1.4.1 base64enc_0.1-3 [53] vctrs_0.6.5 Matrix_1.7-1 [55] jsonlite_1.8.9 sva_3.52.0 [57] IRanges_2.38.1 S4Vectors_0.42.1 [59] bit64_4.5.2 locfit_1.5-9.10 [61] limma_3.60.6 annotate_1.82.0 [63] glue_1.8.0 codetools_0.2-20 [65] GenomeInfoDb_1.40.1 BiocIO_1.14.0 [67] GenomicRanges_1.56.2 UCSC.utils_1.0.0 [69] pillar_1.9.0 htmltools_0.5.8.1 [71] IRkernel_1.3.2 GenomeInfoDbData_1.2.12 [73] R6_2.5.1 evaluate_1.0.1 [75] lattice_0.22-6 Biobase_2.64.0 [77] png_0.1-8 Rsamtools_2.20.0 [79] memoise_2.0.1 Rcpp_1.0.13 [81] uuid_1.2-1 SparseArray_1.4.8 [83] nlme_3.1-166 mgcv_1.9-1 [85] MatrixGenerics_1.16.0 Reference https://www.bioconductor.org/packages/release/bioc/vignettes/ballgown/inst/doc/ballgown.html","title":"DE analysis at isoform-leve using ballgown (C. ele data)"},{"location":"BIOI611_bulkRNA_SE_ballgown/#isoform-level-differential-expression-analysis-with-ballgown","text":"","title":"Isoform-level differential expression analysis with Ballgown."},{"location":"BIOI611_bulkRNA_SE_ballgown/#install-r-package","text":"if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"ballgown\") Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.19 (BiocManager 1.30.25), R 4.4.1 (2024-06-14) Installing package(s) 'BiocVersion', 'ballgown' also installing the dependencies \u2018plogr\u2019, \u2018png\u2019, \u2018formatR\u2019, \u2018abind\u2019, \u2018SparseArray\u2019, \u2018RSQLite\u2019, \u2018KEGGREST\u2019, \u2018lambda.r\u2019, \u2018futile.options\u2019, \u2018S4Arrays\u2019, \u2018DelayedArray\u2019, \u2018MatrixGenerics\u2019, \u2018AnnotationDbi\u2019, \u2018annotate\u2019, \u2018futile.logger\u2019, \u2018snow\u2019, \u2018BH\u2019, \u2018locfit\u2019, \u2018bitops\u2019, \u2018Rhtslib\u2019, \u2018SummarizedExperiment\u2019, \u2018RCurl\u2019, \u2018rjson\u2019, \u2018BiocGenerics\u2019, \u2018XVector\u2019, \u2018genefilter\u2019, \u2018BiocParallel\u2019, \u2018matrixStats\u2019, \u2018edgeR\u2019, \u2018statmod\u2019, \u2018XML\u2019, \u2018Biostrings\u2019, \u2018zlibbioc\u2019, \u2018Rsamtools\u2019, \u2018GenomicAlignments\u2019, \u2018BiocIO\u2019, \u2018restfulr\u2019, \u2018UCSC.utils\u2019, \u2018GenomeInfoDbData\u2019, \u2018GenomicRanges\u2019, \u2018IRanges\u2019, \u2018S4Vectors\u2019, \u2018sva\u2019, \u2018limma\u2019, \u2018rtracklayer\u2019, \u2018Biobase\u2019, \u2018GenomeInfoDb\u2019 Old packages: 'gtable' library(ballgown) Attaching package: \u2018ballgown\u2019 The following object is masked from \u2018package:base\u2019: structure Please upload your data generated by `tablemaker. Please refer to the section Running Tablemaker the link here for details. You can also download a copy from the path below: /scratch/zt1/project/bioi611/shared/output/bulkRNA_SE_tablemaker.tar.gz Or you can download a copy via the link below: https://umd0-my.sharepoint.com/:u:/g/personal/xie186_umd_edu/EYLz8khnMeRCmyK_YFDDXaQBP_4hzpAgs_nN-TNXghdQMQ?e=5By9ct getwd() '/content' system(\"tar zxvf bulkRNA_SE_tablemaker.tar.gz\") data_directory = file.path(getwd(), \"bulkRNA_SE_tablemaker\") data_directory '/content/bulkRNA_SE_tablemaker' # make the ballgown object: bg = ballgown(dataDir = data_directory, samplePattern='N2_day', meas='all') bg Mon Oct 28 10:28:23 2024 Mon Oct 28 10:28:23 2024: Reading linking tables Mon Oct 28 10:28:24 2024: Reading intron data files Mon Oct 28 10:28:27 2024: Merging intron data Mon Oct 28 10:28:27 2024: Reading exon data files Mon Oct 28 10:28:33 2024: Merging exon data Mon Oct 28 10:28:34 2024: Reading transcript data files Mon Oct 28 10:28:38 2024: Merging transcript data Wrapping up the results Mon Oct 28 10:28:38 2024 ballgown instance with 60032 transcripts and 6 samples","title":"Install R package"},{"location":"BIOI611_bulkRNA_SE_ballgown/#accessing-assembly-data","text":"A ballgown object has six slots: structure, expr, indexes, dirs, mergedDate, and meas. Exon, intron, and transcript structures are easily extracted from the main ballgown object: structure(bg)$exon GRanges object with 178766 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 3747-3909 - | 1 1 [2] I 4116-4358 - | 2 2 [3] I 5195-5296 - | 3 2 [4] I 6037-6327 - | 4 2 [5] I 9727-9846 - | 5 2 ... ... ... ... . ... ... [178762] MtDNA 10348-10401 + | 178762 60028 [178763] MtDNA 10403-11354 + | 178763 60029 [178764] MtDNA 11356-11691 + | 178764 60030 [178765] MtDNA 11691-13272 + | 178765 60031 [178766] MtDNA 13275-13327 + | 178766 60032 ------- seqinfo: 7 sequences from an unspecified genome; no seqlengths structure(bg)$intron GRanges object with 116284 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 4359-5194 - | 1 2 [2] I 5297-6036 - | 2 2 [3] I 6328-9726 - | 3 2 [4] I 9847-10094 - | 4 2 [5] I 11562-11617 + | 5 3:4 ... ... ... ... . ... ... [116280] X 17715112-17716973 + | 116280 59995:59996 [116281] X 17717088-17717170 + | 116281 59995:59996 [116282] X 17717279-17717327 + | 116282 59995:59996 [116283] X 17717444-17718427 + | 116283 59995 [116284] X 17717444-17718434 + | 116284 59996 ------- seqinfo: 6 sequences from an unspecified genome; no seqlengths structure(bg)$trans GRangesList object of length 60032: $`1` GRanges object with 1 range and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 3747-3909 - | 1 1 ------- seqinfo: 7 sequences from an unspecified genome; no seqlengths $`2` GRanges object with 5 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 4116-4358 - | 2 2 [2] I 5195-5296 - | 3 2 [3] I 6037-6327 - | 4 2 [4] I 9727-9846 - | 5 2 [5] I 10095-10230 - | 6 2 ------- seqinfo: 7 sequences from an unspecified genome; no seqlengths $`3` GRanges object with 5 ranges and 2 metadata columns: seqnames ranges strand | id transcripts <Rle> <IRanges> <Rle> | <integer> <character> [1] I 11495-11561 + | 7 3:4 [2] I 11618-11689 + | 8 3:5 [3] I 14951-15160 + | 9 3:5 [4] I 16473-16585 + | 10 c(3, 6) [5] I 16702-16793 + | 11 3 ------- seqinfo: 7 sequences from an unspecified genome; no seqlengths ... <60029 more elements>","title":"Accessing assembly data"},{"location":"BIOI611_bulkRNA_SE_ballgown/#expr","text":"The expr slot is a list that contains tables of expression data for the genomic features. These tables are very similar to the *_data.ctab Tablemaker output files. Ballgown implements the following syntax to access components of the expr slot: *expr(ballgown_object_name, <EXPRESSION_MEASUREMENT>) where * is either e for exon, i for intron, t for transcript, or g for gene, and is an expression-measurement column name from the appropriate .ctab file. Gene-level measurements are calculated by aggregating the transcript-level measurements for that gene. All of the following are valid ways to extract expression data from the bg ballgown object: transcript_fpkm = texpr(bg, 'FPKM') transcript_cov = texpr(bg, 'cov') whole_tx_table = texpr(bg, 'all') exon_mcov = eexpr(bg, 'mcov') junction_rcount = iexpr(bg) whole_intron_table = iexpr(bg, 'all') gene_expression = gexpr(bg) Warning message in .normarg_f(f, x): \u201c'NROW(x)' is not a multiple of split factor length\u201d Warning message in tlengths * tmeas: \u201clonger object length is not a multiple of shorter object length\u201d","title":"expr"},{"location":"BIOI611_bulkRNA_SE_ballgown/#indexes","text":"sampleNames(bg) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1' 'N2_day1_rep2' 'N2_day1_rep3' 'N2_day7_rep1' 'N2_day7_rep2' 'N2_day7_rep3' pData(bg) = data.frame(id=sampleNames(bg), group=rep(c(\"young\",\"old\"), each=3)) pData(bg) A data.frame: 6 \u00d7 2 id group <chr> <chr> N2_day1_rep1 young N2_day1_rep2 young N2_day1_rep3 young N2_day7_rep1 old N2_day7_rep2 old N2_day7_rep3 old","title":"Indexes"},{"location":"BIOI611_bulkRNA_SE_ballgown/#plotting-transcript-structures","text":"plotTranscripts(gene='WBGene00002054', gown=bg, samples='N2_day1_rep1', meas='FPKM', colorby='transcript', main='transcripts from gene XLOC_000454: sample 12, FPKM') It is also possible to plot several samples at once: plotTranscripts('WBGene00002054', bg, samples=c('N2_day1_rep1', 'N2_day7_rep1'), meas='FPKM', colorby='transcript') You can also make side-by-side plots comparing mean abundances between groups (here, 0 and 1): plotMeans('WBGene00002054', bg, groupvar='group', meas='FPKM', colorby='transcript')","title":"Plotting transcript structures"},{"location":"BIOI611_bulkRNA_SE_ballgown/#differential-expression-analysis","text":"Ballgown provides a wide selection of simple, fast statistical methods for testing whether transcripts are differentially expressed between experimental conditions or across a continuous covariate (such as time). stat_results = stattest(bg, feature='transcript', meas='FPKM', covariate='group', getFC=TRUE) results_transcripts <- data.frame(geneNames = geneNames(bg), geneIDs = geneIDs(bg), transcriptNames = transcriptNames(bg), stat_results) head(results_transcripts) A data.frame: 6 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 1 Y74C9A.6 WBGene00023193 Y74C9A.6 transcript 1 0.3087935 0.313759448 0.52196762 2 homt-1 WBGene00022277 Y74C9A.3.1 transcript 2 0.6960674 0.006886113 0.08724496 3 nlp-40 WBGene00022276 Y74C9A.2a.3 transcript 3 0.9999961 0.948535319 0.96924051 4 nlp-40 WBGene00022276 Y74C9A.2a.1 transcript 4 0.4248382 0.040862773 0.16836530 5 nlp-40 WBGene00022276 Y74C9A.2a.2 transcript 5 4.8007011 0.050336942 0.18664213 6 nlp-40 WBGene00022276 Y74C9A.2b.1 transcript 6 0.6299300 0.112477785 0.29368625 results_transcripts <- results_transcripts[order(results_transcripts$qval), ] head(results_transcripts, 10) A data.frame: 10 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 1940 F48C1.8 WBGene00018600 F48C1.8.1 transcript 1940 2.1012606 5.213184e-06 0.01647351 3643 F32H2.15 WBGene00284858 F32H2.15 transcript 3643 0.1912040 1.087705e-06 0.01647351 3811 lin-41 WBGene00003026 C12C8.3a.1 transcript 3811 12.1472453 2.940965e-06 0.01647351 6887 WBGene00044425 F54D12.11 transcript 6887 0.8775027 7.411872e-06 0.01647351 8957 ifb-2 WBGene00002054 F10C1.7a.1 transcript 8957 4.5625027 1.180041e-06 0.01647351 20015 Y69A2AR.28 WBGene00022099 Y69A2AR.28.1 transcript 20015 0.6076403 7.905547e-06 0.01647351 20798 str-185 WBGene00006228 R08C7.7.1 transcript 20798 0.9668631 8.516315e-06 0.01647351 23441 unc-44 WBGene00006780 B0350.2a.1 transcript 23441 3.3319026 5.919439e-06 0.01647351 25280 plp-1 WBGene00004046 F45E4.2.1 transcript 25280 0.7053267 7.087841e-06 0.01647351 25710 WBGene00023488 T26A8.5 transcript 25710 0.9632862 8.470675e-06 0.01647351 results_transcripts[results_transcripts$geneIDs == \"WBGene00002054\", ] A data.frame: 3 \u00d7 8 geneNames geneIDs transcriptNames feature id fc pval qval <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl> 8957 ifb-2 WBGene00002054 F10C1.7a.1 transcript 8957 4.562503 1.180041e-06 0.01647351 8956 ifb-2 WBGene00002054 F10C1.7c.1 transcript 8956 3.554543 3.838807e-04 0.04612121 8958 ifb-2 WBGene00002054 F10C1.7e.1 transcript 8958 1.009672 8.838138e-01 0.93058010 plotMeans('WBGene00002054', bg, groupvar='group', meas='FPKM', colorby='transcript') write.csv(results_transcripts, file = \"BIOI611_bulkRNA_SE_ballgown.csv\", row.names = FALSE) sessionInfo() R version 4.4.1 (2024-06-14) Platform: x86_64-pc-linux-gnu Running under: Ubuntu 22.04.3 LTS Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so; LAPACK version 3.10.0 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C time zone: Etc/UTC tzcode source: system (glibc) attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] ballgown_2.36.0 loaded via a namespace (and not attached): [1] IRdisplay_1.1 blob_1.2.4 [3] Biostrings_2.72.1 bitops_1.0-9 [5] fastmap_1.2.0 RCurl_1.98-1.16 [7] GenomicAlignments_1.40.0 XML_3.99-0.17 [9] digest_0.6.37 lifecycle_1.0.4 [11] survival_3.7-0 statmod_1.5.0 [13] KEGGREST_1.44.1 RSQLite_2.3.7 [15] genefilter_1.86.0 compiler_4.4.1 [17] rlang_1.1.4 tools_4.4.1 [19] utf8_1.2.4 yaml_2.3.10 [21] rtracklayer_1.64.0 S4Arrays_1.4.1 [23] bit_4.5.0 curl_5.2.3 [25] DelayedArray_0.30.1 repr_1.1.7 [27] RColorBrewer_1.1-3 abind_1.4-8 [29] BiocParallel_1.38.0 pbdZMQ_0.3-13 [31] BiocGenerics_0.50.0 grid_4.4.1 [33] stats4_4.4.1 fansi_1.0.6 [35] xtable_1.8-4 edgeR_4.2.2 [37] SummarizedExperiment_1.34.0 cli_3.6.3 [39] crayon_1.5.3 httr_1.4.7 [41] rjson_0.2.23 DBI_1.2.3 [43] cachem_1.1.0 zlibbioc_1.50.0 [45] splines_4.4.1 parallel_4.4.1 [47] AnnotationDbi_1.66.0 BiocManager_1.30.25 [49] XVector_0.44.0 restfulr_0.0.15 [51] matrixStats_1.4.1 base64enc_0.1-3 [53] vctrs_0.6.5 Matrix_1.7-1 [55] jsonlite_1.8.9 sva_3.52.0 [57] IRanges_2.38.1 S4Vectors_0.42.1 [59] bit64_4.5.2 locfit_1.5-9.10 [61] limma_3.60.6 annotate_1.82.0 [63] glue_1.8.0 codetools_0.2-20 [65] GenomeInfoDb_1.40.1 BiocIO_1.14.0 [67] GenomicRanges_1.56.2 UCSC.utils_1.0.0 [69] pillar_1.9.0 htmltools_0.5.8.1 [71] IRkernel_1.3.2 GenomeInfoDbData_1.2.12 [73] R6_2.5.1 evaluate_1.0.1 [75] lattice_0.22-6 Biobase_2.64.0 [77] png_0.1-8 Rsamtools_2.20.0 [79] memoise_2.0.1 Rcpp_1.0.13 [81] uuid_1.2-1 SparseArray_1.4.8 [83] nlme_3.1-166 mgcv_1.9-1 [85] MatrixGenerics_1.16.0","title":"Differential expression analysis"},{"location":"BIOI611_bulkRNA_SE_ballgown/#reference","text":"https://www.bioconductor.org/packages/release/bioc/vignettes/ballgown/inst/doc/ballgown.html","title":"Reference"},{"location":"BIOI611_introR/","text":"Introduction to R What is R R is a language and environment for statistical computing and graphics. Runs on a variaty of operation systerms: Windows, Linux and MacOS Generates publication-ready plots Owns a large open-source community Extends functions as packages Essetnial concepts for programming languages Variables Variable names can have letters, dots and undercores (e.g. gene_name , \"csvfile.1\" and chr1 ). Functions A function is a structured, reusable segment of code designed to carry out a specific set of operations. It can accept zero or more inputs (parameters) and can produce an output (result). INPUT --function--> OUTPUT The way to define a function is: read_star_file <- function(file_path){ ...code goes here... return(df) } The way to use a function in R is: read_star_file(paths) Basic data types # assign a number to variable gene_count gene1 <- 150 gene2 <- 200 gene1 gene2 150 200 # Examples of character value gene_name1 <- \"KRAS\" gene_name1 'KRAS' # Examples of character value \"RAS\" -> gene_name2 gene_name2 'RAS' # Examples of character value gene_name3 <- \"KRAS\" gene_name3 'KRAS' # Logical value gene1 > gene2 gene1 < gene2 bool_val = gene1 < gene2 bool_val FALSE TRUE TRUE class(gene1) class(gene_name) class() 'numeric' 'character' Basic data structure An atomic vector is a collection of multiple values (numeric, character, or logical) stored in a single object. You can create an atomic vector using the c() function. sample_names <- c(\"N2_day1_rep1\", \"N2_day1_rep2\", \"N2_day1_rep3\", \"N2_day7_rep1\", \"N2_day7_rep2\", \"N2_day7_rep3\") sample_names .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1' 'N2_day1_rep2' 'N2_day1_rep3' 'N2_day7_rep1' 'N2_day7_rep2' 'N2_day7_rep3' group <- gsub(\"_rep\\\\d\", \"\", sample_names) group .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1' 'N2_day1' 'N2_day1' 'N2_day7' 'N2_day7' 'N2_day7' rep <- gsub(\"N2_day\\\\d_rep\", \"\", sample_names) rep .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '1' '2' '3' '1' '2' '3' coldata_df <- cbind(group = gsub(\"_rep\\\\d\", \"\", sample_names)) coldata_df A matrix: 6 \u00d7 1 of type chr group N2_day1 N2_day1 N2_day1 N2_day7 N2_day7 N2_day7 coldata_df <- cbind(group = gsub(\"_rep\\\\d\", \"\", sample_names), rep = gsub(\"N2_day\\\\d_rep\", \"\", sample_names)) coldata_df A matrix: 6 \u00d7 2 of type chr group rep N2_day1 1 N2_day1 2 N2_day1 3 N2_day7 1 N2_day7 2 N2_day7 3 rownames(coldata_df) NULL rownames(coldata_df) = sample_names coldata_df A matrix: 6 \u00d7 2 of type chr group rep N2_day1_rep1 N2_day1 1 N2_day1_rep2 N2_day1 2 N2_day1_rep3 N2_day1 3 N2_day7_rep1 N2_day7 1 N2_day7_rep2 N2_day7 2 N2_day7_rep3 N2_day7 3 t(coldata_df) A matrix: 2 \u00d7 6 of type chr N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 group N2_day1 N2_day1 N2_day1 N2_day7 N2_day7 N2_day7 rep 1 2 3 1 2 3 is.matrix(coldata_df) coldata_df <- as.data.frame(coldata_df) is.data.frame(coldata_df) TRUE TRUE A matrix can contain either character or numeric columns and a dataframe can contain both numeric and character columns. A list is an ordered collection of objects, which can be any type of R objects (vectors, matrices, data frames, even lists). count_files = list(\"sample\" = 'N2_day1_rep1.ReadsPerGene.out.tab', \"sample2\"='N2_day1_rep2.ReadsPerGene.out.tab') count_files $sample 'N2_day1_rep1.ReadsPerGene.out.tab' $sample2 'N2_day1_rep2.ReadsPerGene.out.tab' gene_count = list(\"gene1\" = 10, \"gene2\"=20) lapply(gene_count, function(x){log2(x+1)}) $gene1 3.4594316186373 $gene2 4.39231742277876 log2_transform <- function(x){ log2(x+1) } lapply(gene_count, log2_transform) $gene1 3.4594316186373 $gene2 4.39231742277876 Dealing with text files getwd() #setwd() '/content' list.files() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1.ReadsPerGene.out.tab' 'N2_day1_rep2.ReadsPerGene.out.tab' 'N2_day1_rep3.ReadsPerGene.out.tab' 'N2_day7_rep1.ReadsPerGene.out.tab' 'N2_day7_rep2.ReadsPerGene.out.tab' 'N2_day7_rep3.ReadsPerGene.out.tab' 'sample_data' file_paths <- list.files(pattern = \"*..ReadsPerGene.out.tab\") file_paths .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1.ReadsPerGene.out.tab' 'N2_day1_rep2.ReadsPerGene.out.tab' 'N2_day1_rep3.ReadsPerGene.out.tab' 'N2_day7_rep1.ReadsPerGene.out.tab' 'N2_day7_rep2.ReadsPerGene.out.tab' 'N2_day7_rep3.ReadsPerGene.out.tab' tab_N2_day1_rep1 <- read.table('N2_day1_rep1.ReadsPerGene.out.tab') head(tab_N2_day1_rep1, 5) A data.frame: 5 \u00d7 4 V1 V2 V3 V4 <chr> <int> <int> <int> 1 N_unmapped 1332776 1332776 1332776 2 N_multimapping 1540190 1540190 1540190 3 N_noFeature 157102 19017455 18933214 4 N_ambiguous 536422 128854 120342 5 WBGene00000003 341 161 180 tab_N2_day1_rep2 <- read.table('N2_day1_rep2.ReadsPerGene.out.tab') head(tab_N2_day1_rep2,5) A data.frame: 5 \u00d7 4 V1 V2 V3 V4 <chr> <int> <int> <int> 1 N_unmapped 1400596 1400596 1400596 2 N_multimapping 1305129 1305129 1305129 3 N_noFeature 152183 15009786 14975925 4 N_ambiguous 439830 104631 98489 5 WBGene00000003 415 198 217 tab_N2_day1_rep3 <- read.table('N2_day1_rep3.ReadsPerGene.out.tab') head(tab_N2_day1_rep3,5) A data.frame: 5 \u00d7 4 V1 V2 V3 V4 <chr> <int> <int> <int> 1 N_unmapped 5887223 5887223 5887223 2 N_multimapping 1557570 1557570 1557570 3 N_noFeature 184441 17612359 17574940 4 N_ambiguous 514559 122385 115498 5 WBGene00000003 411 175 236 library(dplyr) Attaching package: \u2018dplyr\u2019 The following objects are masked from \u2018package:stats\u2019: filter, lag The following objects are masked from \u2018package:base\u2019: intersect, setdiff, setequal, union tab_N2_day1_rep1 <- tab_N2_day1_rep1 %>% select(V1, V2) head(tab_N2_day1_rep1, 5) tab_N2_day1_rep2 <- tab_N2_day1_rep2[, c(\"V1\", \"V2\")] head(tab_N2_day1_rep2, 5) tab_N2_day1_rep3 <- tab_N2_day1_rep3[, c(\"V1\", \"V2\")] head(tab_N2_day1_rep3, 5) A data.frame: 5 \u00d7 2 V1 V2 <chr> <int> 1 N_unmapped 1332776 2 N_multimapping 1540190 3 N_noFeature 157102 4 N_ambiguous 536422 5 WBGene00000003 341 A data.frame: 5 \u00d7 2 V1 V2 <chr> <int> 1 N_unmapped 1400596 2 N_multimapping 1305129 3 N_noFeature 152183 4 N_ambiguous 439830 5 WBGene00000003 415 A data.frame: 5 \u00d7 2 V1 V2 <chr> <int> 1 N_unmapped 5887223 2 N_multimapping 1557570 3 N_noFeature 184441 4 N_ambiguous 514559 5 WBGene00000003 411 df_merged <- merge(tab_N2_day1_rep1, tab_N2_day1_rep2, by = \"V1\") head(df_merged) df_merged <- merge(df_merged, tab_N2_day1_rep3, by = \"V1\") head(df_merged) A data.frame: 6 \u00d7 3 V1 V2.x V2.y <chr> <int> <int> 1 N_ambiguous 536422 439830 2 N_multimapping 1540190 1305129 3 N_noFeature 157102 152183 4 N_unmapped 1332776 1400596 5 WBGene00000001 3227 2168 6 WBGene00000002 270 203 A data.frame: 6 \u00d7 4 V1 V2.x V2.y V2 <chr> <int> <int> <int> 1 N_ambiguous 536422 439830 514559 2 N_multimapping 1540190 1305129 1557570 3 N_noFeature 157102 152183 184441 4 N_unmapped 1332776 1400596 5887223 5 WBGene00000001 3227 2168 2589 6 WBGene00000002 270 203 266 The Reduce() function in R allows us to apply a function repeatedly to a list of elements. Here, we are applying merge() iteratively to a list of data frames. df_mer_red <- Reduce(function(x, y) merge(x, y, by = \"V1\"), list(\"tab_N2_day1_rep1\" = tab_N2_day1_rep1, \"tab_N2_day1_rep2\" = tab_N2_day1_rep2, \"tab_N2_day1_rep3\" = tab_N2_day1_rep3)) head(df_mer_red, 5) A data.frame: 5 \u00d7 4 V1 V2.x V2.y V2 <chr> <int> <int> <int> 1 N_ambiguous 536422 439830 514559 2 N_multimapping 1540190 1305129 1557570 3 N_noFeature 157102 152183 184441 4 N_unmapped 1332776 1400596 5887223 5 WBGene00000001 3227 2168 2589 Producing Graphs with R Producing Graphs using basic Line charts # Define the cars vector with 5 values cars <- c(1, 3, 6, 4, 9) # Graph the cars vector with all defaults plot(cars) Let's add a title, a line to connect the points, and some color: # Define the cars vector with 5 values cars <- c(1, 3, 6, 4, 9) # Graph cars using blue points overlayed by a line plot(cars, type=\"o\", col=\"blue\") # Create a title with a red, bold/italic font title(main=\"Autos\", col.main=\"red\", font.main=4) # Define 2 vectors cars <- c(1, 3, 6, 4, 9) trucks <- c(2, 5, 4, 5, 12) # Graph cars using a y axis that ranges from 0 to 12 plot(cars, type=\"o\", col=\"blue\", ylim=c(0,12)) # Graph trucks with red dashed line and square points lines(trucks, type=\"o\", pch=22, lty=2, col=\"red\") # Create a title with a red, bold/italic font title(main=\"Autos\", col.main=\"red\", font.main=4) csv_url <- \"https://gist.githubusercontent.com/seankross/a412dfbd88b3db70b74b/raw/5f23f993cd87c283ce766e7ac6b329ee7cc2e1d1/mtcars.csv\" mtcars <- read.csv(csv_url) mtcars A data.frame: 32 \u00d7 12 model mpg cyl disp hp drat wt qsec vs am gear carb <chr> <dbl> <int> <dbl> <int> <dbl> <dbl> <dbl> <int> <int> <int> <int> Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 plot(mtcars$wt,mtcars$mpg, main=\"Scatterplot in Base R\", xlab=\"Car Weight\", ylab=\"MPG\", pch=4, col = \"blue\", lwd=1, cex = 2) abline(lm(mtcars$mpg~mtcars$wt), col=\"red\") text(mtcars$wt, mtcars$mpg, labels=rownames(mtcars), cex=0.5, font=2) hist(mtcars$hp, prob = TRUE) lines(density(mtcars$hp), # density plot lwd = 2, # thickness of line col = \"red\") abline(v=mean(mtcars$hp), lty=\"dashed\", col=\"blue\") Probability Density : It tells you how the data is distributed over different ranges (or bins) of values. The height of each bar shows how densely the data is packed in that range of horsepower values. Producing graphs using ggplot2 library(ggplot2) ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point(size=5, shape=4, color=\"blue\", stroke=1) + geom_smooth(method=lm, color=\"red\") + ggtitle(\"Scatterplot in ggplot2\") + xlab(\"Car Weight\") + # for the x axis label geom_text(label=rownames(mtcars),cex=3) \u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x' ggplot(mtcars, aes(x = hp)) + geom_histogram(aes(y = ..density..), bins = 6, # You can adjust the number of bins fill = \"lightblue\", color = \"black\") + # Histogram with probability density geom_density(color = \"red\", size = 1.5) + # Add the density plot geom_vline(aes(xintercept = mean(hp)), linetype = \"dashed\", color = \"blue\", size = 1.2) + # Add dashed blue vertical line at the mean labs(title = \"Distribution of Horsepower in mtcars Dataset\", x = \"Horsepower\", y = \"Density\") + # Add axis labels and title theme_minimal() # Use a clean theme for the plot Reference https://sites.harding.edu/fmccown/R/ https://jtr13.github.io/cc21fall2/base-r-vs.-ggplot2-visualization.html#base-r-vs.-ggplot2-visualization","title":"Minimal R Introduction"},{"location":"BIOI611_introR/#introduction-to-r","text":"","title":"Introduction to R"},{"location":"BIOI611_introR/#what-is-r","text":"R is a language and environment for statistical computing and graphics. Runs on a variaty of operation systerms: Windows, Linux and MacOS Generates publication-ready plots Owns a large open-source community Extends functions as packages","title":"What is R"},{"location":"BIOI611_introR/#essetnial-concepts-for-programming-languages","text":"","title":"Essetnial concepts for programming languages"},{"location":"BIOI611_introR/#variables","text":"Variable names can have letters, dots and undercores (e.g. gene_name , \"csvfile.1\" and chr1 ).","title":"Variables"},{"location":"BIOI611_introR/#functions","text":"A function is a structured, reusable segment of code designed to carry out a specific set of operations. It can accept zero or more inputs (parameters) and can produce an output (result). INPUT --function--> OUTPUT The way to define a function is: read_star_file <- function(file_path){ ...code goes here... return(df) } The way to use a function in R is: read_star_file(paths)","title":"Functions"},{"location":"BIOI611_introR/#basic-data-types","text":"# assign a number to variable gene_count gene1 <- 150 gene2 <- 200 gene1 gene2 150 200 # Examples of character value gene_name1 <- \"KRAS\" gene_name1 'KRAS' # Examples of character value \"RAS\" -> gene_name2 gene_name2 'RAS' # Examples of character value gene_name3 <- \"KRAS\" gene_name3 'KRAS' # Logical value gene1 > gene2 gene1 < gene2 bool_val = gene1 < gene2 bool_val FALSE TRUE TRUE class(gene1) class(gene_name) class() 'numeric' 'character'","title":"Basic data types"},{"location":"BIOI611_introR/#basic-data-structure","text":"An atomic vector is a collection of multiple values (numeric, character, or logical) stored in a single object. You can create an atomic vector using the c() function. sample_names <- c(\"N2_day1_rep1\", \"N2_day1_rep2\", \"N2_day1_rep3\", \"N2_day7_rep1\", \"N2_day7_rep2\", \"N2_day7_rep3\") sample_names .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1' 'N2_day1_rep2' 'N2_day1_rep3' 'N2_day7_rep1' 'N2_day7_rep2' 'N2_day7_rep3' group <- gsub(\"_rep\\\\d\", \"\", sample_names) group .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1' 'N2_day1' 'N2_day1' 'N2_day7' 'N2_day7' 'N2_day7' rep <- gsub(\"N2_day\\\\d_rep\", \"\", sample_names) rep .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '1' '2' '3' '1' '2' '3' coldata_df <- cbind(group = gsub(\"_rep\\\\d\", \"\", sample_names)) coldata_df A matrix: 6 \u00d7 1 of type chr group N2_day1 N2_day1 N2_day1 N2_day7 N2_day7 N2_day7 coldata_df <- cbind(group = gsub(\"_rep\\\\d\", \"\", sample_names), rep = gsub(\"N2_day\\\\d_rep\", \"\", sample_names)) coldata_df A matrix: 6 \u00d7 2 of type chr group rep N2_day1 1 N2_day1 2 N2_day1 3 N2_day7 1 N2_day7 2 N2_day7 3 rownames(coldata_df) NULL rownames(coldata_df) = sample_names coldata_df A matrix: 6 \u00d7 2 of type chr group rep N2_day1_rep1 N2_day1 1 N2_day1_rep2 N2_day1 2 N2_day1_rep3 N2_day1 3 N2_day7_rep1 N2_day7 1 N2_day7_rep2 N2_day7 2 N2_day7_rep3 N2_day7 3 t(coldata_df) A matrix: 2 \u00d7 6 of type chr N2_day1_rep1 N2_day1_rep2 N2_day1_rep3 N2_day7_rep1 N2_day7_rep2 N2_day7_rep3 group N2_day1 N2_day1 N2_day1 N2_day7 N2_day7 N2_day7 rep 1 2 3 1 2 3 is.matrix(coldata_df) coldata_df <- as.data.frame(coldata_df) is.data.frame(coldata_df) TRUE TRUE A matrix can contain either character or numeric columns and a dataframe can contain both numeric and character columns. A list is an ordered collection of objects, which can be any type of R objects (vectors, matrices, data frames, even lists). count_files = list(\"sample\" = 'N2_day1_rep1.ReadsPerGene.out.tab', \"sample2\"='N2_day1_rep2.ReadsPerGene.out.tab') count_files $sample 'N2_day1_rep1.ReadsPerGene.out.tab' $sample2 'N2_day1_rep2.ReadsPerGene.out.tab' gene_count = list(\"gene1\" = 10, \"gene2\"=20) lapply(gene_count, function(x){log2(x+1)}) $gene1 3.4594316186373 $gene2 4.39231742277876 log2_transform <- function(x){ log2(x+1) } lapply(gene_count, log2_transform) $gene1 3.4594316186373 $gene2 4.39231742277876","title":"Basic data structure"},{"location":"BIOI611_introR/#dealing-with-text-files","text":"getwd() #setwd() '/content' list.files() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1.ReadsPerGene.out.tab' 'N2_day1_rep2.ReadsPerGene.out.tab' 'N2_day1_rep3.ReadsPerGene.out.tab' 'N2_day7_rep1.ReadsPerGene.out.tab' 'N2_day7_rep2.ReadsPerGene.out.tab' 'N2_day7_rep3.ReadsPerGene.out.tab' 'sample_data' file_paths <- list.files(pattern = \"*..ReadsPerGene.out.tab\") file_paths .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'N2_day1_rep1.ReadsPerGene.out.tab' 'N2_day1_rep2.ReadsPerGene.out.tab' 'N2_day1_rep3.ReadsPerGene.out.tab' 'N2_day7_rep1.ReadsPerGene.out.tab' 'N2_day7_rep2.ReadsPerGene.out.tab' 'N2_day7_rep3.ReadsPerGene.out.tab' tab_N2_day1_rep1 <- read.table('N2_day1_rep1.ReadsPerGene.out.tab') head(tab_N2_day1_rep1, 5) A data.frame: 5 \u00d7 4 V1 V2 V3 V4 <chr> <int> <int> <int> 1 N_unmapped 1332776 1332776 1332776 2 N_multimapping 1540190 1540190 1540190 3 N_noFeature 157102 19017455 18933214 4 N_ambiguous 536422 128854 120342 5 WBGene00000003 341 161 180 tab_N2_day1_rep2 <- read.table('N2_day1_rep2.ReadsPerGene.out.tab') head(tab_N2_day1_rep2,5) A data.frame: 5 \u00d7 4 V1 V2 V3 V4 <chr> <int> <int> <int> 1 N_unmapped 1400596 1400596 1400596 2 N_multimapping 1305129 1305129 1305129 3 N_noFeature 152183 15009786 14975925 4 N_ambiguous 439830 104631 98489 5 WBGene00000003 415 198 217 tab_N2_day1_rep3 <- read.table('N2_day1_rep3.ReadsPerGene.out.tab') head(tab_N2_day1_rep3,5) A data.frame: 5 \u00d7 4 V1 V2 V3 V4 <chr> <int> <int> <int> 1 N_unmapped 5887223 5887223 5887223 2 N_multimapping 1557570 1557570 1557570 3 N_noFeature 184441 17612359 17574940 4 N_ambiguous 514559 122385 115498 5 WBGene00000003 411 175 236 library(dplyr) Attaching package: \u2018dplyr\u2019 The following objects are masked from \u2018package:stats\u2019: filter, lag The following objects are masked from \u2018package:base\u2019: intersect, setdiff, setequal, union tab_N2_day1_rep1 <- tab_N2_day1_rep1 %>% select(V1, V2) head(tab_N2_day1_rep1, 5) tab_N2_day1_rep2 <- tab_N2_day1_rep2[, c(\"V1\", \"V2\")] head(tab_N2_day1_rep2, 5) tab_N2_day1_rep3 <- tab_N2_day1_rep3[, c(\"V1\", \"V2\")] head(tab_N2_day1_rep3, 5) A data.frame: 5 \u00d7 2 V1 V2 <chr> <int> 1 N_unmapped 1332776 2 N_multimapping 1540190 3 N_noFeature 157102 4 N_ambiguous 536422 5 WBGene00000003 341 A data.frame: 5 \u00d7 2 V1 V2 <chr> <int> 1 N_unmapped 1400596 2 N_multimapping 1305129 3 N_noFeature 152183 4 N_ambiguous 439830 5 WBGene00000003 415 A data.frame: 5 \u00d7 2 V1 V2 <chr> <int> 1 N_unmapped 5887223 2 N_multimapping 1557570 3 N_noFeature 184441 4 N_ambiguous 514559 5 WBGene00000003 411 df_merged <- merge(tab_N2_day1_rep1, tab_N2_day1_rep2, by = \"V1\") head(df_merged) df_merged <- merge(df_merged, tab_N2_day1_rep3, by = \"V1\") head(df_merged) A data.frame: 6 \u00d7 3 V1 V2.x V2.y <chr> <int> <int> 1 N_ambiguous 536422 439830 2 N_multimapping 1540190 1305129 3 N_noFeature 157102 152183 4 N_unmapped 1332776 1400596 5 WBGene00000001 3227 2168 6 WBGene00000002 270 203 A data.frame: 6 \u00d7 4 V1 V2.x V2.y V2 <chr> <int> <int> <int> 1 N_ambiguous 536422 439830 514559 2 N_multimapping 1540190 1305129 1557570 3 N_noFeature 157102 152183 184441 4 N_unmapped 1332776 1400596 5887223 5 WBGene00000001 3227 2168 2589 6 WBGene00000002 270 203 266 The Reduce() function in R allows us to apply a function repeatedly to a list of elements. Here, we are applying merge() iteratively to a list of data frames. df_mer_red <- Reduce(function(x, y) merge(x, y, by = \"V1\"), list(\"tab_N2_day1_rep1\" = tab_N2_day1_rep1, \"tab_N2_day1_rep2\" = tab_N2_day1_rep2, \"tab_N2_day1_rep3\" = tab_N2_day1_rep3)) head(df_mer_red, 5) A data.frame: 5 \u00d7 4 V1 V2.x V2.y V2 <chr> <int> <int> <int> 1 N_ambiguous 536422 439830 514559 2 N_multimapping 1540190 1305129 1557570 3 N_noFeature 157102 152183 184441 4 N_unmapped 1332776 1400596 5887223 5 WBGene00000001 3227 2168 2589","title":"Dealing with text files"},{"location":"BIOI611_introR/#producing-graphs-with-r","text":"","title":"Producing Graphs with R"},{"location":"BIOI611_introR/#producing-graphs-using-basic","text":"","title":"Producing Graphs using basic"},{"location":"BIOI611_introR/#line-charts","text":"# Define the cars vector with 5 values cars <- c(1, 3, 6, 4, 9) # Graph the cars vector with all defaults plot(cars) Let's add a title, a line to connect the points, and some color: # Define the cars vector with 5 values cars <- c(1, 3, 6, 4, 9) # Graph cars using blue points overlayed by a line plot(cars, type=\"o\", col=\"blue\") # Create a title with a red, bold/italic font title(main=\"Autos\", col.main=\"red\", font.main=4) # Define 2 vectors cars <- c(1, 3, 6, 4, 9) trucks <- c(2, 5, 4, 5, 12) # Graph cars using a y axis that ranges from 0 to 12 plot(cars, type=\"o\", col=\"blue\", ylim=c(0,12)) # Graph trucks with red dashed line and square points lines(trucks, type=\"o\", pch=22, lty=2, col=\"red\") # Create a title with a red, bold/italic font title(main=\"Autos\", col.main=\"red\", font.main=4) csv_url <- \"https://gist.githubusercontent.com/seankross/a412dfbd88b3db70b74b/raw/5f23f993cd87c283ce766e7ac6b329ee7cc2e1d1/mtcars.csv\" mtcars <- read.csv(csv_url) mtcars A data.frame: 32 \u00d7 12 model mpg cyl disp hp drat wt qsec vs am gear carb <chr> <dbl> <int> <dbl> <int> <dbl> <dbl> <dbl> <int> <int> <int> <int> Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 plot(mtcars$wt,mtcars$mpg, main=\"Scatterplot in Base R\", xlab=\"Car Weight\", ylab=\"MPG\", pch=4, col = \"blue\", lwd=1, cex = 2) abline(lm(mtcars$mpg~mtcars$wt), col=\"red\") text(mtcars$wt, mtcars$mpg, labels=rownames(mtcars), cex=0.5, font=2) hist(mtcars$hp, prob = TRUE) lines(density(mtcars$hp), # density plot lwd = 2, # thickness of line col = \"red\") abline(v=mean(mtcars$hp), lty=\"dashed\", col=\"blue\") Probability Density : It tells you how the data is distributed over different ranges (or bins) of values. The height of each bar shows how densely the data is packed in that range of horsepower values.","title":"Line charts"},{"location":"BIOI611_introR/#producing-graphs-using-ggplot2","text":"library(ggplot2) ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point(size=5, shape=4, color=\"blue\", stroke=1) + geom_smooth(method=lm, color=\"red\") + ggtitle(\"Scatterplot in ggplot2\") + xlab(\"Car Weight\") + # for the x axis label geom_text(label=rownames(mtcars),cex=3) \u001b[1m\u001b[22m`geom_smooth()` using formula = 'y ~ x' ggplot(mtcars, aes(x = hp)) + geom_histogram(aes(y = ..density..), bins = 6, # You can adjust the number of bins fill = \"lightblue\", color = \"black\") + # Histogram with probability density geom_density(color = \"red\", size = 1.5) + # Add the density plot geom_vline(aes(xintercept = mean(hp)), linetype = \"dashed\", color = \"blue\", size = 1.2) + # Add dashed blue vertical line at the mean labs(title = \"Distribution of Horsepower in mtcars Dataset\", x = \"Horsepower\", y = \"Density\") + # Add axis labels and title theme_minimal() # Use a clean theme for the plot","title":"Producing graphs using ggplot2"},{"location":"BIOI611_introR/#reference","text":"https://sites.harding.edu/fmccown/R/ https://jtr13.github.io/cc21fall2/base-r-vs.-ggplot2-visualization.html#base-r-vs.-ggplot2-visualization","title":"Reference"},{"location":"BIOI611_long_read_transcriptome/","text":"Analysis of long read transcriptome data In this lab, you are going to analyze the direct RNA data published on Genome Research in 2020. The title of the paper is: The full-length transcriptome of C. elegans using direct RNA sequencing . Download the data You can go the Data access section of the paper here: https://genome.cshlp.org/content/30/2/299.full Go to: https://www.ncbi.nlm.nih.gov/ Search PRJEB31791 Click SRA link Click the first item in the search results Click the link: ERP114391 Right click on the fastq files to obtain the FTP URL Then you can use wget to download the fastq files. The data for L1 and adult male samples has been downloaded and saved on the HPC cluster: /scratch/zt1/project/bioi611/shared/raw_data/ONT_directRNA/L1_rep1.fastq.gz /scratch/zt1/project/bioi611/shared/raw_data/ONT_directRNA/L1_rep2.fastq.gz /scratch/zt1/project/bioi611/shared/raw_data/ONT_directRNA/male_rep1.fastq.gz /scratch/zt1/project/bioi611/shared/raw_data/ONT_directRNA/male_rep2.fastq.gz Analyze the data using wf-transcriptomes wf-transcriptomes is a cDNA and RNA sequencing data analysis workflow that leverages long nanopore reads, providing a detailed view of the transcriptome. Download the tool https://github.com/epi2me-labs/wf-transcriptomes Path: /scratch/zt1/project/bioi611/shared/software/wf-transcriptomes-1.4.0/main.nf Install conda Miniforge is a minimal installer for Conda specific to conda-forge. Miniforge allows users to install the conda package manager with the following features pre-configured: conda-forge set as the default (and only) channel. rm -rf miniforge3 wget \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\" bash Miniforge3-$(uname)-$(uname -m).sh Run wf-transcriptome on the demo datasets The workflow wf-transcriptome has a demo datasets. This demo datasets can be used to test the workflow and help you undestand the input and output. The demo data can be found here: ls /scratch/zt1/project/bioi611/shared/raw_data/wf-transcriptomes-demo/ |cat chr20 differential_expression_fastq gencode.v22.annotation.chr20.gff gencode.v22.annotation.chr20.gff3 gencode.v22.annotation.chr20.gtf hg38_chr20.fa Homo_sapiens.GRCh38.109.gtf.gz Homo_sapiens.GRCh38.cdna.all.fa.gz Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz md5sums.txt nextflow.config ref_transcriptome.fasta sample_sheet.csv You can analyze the demo data by submitting the job file below: # Takes around 8 minutes to finish sbatch /scratch/zt1/project/bioi611/shared/scripts/ONT_directRNA_wf_transcriptome_demo.sub The output folder is: /scratch/zt1/project/bioi611/user/$USER/ONT_directRNA_demo The documentation for the output files can be found here: https://github.com/epi2me-labs/wf-transcriptomes?tab=readme-ov-file#outputs Output files may be aggregated including information for all samples or provided per sample. Per-sample files will be prefixed with respective aliases and represented below as {{ alias }}. Title File path Description Per sample or aggregated workflow report wf-transcriptomes-report.html a HTML report document detailing the primary findings of the workflow aggregated Per file read stats fastq_ingress_results/reads/fastcat_stats/per-file-stats.tsv A TSV with per file read stats, including all samples. aggregated Read stats fastq_ingress_results/reads/fastcat_stats/per-read-stats.tsv A TSV with per read stats, including all samples. aggregated Run ID's fastq_ingress_results/reads/fastcat_stats/run_ids List of run IDs present in reads. aggregated Meta map json fastq_ingress_results/reads/metamap.json Metadata used in workflow presented in a JSON. aggregated Concatenated sequence data fastq_ingress_results/reads/{{ alias }}.fastq.gz Per sample reads concatenated in to one FASTQ file. per-sample Assembled transcriptome {{ alias }}_transcriptome.fas Per sample assembled transcriptome. per-sample Annotated assembled transcriptome {{ alias }}_merged_transcriptome.fas Per sample annotated assembled transcriptome. per-sample Alignment summary statistics {{ alias }}_read_aln_stats.tsv Per sample alignment summary statistics. per-sample GFF compare results. {{ alias }}_gffcompare All GFF compare output files. per-sample Differential gene expression results de_analysis/results_dge.tsv This is a gene-level result file that describes genes and their probability of showing differential expression between experimental conditions. aggregated Differential gene expression report de_analysis/results_dge.pdf Summary report of differential gene expression analysis as a PDF. aggregated Differential transcript usage gene TSV de_analysis/results_dtu_gene.tsv This is a gene-level result file from DEXSeq that lists annotated genes and their probabilities of differential expression. aggregated Differential transcript usage report de_analysis/results_dtu.pdf Summary report of differential transcript usage results as a PDF. aggregated Differential transcript usage TSV de_analysis/results_dtu_transcript.tsv This is a transcript-level result file from DEXSeq that lists annotated genes and their probabilities of differential expression. aggregated Differential transcript usage stageR TSV de_analysis/results_dtu_stageR.tsv This is the output from StageR and it shows both gene and transcript probabilities of differential expression aggregated Differential transcript usage DEXSeq TSV de_analysis/results_dexseq.tsv The complete output from the DEXSeq-analysis, shows both gene and transcript probabilities of differential expression. aggregated Gene counts de_analysis/all_gene_counts.tsv Raw gene counts created by the Salmon tool, before filtering. aggregated Gene counts per million de_analysis/cpm_gene_counts.tsv This file shows counts per million (CPM) of the raw gene counts to facilitate comparisons across samples. aggregated Transcript counts de_analysis/unfiltered_transcript_counts_with_genes.tsv Raw transcript counts created by the Salmon tool, before filtering. Includes reference to the associated gene ID. aggregated Transcript per million counts de_analysis/unfiltered_tpm_transcript_counts.tsv This file shows transcripts per million (TPM) of the raw counts to facilitate comparisons across samples. aggregated Transcript counts filtered de_analysis/filtered_transcript_counts_with_genes.tsv Filtered transcript counts, used for differential transcript usage analysis. Includes a reference to the associated gene ID. aggregated Transcript info table {{ alias }}_transcripts_table.tsv This file details each isoform that was reconstructed from the input reads. It contains a subset of columns from the .tmap output from gffcompare per-sample Final non redundant transcriptome de_analysis/final_non_redundant_transcriptome.fasta Transcripts that were used for differential expression analysis including novel transcripts with the identifiers used for DE analysis. aggregated Index of reference FASTA file igv_reference/{{ ref_genome file }}.fai Reference genome index of the FASTA file required for IGV config. aggregated GZI index of the reference FASTA file igv_reference/{{ ref_genome file }}.gzi GZI Index of the reference FASTA file. aggregated JSON configuration file for IGV browser igv.json JSON configuration file to be loaded in IGV for visualising alignments against the reference. aggregated BAM file (minimap2) BAMS/{{ alias }}.reads_aln_sorted.bam BAM file generated from mapping input reads to the reference. per-sample BAM index file (minimap2) BAMS/{{ alias }}.reads_aln_sort.bam.bai Index file generated from mapping input reads to the reference. per-sample Run wf-transcriptome on the direct RNA sequencing data from C. elegans Based on the demo data, you can set up the input folder and run the workflow on the direct RNA from the Genome Research paper. # Takes around 14 minutes to finish sbatch /scratch/zt1/project/bioi611/shared/scripts/ONT_directRNA_wf_transcriptome.sub You can find the output files here: /scratch/zt1/project/bioi611/user/$USER/ONT_directRNA Basecalling [Optional] Introduction to ONT Raw Data (FAST5/POD5) In Oxford Nanopore sequencing, raw data captures the electrical signal generated as DNA or RNA molecules pass through a nanopore. This signal reflects variations in ionic current caused by the unique properties of each nucleotide. Key points about raw data: Ionic Current Signal: The primary measurement is the change in ionic current as each nucleotide interacts with the nanopore. This signal is captured continuously. MinKNOW Software: This software suite manages the sequencing process, capturing raw signals and translating them into \"reads.\" File Formats: POD5: This is the primary file format used in recent ONT sequencing runs, replacing the older FAST5 format. Each read in these files corresponds to a single DNA or RNA strand. Understanding raw data is crucial because it represents the initial and most unprocessed form of information from ONT sequencing. However, it\u2019s challenging to interpret without further processing. Base Calling and File Outputs (BAM/FASTQ) After generating raw data, the next essential step is base calling, which translates the electrical signal into nucleotide sequences. This is where machine learning plays a critical role: Base Calling Process: Signal Processing Techniques: ONT\u2019s basecalling algorithms use advanced machine learning models to interpret the raw signal. Output: Each ionic current pattern is mapped to a sequence of nucleotide bases (A, T, C, or G). Output File Formats: BAM Files: These files contain sequence information along with potential modifications and alignment information. ONT typically structures BAM files with 4,000 reads per file by default. FASTQ Files: This is the widely-used format for storing nucleotide sequences and their associated quality scores. Similar to BAM, ONT defaults to 4,000 reads per file in FASTQ format. Basecalling using Guppy In Roach, et. al., 2020, RNA sequencing on the GridION platform was performed using ONT R9.4 flow cells and the standard MinKNOW protocol script (NC_48Hr_sequencing_FLO-MIN106_SQK-RNA001). The raw data is in FAST5 format. Guppy is a data processing toolkit that contains the Oxford Nanopore Technologies' production basecalling algorithms and several bioinformatic post-processing features. To basecall reads with Guppy , you will need to use the following commands: guppy_basecaller (or the fully-qualified path if using the archive installer) --input_path : Full or relative path to the directory where the raw read files are located. The folder can be absolute or a relative path to the current working directory. --save_path : Full or relative path to the directory where the basecall results will be saved. The folder can be absolute or a relative path to the current working directory. This folder will be created if it does not exist using the path you provide. (e.g. if it is a relative path, it will be relative to the current working directory) Then either: --config : configuration file containing Guppy parameters or --flowcell flow cell version --kit sequencing kit version Find the corresponding model The kit and flow cell information should be clearly labelled on the corresponding boxes. Flow cells almost always start with \"FLO\" and kits almost always start with \"SQK\" or \"VSK\". To see the supported flow cells and kits, run Guppy with the --print_workflows option: /scratch/zt1/project/bioi611/shared/software/ont-guppy-cpu/bin/guppy_basecaller --print_workflows |grep 'FLO-M IN106' |grep 'SQK-RNA001' flowcell kit barcoding config_name model version FLO-MIN106 SQK-RNA001 rna_r9.4.1_70bps_hac 2020-09-07_rna_r9.4.1_minion_256_8f8fc47b Basecalling using Guppy /scratch/zt1/project/bioi611/shared/software/ont-guppy-cpu/bin/guppy_basecaller \\ -i test_data/ \\ --config /scratch/zt1/project/bioi611/sha red/software/ont-guppy-cpu/data/rna_r9.4.1_70bps_hac.cfg \\ --save_path temp --recursive Quality-Based Output Directories Guppy categorizes reads based on their quality scores, storing them in separate folders for easy access and downstream processing. pass/: Contains reads with quality scores above a specified threshold (typically a Phred quality score of 7 or higher). These reads are considered high quality and are commonly used for downstream analyses. File Format: FASTQ files, each storing sequences and associated quality scores. fail/: Contains reads with quality scores below the specified threshold, indicating lower confidence in accuracy. These reads might be filtered out or re-processed depending on the study's goals. File Format: FASTQ files, similar to those in the pass directory, but typically excluded from final analyses. Remember the data you basecalled here is only a test dataset. The number of reads in pass/ and fail/ doesn't reflect the acutual data. Software dorado is now the recommended tool to perform basecalling on POD5 files. FAST5 files can be converted to POD5 files using the tool below: https://github.com/nanoporetech/pod5-file-format","title":"Long read transcriptome"},{"location":"BIOI611_long_read_transcriptome/#analysis-of-long-read-transcriptome-data","text":"In this lab, you are going to analyze the direct RNA data published on Genome Research in 2020. The title of the paper is: The full-length transcriptome of C. elegans using direct RNA sequencing .","title":"Analysis of long read transcriptome data"},{"location":"BIOI611_long_read_transcriptome/#download-the-data","text":"You can go the Data access section of the paper here: https://genome.cshlp.org/content/30/2/299.full Go to: https://www.ncbi.nlm.nih.gov/ Search PRJEB31791 Click SRA link Click the first item in the search results Click the link: ERP114391 Right click on the fastq files to obtain the FTP URL Then you can use wget to download the fastq files. The data for L1 and adult male samples has been downloaded and saved on the HPC cluster: /scratch/zt1/project/bioi611/shared/raw_data/ONT_directRNA/L1_rep1.fastq.gz /scratch/zt1/project/bioi611/shared/raw_data/ONT_directRNA/L1_rep2.fastq.gz /scratch/zt1/project/bioi611/shared/raw_data/ONT_directRNA/male_rep1.fastq.gz /scratch/zt1/project/bioi611/shared/raw_data/ONT_directRNA/male_rep2.fastq.gz","title":"Download the data"},{"location":"BIOI611_long_read_transcriptome/#analyze-the-data-using-wf-transcriptomes","text":"wf-transcriptomes is a cDNA and RNA sequencing data analysis workflow that leverages long nanopore reads, providing a detailed view of the transcriptome.","title":"Analyze the data using wf-transcriptomes"},{"location":"BIOI611_long_read_transcriptome/#download-the-tool","text":"https://github.com/epi2me-labs/wf-transcriptomes Path: /scratch/zt1/project/bioi611/shared/software/wf-transcriptomes-1.4.0/main.nf","title":"Download the tool"},{"location":"BIOI611_long_read_transcriptome/#install-conda","text":"Miniforge is a minimal installer for Conda specific to conda-forge. Miniforge allows users to install the conda package manager with the following features pre-configured: conda-forge set as the default (and only) channel. rm -rf miniforge3 wget \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\" bash Miniforge3-$(uname)-$(uname -m).sh","title":"Install conda"},{"location":"BIOI611_long_read_transcriptome/#run-wf-transcriptome-on-the-demo-datasets","text":"The workflow wf-transcriptome has a demo datasets. This demo datasets can be used to test the workflow and help you undestand the input and output. The demo data can be found here: ls /scratch/zt1/project/bioi611/shared/raw_data/wf-transcriptomes-demo/ |cat chr20 differential_expression_fastq gencode.v22.annotation.chr20.gff gencode.v22.annotation.chr20.gff3 gencode.v22.annotation.chr20.gtf hg38_chr20.fa Homo_sapiens.GRCh38.109.gtf.gz Homo_sapiens.GRCh38.cdna.all.fa.gz Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz md5sums.txt nextflow.config ref_transcriptome.fasta sample_sheet.csv You can analyze the demo data by submitting the job file below: # Takes around 8 minutes to finish sbatch /scratch/zt1/project/bioi611/shared/scripts/ONT_directRNA_wf_transcriptome_demo.sub The output folder is: /scratch/zt1/project/bioi611/user/$USER/ONT_directRNA_demo The documentation for the output files can be found here: https://github.com/epi2me-labs/wf-transcriptomes?tab=readme-ov-file#outputs Output files may be aggregated including information for all samples or provided per sample. Per-sample files will be prefixed with respective aliases and represented below as {{ alias }}. Title File path Description Per sample or aggregated workflow report wf-transcriptomes-report.html a HTML report document detailing the primary findings of the workflow aggregated Per file read stats fastq_ingress_results/reads/fastcat_stats/per-file-stats.tsv A TSV with per file read stats, including all samples. aggregated Read stats fastq_ingress_results/reads/fastcat_stats/per-read-stats.tsv A TSV with per read stats, including all samples. aggregated Run ID's fastq_ingress_results/reads/fastcat_stats/run_ids List of run IDs present in reads. aggregated Meta map json fastq_ingress_results/reads/metamap.json Metadata used in workflow presented in a JSON. aggregated Concatenated sequence data fastq_ingress_results/reads/{{ alias }}.fastq.gz Per sample reads concatenated in to one FASTQ file. per-sample Assembled transcriptome {{ alias }}_transcriptome.fas Per sample assembled transcriptome. per-sample Annotated assembled transcriptome {{ alias }}_merged_transcriptome.fas Per sample annotated assembled transcriptome. per-sample Alignment summary statistics {{ alias }}_read_aln_stats.tsv Per sample alignment summary statistics. per-sample GFF compare results. {{ alias }}_gffcompare All GFF compare output files. per-sample Differential gene expression results de_analysis/results_dge.tsv This is a gene-level result file that describes genes and their probability of showing differential expression between experimental conditions. aggregated Differential gene expression report de_analysis/results_dge.pdf Summary report of differential gene expression analysis as a PDF. aggregated Differential transcript usage gene TSV de_analysis/results_dtu_gene.tsv This is a gene-level result file from DEXSeq that lists annotated genes and their probabilities of differential expression. aggregated Differential transcript usage report de_analysis/results_dtu.pdf Summary report of differential transcript usage results as a PDF. aggregated Differential transcript usage TSV de_analysis/results_dtu_transcript.tsv This is a transcript-level result file from DEXSeq that lists annotated genes and their probabilities of differential expression. aggregated Differential transcript usage stageR TSV de_analysis/results_dtu_stageR.tsv This is the output from StageR and it shows both gene and transcript probabilities of differential expression aggregated Differential transcript usage DEXSeq TSV de_analysis/results_dexseq.tsv The complete output from the DEXSeq-analysis, shows both gene and transcript probabilities of differential expression. aggregated Gene counts de_analysis/all_gene_counts.tsv Raw gene counts created by the Salmon tool, before filtering. aggregated Gene counts per million de_analysis/cpm_gene_counts.tsv This file shows counts per million (CPM) of the raw gene counts to facilitate comparisons across samples. aggregated Transcript counts de_analysis/unfiltered_transcript_counts_with_genes.tsv Raw transcript counts created by the Salmon tool, before filtering. Includes reference to the associated gene ID. aggregated Transcript per million counts de_analysis/unfiltered_tpm_transcript_counts.tsv This file shows transcripts per million (TPM) of the raw counts to facilitate comparisons across samples. aggregated Transcript counts filtered de_analysis/filtered_transcript_counts_with_genes.tsv Filtered transcript counts, used for differential transcript usage analysis. Includes a reference to the associated gene ID. aggregated Transcript info table {{ alias }}_transcripts_table.tsv This file details each isoform that was reconstructed from the input reads. It contains a subset of columns from the .tmap output from gffcompare per-sample Final non redundant transcriptome de_analysis/final_non_redundant_transcriptome.fasta Transcripts that were used for differential expression analysis including novel transcripts with the identifiers used for DE analysis. aggregated Index of reference FASTA file igv_reference/{{ ref_genome file }}.fai Reference genome index of the FASTA file required for IGV config. aggregated GZI index of the reference FASTA file igv_reference/{{ ref_genome file }}.gzi GZI Index of the reference FASTA file. aggregated JSON configuration file for IGV browser igv.json JSON configuration file to be loaded in IGV for visualising alignments against the reference. aggregated BAM file (minimap2) BAMS/{{ alias }}.reads_aln_sorted.bam BAM file generated from mapping input reads to the reference. per-sample BAM index file (minimap2) BAMS/{{ alias }}.reads_aln_sort.bam.bai Index file generated from mapping input reads to the reference. per-sample","title":"Run wf-transcriptome on the demo datasets"},{"location":"BIOI611_long_read_transcriptome/#run-wf-transcriptome-on-the-direct-rna-sequencing-data-from-c-elegans","text":"Based on the demo data, you can set up the input folder and run the workflow on the direct RNA from the Genome Research paper. # Takes around 14 minutes to finish sbatch /scratch/zt1/project/bioi611/shared/scripts/ONT_directRNA_wf_transcriptome.sub You can find the output files here: /scratch/zt1/project/bioi611/user/$USER/ONT_directRNA","title":"Run wf-transcriptome on the direct RNA sequencing data from C. elegans"},{"location":"BIOI611_long_read_transcriptome/#basecalling-optional","text":"Introduction to ONT Raw Data (FAST5/POD5) In Oxford Nanopore sequencing, raw data captures the electrical signal generated as DNA or RNA molecules pass through a nanopore. This signal reflects variations in ionic current caused by the unique properties of each nucleotide. Key points about raw data: Ionic Current Signal: The primary measurement is the change in ionic current as each nucleotide interacts with the nanopore. This signal is captured continuously. MinKNOW Software: This software suite manages the sequencing process, capturing raw signals and translating them into \"reads.\" File Formats: POD5: This is the primary file format used in recent ONT sequencing runs, replacing the older FAST5 format. Each read in these files corresponds to a single DNA or RNA strand. Understanding raw data is crucial because it represents the initial and most unprocessed form of information from ONT sequencing. However, it\u2019s challenging to interpret without further processing. Base Calling and File Outputs (BAM/FASTQ) After generating raw data, the next essential step is base calling, which translates the electrical signal into nucleotide sequences. This is where machine learning plays a critical role: Base Calling Process: Signal Processing Techniques: ONT\u2019s basecalling algorithms use advanced machine learning models to interpret the raw signal. Output: Each ionic current pattern is mapped to a sequence of nucleotide bases (A, T, C, or G). Output File Formats: BAM Files: These files contain sequence information along with potential modifications and alignment information. ONT typically structures BAM files with 4,000 reads per file by default. FASTQ Files: This is the widely-used format for storing nucleotide sequences and their associated quality scores. Similar to BAM, ONT defaults to 4,000 reads per file in FASTQ format.","title":"Basecalling [Optional]"},{"location":"BIOI611_long_read_transcriptome/#basecalling-using-guppy","text":"In Roach, et. al., 2020, RNA sequencing on the GridION platform was performed using ONT R9.4 flow cells and the standard MinKNOW protocol script (NC_48Hr_sequencing_FLO-MIN106_SQK-RNA001). The raw data is in FAST5 format. Guppy is a data processing toolkit that contains the Oxford Nanopore Technologies' production basecalling algorithms and several bioinformatic post-processing features. To basecall reads with Guppy , you will need to use the following commands: guppy_basecaller (or the fully-qualified path if using the archive installer) --input_path : Full or relative path to the directory where the raw read files are located. The folder can be absolute or a relative path to the current working directory. --save_path : Full or relative path to the directory where the basecall results will be saved. The folder can be absolute or a relative path to the current working directory. This folder will be created if it does not exist using the path you provide. (e.g. if it is a relative path, it will be relative to the current working directory) Then either: --config : configuration file containing Guppy parameters or --flowcell flow cell version --kit sequencing kit version","title":"Basecalling using Guppy"},{"location":"BIOI611_long_read_transcriptome/#find-the-corresponding-model","text":"The kit and flow cell information should be clearly labelled on the corresponding boxes. Flow cells almost always start with \"FLO\" and kits almost always start with \"SQK\" or \"VSK\". To see the supported flow cells and kits, run Guppy with the --print_workflows option: /scratch/zt1/project/bioi611/shared/software/ont-guppy-cpu/bin/guppy_basecaller --print_workflows |grep 'FLO-M IN106' |grep 'SQK-RNA001' flowcell kit barcoding config_name model version FLO-MIN106 SQK-RNA001 rna_r9.4.1_70bps_hac 2020-09-07_rna_r9.4.1_minion_256_8f8fc47b","title":"Find the corresponding model"},{"location":"BIOI611_long_read_transcriptome/#_1","text":"","title":""},{"location":"BIOI611_long_read_transcriptome/#basecalling-using-guppy_1","text":"/scratch/zt1/project/bioi611/shared/software/ont-guppy-cpu/bin/guppy_basecaller \\ -i test_data/ \\ --config /scratch/zt1/project/bioi611/sha red/software/ont-guppy-cpu/data/rna_r9.4.1_70bps_hac.cfg \\ --save_path temp --recursive","title":"Basecalling using Guppy"},{"location":"BIOI611_long_read_transcriptome/#quality-based-output-directories","text":"Guppy categorizes reads based on their quality scores, storing them in separate folders for easy access and downstream processing. pass/: Contains reads with quality scores above a specified threshold (typically a Phred quality score of 7 or higher). These reads are considered high quality and are commonly used for downstream analyses. File Format: FASTQ files, each storing sequences and associated quality scores. fail/: Contains reads with quality scores below the specified threshold, indicating lower confidence in accuracy. These reads might be filtered out or re-processed depending on the study's goals. File Format: FASTQ files, similar to those in the pass directory, but typically excluded from final analyses. Remember the data you basecalled here is only a test dataset. The number of reads in pass/ and fail/ doesn't reflect the acutual data. Software dorado is now the recommended tool to perform basecalling on POD5 files. FAST5 files can be converted to POD5 files using the tool below: https://github.com/nanoporetech/pod5-file-format","title":"Quality-Based Output Directories"},{"location":"BIOI611_scRNA/","text":"Install required R packages # # Install the remotes package # if (!requireNamespace(\"remotes\", quietly = TRUE)) { # install.packages(\"remotes\") # } # # Install Seurat # if (!requireNamespace(\"Seurat\", quietly = TRUE)) { # remotes::install_github(\"satijalab/seurat\", \"seurat5\", quiet = TRUE) # } # # Install BiocManager # if (!require(\"BiocManager\", quietly = TRUE)) # install.packages(\"BiocManager\") # # Install SingleR package # if (!require(\"hdf5r\", quietly = TRUE)){ # BiocManager::install(\"hdf5r\") # } # # Install SingleR package # if (!require(\"presto\", quietly = TRUE)){ # remotes::install_github(\"immunogenomics/presto\") # } # # Install SingleR package # if (!require(\"SingleR\", quietly = TRUE)){ # BiocManager::install(\"SingleR\") # } # if (!require(\"celldex\", quietly = TRUE)){ # BiocManager::install(\"celldex\") # } # if (!require(\"SingleCellExperiment\", quietly = TRUE)){ # BiocManager::install(\"SingleCellExperiment\") # } # if (!require(\"scater\", quietly = TRUE)){ # BiocManager::install(\"scater\") # } ## Installing the R packages could take around 51 minutes ## To speed up this process, you can download the R lib files ## saved from a working Google Colab session ## https://drive.google.com/file/d/1EQvZnsV6P0eNjbW0hwYhz0P5z0iH3bsL/view?usp=drive_link system(\"gdown 1EQvZnsV6P0eNjbW0hwYhz0P5z0iH3bsL\") system(\"md5sum R_lib4scRNA.tar.gz\", intern = TRUE) '5898c04fca5e680710cd6728ef9b1422 R_lib4scRNA.tar.gz' ## required by scater package system(\"apt-get install libx11-dev libcairo2-dev\") #, intern = TRUE) system(\"tar zxvf R_lib4scRNA.tar.gz\") .libPaths(c(\"/content/usr/local/lib/R/site-library\", .libPaths())) .libPaths() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '/content/usr/local/lib/R/site-library' '/usr/local/lib/R/site-library' '/usr/lib/R/site-library' '/usr/lib/R/library' Load required R packages library(Seurat) library(dplyr) library(SingleR) library(celldex) library(scater) library(SingleCellExperiment) list.files() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'R_lib4scRNA.tar.gz' 'sample_data' 'usr' # https://drive.google.com/file/d/1-CvmcLvKMYW-OcLuGfFuGQMK2b5_VMFk/view?usp=drive_link # Download \"filtered_feature_bc_matrix.h5\" # Output of cellranger system(\"gdown 1-CvmcLvKMYW-OcLuGfFuGQMK2b5_VMFk\") system(\"md5sum filtered_feature_bc_matrix.h5\", intern = TRUE) '360fc0760ebb9e6dd253d808a427b20d filtered_feature_bc_matrix.h5' count_mtx_scrna <- Read10X_h5(\"filtered_feature_bc_matrix.h5\") # If you have the filtered_feature_bc_matrix/ folder, you can use # Read10X to create 'count_mtx_scrna' # system(\"mkdir filtered_feature_bc_matrix/; mv filtered_feature_bc_matrix.zip filtered_feature_bc_matrix\") # system(\"cd filtered_feature_bc_matrix; unzip filtered_feature_bc_matrix.zip\") # count_mtx_scrna <- Read10X(\"filtered_feature_bc_matrix/\") class(count_mtx_scrna) 'dgCMatrix' The dgCMatrix class is a specific data structure in R's Matrix package, designed to store sparse matrices in a memory-efficient format. Sparse matrices are those with many zeros, making them ideal for high-dimensional data in applications like bioinformatics, where gene expression matrices often contain a lot of zeroes. Why Use dgCMatrix? Memory Efficiency : Storing only non-zero values saves memory, especially in high-dimensional matrices. Computational Speed : Some operations on sparse matrices can be faster, as computations are limited to non-zero entries. print(format(object.size(count_mtx_scrna), units = \"MB\")) [1] \"168.7 Mb\" # Check a few genes in the first 20 cells count_mtx_scrna[c(\"CD3D\", \"TCL1A\", \"MS4A1\"), 100:140] [[ suppressing 41 column names \u2018AACCATGCACTCAAGT-1\u2019, \u2018AACCATGGTAGCTTGT-1\u2019, \u2018AACCATGTCAATCCGA-1\u2019 ... ]] 3 x 41 sparse Matrix of class \"dgCMatrix\" CD3D 8 1 . . . 3 . 2 10 . 3 . . . 2 7 1 . . . 1 1 . 8 . . 2 4 . . . 12 11 . TCL1A . . . . . . 6 . . . . . . . . . . . . . . . 10 . . . . . . . . . . . MS4A1 . . . . . . 9 . . 16 . . . . . . . . . . . . 5 . . . . . . . . . . . CD3D . 5 . . . 3 . TCL1A . . . . . . . MS4A1 20 . . . 39 . . # non-normalized da# Initialize the Seurat object with the raw count matrix pbmc <- CreateSeuratObject(counts = count_mtx_scrna, project = \"pbmc5k\", min.cells = 3, min.features = 200) pbmc An object of class Seurat 24785 features across 4884 samples within 1 assay Active assay: RNA (24785 features, 0 variable features) 1 layer present: counts Understand Seurat object Seurat slots https://github.com/satijalab/seurat/wiki/seurat str(pbmc) Formal class 'Seurat' [package \"SeuratObject\"] with 13 slots ..@ assays :List of 1 .. ..$ RNA:Formal class 'Assay5' [package \"SeuratObject\"] with 8 slots .. .. .. ..@ layers :List of 1 .. .. .. .. ..$ counts:Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots .. .. .. .. .. .. ..@ i : int [1:14449622] 6 17 42 62 79 83 85 94 100 109 ... .. .. .. .. .. .. ..@ p : int [1:4885] 0 3378 5344 5581 8581 10897 13921 16902 20299 22669 ... .. .. .. .. .. .. ..@ Dim : int [1:2] 24785 4884 .. .. .. .. .. .. ..@ Dimnames:List of 2 .. .. .. .. .. .. .. ..$ : NULL .. .. .. .. .. .. .. ..$ : NULL .. .. .. .. .. .. ..@ x : num [1:14449622] 1 1 4 1 1 2 1 1 1 1 ... .. .. .. .. .. .. ..@ factors : list() .. .. .. ..@ cells :Formal class 'LogMap' [package \"SeuratObject\"] with 1 slot .. .. .. .. .. ..@ .Data: logi [1:4884, 1] TRUE TRUE TRUE TRUE TRUE TRUE ... .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2 .. .. .. .. .. .. .. ..$ : chr [1:4884] \"AAACCCATCAGATGCT-1\" \"AAACGAAAGTGCTACT-1\" \"AAACGAAGTCGTAATC-1\" \"AAACGAAGTTGCCAAT-1\" ... .. .. .. .. .. .. .. ..$ : chr \"counts\" .. .. .. .. .. ..$ dim : int [1:2] 4884 1 .. .. .. .. .. ..$ dimnames:List of 2 .. .. .. .. .. .. ..$ : chr [1:4884] \"AAACCCATCAGATGCT-1\" \"AAACGAAAGTGCTACT-1\" \"AAACGAAGTCGTAATC-1\" \"AAACGAAGTTGCCAAT-1\" ... .. .. .. .. .. .. ..$ : chr \"counts\" .. .. .. ..@ features :Formal class 'LogMap' [package \"SeuratObject\"] with 1 slot .. .. .. .. .. ..@ .Data: logi [1:24785, 1] TRUE TRUE TRUE TRUE TRUE TRUE ... .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2 .. .. .. .. .. .. .. ..$ : chr [1:24785] \"ENSG00000238009\" \"ENSG00000241860\" \"ENSG00000290385\" \"ENSG00000291215\" ... .. .. .. .. .. .. .. ..$ : chr \"counts\" .. .. .. .. .. ..$ dim : int [1:2] 24785 1 .. .. .. .. .. ..$ dimnames:List of 2 .. .. .. .. .. .. ..$ : chr [1:24785] \"ENSG00000238009\" \"ENSG00000241860\" \"ENSG00000290385\" \"ENSG00000291215\" ... .. .. .. .. .. .. ..$ : chr \"counts\" .. .. .. ..@ default : int 1 .. .. .. ..@ assay.orig: chr(0) .. .. .. ..@ meta.data :'data.frame': 24785 obs. of 0 variables .. .. .. ..@ misc :List of 1 .. .. .. .. ..$ calcN: logi TRUE .. .. .. ..@ key : chr \"rna_\" ..@ meta.data :'data.frame': 4884 obs. of 3 variables: .. ..$ orig.ident : Factor w/ 1 level \"pbmc5k\": 1 1 1 1 1 1 1 1 1 1 ... .. ..$ nCount_RNA : num [1:4884] 11578 5655 14728 10903 6174 ... .. ..$ nFeature_RNA: int [1:4884] 3378 1966 237 3000 2316 3024 2981 3397 2370 2811 ... ..@ active.assay: chr \"RNA\" ..@ active.ident: Factor w/ 1 level \"pbmc5k\": 1 1 1 1 1 1 1 1 1 1 ... .. ..- attr(*, \"names\")= chr [1:4884] \"AAACCCATCAGATGCT-1\" \"AAACGAAAGTGCTACT-1\" \"AAACGAAGTCGTAATC-1\" \"AAACGAAGTTGCCAAT-1\" ... ..@ graphs : list() ..@ neighbors : list() ..@ reductions : list() ..@ images : list() ..@ project.name: chr \"pbmc5k\" ..@ misc : list() ..@ version :Classes 'package_version', 'numeric_version' hidden list of 1 .. ..$ : int [1:3] 5 0 2 ..@ commands : list() ..@ tools : list() slotNames(pbmc) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'assays' 'meta.data' 'active.assay' 'active.ident' 'graphs' 'neighbors' 'reductions' 'images' 'project.name' 'misc' 'version' 'commands' 'tools' Access Seurat object pbmc@active.assay 'RNA' class(pbmc@meta.data) head(pbmc@meta.data, 4) 'data.frame' A data.frame: 4 \u00d7 3 orig.ident nCount_RNA nFeature_RNA <fct> <dbl> <int> AAACCCATCAGATGCT-1 pbmc5k 11578 3378 AAACGAAAGTGCTACT-1 pbmc5k 5655 1966 AAACGAAGTCGTAATC-1 pbmc5k 14728 237 AAACGAAGTTGCCAAT-1 pbmc5k 10903 3000 colSums(pbmc@assays$RNA$counts)[1:3] .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} AAACCCATCAGATGCT-1 11578 AAACGAAAGTGCTACT-1 5655 AAACGAAGTCGTAATC-1 14728 Layers(pbmc) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'counts' 'data' 'scale.data' Data preprocessing # Use $ operator to add columns to object metadata. pbmc$percent.mt <- PercentageFeatureSet(pbmc, pattern = \"^MT-\") colnames(pbmc@meta.data) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'orig.ident' 'nCount_RNA' 'nFeature_RNA' 'percent.mt' head(pbmc, 4) A data.frame: 4 \u00d7 8 orig.ident nCount_RNA nFeature_RNA percent.mt RNA_snn_res.0.1 seurat_clusters singleR_hpca singleR_blueprint <fct> <dbl> <int> <dbl> <fct> <fct> <chr> <chr> AAACCCATCAGATGCT-1 pbmc5k 11578 3378 3.62756953 1 1 T_cells CD4+ T-cells AAACGAAAGTGCTACT-1 pbmc5k 5655 1966 4.29708223 0 0 T_cells CD4+ T-cells AAACGAAGTCGTAATC-1 pbmc5k 14728 237 0.02715915 6 6 Erythroblast Erythrocytes AAACGAAGTTGCCAAT-1 pbmc5k 10903 3000 4.89773457 5 5 T_cells CD8+ T-cells # Use violin plot to visualize QC metrics VlnPlot(pbmc, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3) Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d How to read the Violin Plot Shape: Each violin plot shows the distribution of values for each feature across the cells in your dataset. The shape of the plot indicates the density of cells with particular values for that feature. Wider sections indicate more cells with those values. Narrow sections indicate fewer cells with those values. Vertical Axis: Represents the range of values for each feature. For instance: nFeature_RNA and nCount_RNA : Higher values suggest more gene diversity and RNA content, respectively. percent.mt : Higher values indicate higher mitochondrial content, which may point to stressed or dying cells. Horizontal Axis (Groups): If your dataset is separated into clusters or groups (e.g., cell types or conditions), each group will have its own violin, allowing you to compare distributions between groups. How to interpret QC plot nFeature_RNA : The number of unique features (genes) detected per cell. Extremely high values could suggest potential doublets (two cells mistakenly captured as one), as two cells would have more unique genes combined. Low number of detected genes - potential ambient mRNA (not real cells) nCount_RNA : The total number of RNA molecules (or unique molecular identifiers, UMIs) detected per cell. Higher counts generally indicate higher RNA content, but they could also result from cell doublets. Cells with very low nCount_RNA might represent poor-quality cells with low RNA capture, while very high counts may also suggest doublets. percent.mt : The percentage of reads mapping to mitochondrial genes. High mitochondrial content often indicates cell stress or apoptosis, as damaged cells tend to release mitochondrial RNA. Filtering cells with high percent.mt values is common to exclude potentially dying cells. # FeatureScatter is typically used to visualize feature-feature relationships, but can be used # for anything calculated by the object, i.e. columns in object metadata, PC scores etc. plot1 <- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\") plot2 <- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\") plot1 + plot2 # Load necessary libraries library(Seurat) library(ggplot2) # Define the function to calculate median and MAD values calculate_thresholds <- function(seurat_obj) { # Extract relevant columns nFeature_values <- seurat_obj@meta.data$nFeature_RNA nCount_values <- seurat_obj@meta.data$nCount_RNA percent_mt_values <- seurat_obj@meta.data$percent.mt # Calculate medians and MADs nFeature_median <- median(nFeature_values, na.rm = TRUE) nFeature_mad <- mad(nFeature_values, constant = 1, na.rm = TRUE) nCount_median <- median(nCount_values, na.rm = TRUE) nCount_mad <- mad(nCount_values, constant = 1, na.rm = TRUE) percent_mt_median <- median(percent_mt_values, na.rm = TRUE) percent_mt_mad <- mad(percent_mt_values, constant = 1, na.rm = TRUE) # Calculate thresholds for horizontal lines thresholds <- list( nFeature_upper = nFeature_median + 4 * nFeature_mad, nFeature_lower = nFeature_median - 4 * nFeature_mad, nCount_upper = nCount_median + 4 * nCount_mad, nCount_lower = nCount_median - 4 * nCount_mad, percent_mt_upper = percent_mt_median + 4 * percent_mt_mad ) return(thresholds) } # Calculate thresholds thresholds <- calculate_thresholds(pbmc) thresholds $nFeature_upper 5243.5 $nFeature_lower 583.5 $nCount_upper 19044 $nCount_lower -1224 $percent_mt_upper 8.44783722411371 vplot1 <- VlnPlot(pbmc, features = c(\"nFeature_RNA\"), ncol = 2) + geom_hline(yintercept = thresholds$nFeature_upper, color = \"blue\", linetype = \"solid\") + geom_hline(yintercept = thresholds$nFeature_lower, color = \"blue\", linetype = \"solid\") + theme(legend.position=\"none\") vplot2 <- VlnPlot(pbmc, features = c(\"percent.mt\"), ncol = 2) + geom_hline(yintercept = thresholds$percent_mt_upper, color = \"blue\", linetype = \"solid\") + theme(legend.position=\"none\") vplot1 + vplot2 Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Filter out potential doublets, empty droplets and dying cells pbmc <- subset(pbmc, subset = nFeature_RNA > thresholds$nCount_lower & nFeature_RNA < thresholds$nFeature_upper & percent.mt < thresholds$percent_mt_upper) # Use violin plot to visualize QC metrics after QC VlnPlot(pbmc, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3) Instead of using an arbitrary number, you can also use statistical algorithm to predict doublets and empty droplets to filter the cells, such as DoubletFinder and EmptyDrops . Normalization and Scaling of the data Normalization After removing unwanted cells from the dataset, the next step is to normalize the data. By default, a global-scaling normalization method \u201cLogNormalize\u201d that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. In Seurat v5, Normalized values are stored in pbmc[[\"RNA\"]]$data . pbmc <- NormalizeData(pbmc) # normalization.method = \"LogNormalize\", scale.factor = 10000 Normalizing layer: counts While this method of normalization is standard and widely used in scRNA-seq analysis, global-scaling relies on an assumption that each cell originally contains the same number of RNA molecules. Next, we identify a subset of features that show high variation across cells in the dataset\u2014meaning they are highly expressed in some cells and lowly expressed in others. Prior work, including our own, has shown that focusing on these variable genes in downstream analyses can enhance the detection of biological signals in single-cell datasets. The approach used in Seurat improves upon previous versions by directly modeling the inherent mean-variance relationship in single-cell data. This method is implemented in the FindVariableFeatures() function, which, by default, selects 2,000 variable features per dataset. These features will then be used in downstream analyses, such as PCA. pbmc <- FindVariableFeatures(pbmc, selection.method = \"vst\", nfeatures = 2000) Finding variable features for layer counts # Identify the 10 most highly variable genes top10 <- head(VariableFeatures(pbmc), 10) options(repr.plot.width=10, repr.plot.height= 6) # plot variable features with and without labels plot1 <- VariableFeaturePlot(pbmc) plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE) plot1 + plot2 When using repel, set xnudge and ynudge to 0 for optimal results Warning message in scale_x_log10(): \u201c\u001b[1m\u001b[22m\u001b[32mlog-10\u001b[39m transformation introduced infinite values.\u201d Warning message in scale_x_log10(): \u201c\u001b[1m\u001b[22m\u001b[32mlog-10\u001b[39m transformation introduced infinite values.\u201d Scaling the data Next, we apply a linear transformation ( scaling ) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData() function: Shifts the expression of each gene, so that the mean expression across cells is 0 Scales the expression of each gene, so that the variance across cells is 1 This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate The results of this are stored in pbmc[[\"RNA\"]]$scale.data By default, only variable features are scaled. You can specify the features argument to scale additional features. all.genes <- rownames(pbmc) pbmc <- ScaleData(pbmc, features = all.genes) Centering and scaling data matrix Perform linear dimensional reduction pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc)) PC_ 1 Positive: CD247, IL32, IL7R, RORA, CAMK4, LTB, INPP4B, STAT4, BCL2, ANK3 ZEB1, LEF1, TRBC1, CARD11, THEMIS, BACH2, MLLT3, RNF125, RASGRF2, NR3C2 NELL2, PDE3B, LINC01934, ENSG00000290067, PRKCA, TAFA1, PYHIN1, CTSW, CSGALNACT1, SAMD3 Negative: LYZ, FCN1, IRAK3, SLC8A1, CLEC7A, PLXDC2, IFI30, S100A9, SPI1, CYBB MNDA, LRMDA, FGL2, VCAN, CTSS, RBM47, CSF3R, MCTP1, NCF2, TYMP CYRIA, CST3, HCK, SLC11A1, WDFY3, S100A8, MS4A6A, MPEG1, LST1, CSTA PC_ 2 Positive: CD247, S100A4, STAT4, NKG7, CST7, CTSW, GZMA, SYTL3, RNF125, SAMD3 NCALD, MYO1F, MYBL1, KLRD1, PLCB1, TGFBR3, PRF1, GNLY, RAP1GAP2, RORA CCL5, HOPX, FGFBP2, YES1, PYHIN1, FNDC3B, GNG2, SYNE1, KLRF1, SPON2 Negative: BANK1, MS4A1, CD79A, FCRL1, PAX5, IGHM, AFF3, LINC00926, NIBAN3, EBF1 IGHD, BLK, CD22, OSBPL10, HLA-DQA1, COL19A1, GNG7, KHDRBS2, RUBCNL, TNFRSF13C COBLL1, RALGPS2, TCL1A, BCL11A, CDK14, CD79B, PLEKHG1, HLA-DQB1, IGKC, BLNK PC_ 3 Positive: TUBB1, GP9, GP1BB, PF4, CAVIN2, GNG11, NRGN, PPBP, RGS18, PRKAR2B H2AC6, ACRBP, PTCRA, TMEM40, TREML1, CLU, LEF1, GPX1, CMTM5, SMANTIS MPIG6B, CAMK4, MPP1, SPARC, ENSG00000289621, ITGB3, MYL9, MYL4, ITGA2B, F13A1 Negative: NKG7, CST7, GNLY, PRF1, KLRD1, GZMA, KLRF1, MCTP2, GZMB, FGFBP2 HOPX, SPON2, C1orf21, TGFBR3, VAV3, MYBL1, CTSW, SYNE1, NCALD, IL2RB SAMD3, GNG2, BNC2, CEP78, YES1, RAP1GAP2, PDGFD, LINC02384, CARD11, CLIC3 PC_ 4 Positive: CAMK4, INPP4B, IL7R, LEF1, PRKCA, PDE3B, MAML2, LTB, ANK3, PLCL1 BCL2, CDC14A, THEMIS, FHIT, NELL2, VIM, ENSG00000290067, MLLT3, TSHZ2, NR3C2 IL32, CMTM8, ENSG00000249806, ZEB1, SESN3, CSGALNACT1, TAFA1, LEF1-AS1, SLC16A10, LDLRAD4 Negative: GP1BB, GP9, TUBB1, PF4, CAVIN2, GNG11, PPBP, H2AC6, PTCRA, NRGN ACRBP, TMEM40, PRKAR2B, RGS18, TREML1, MPIG6B, SMANTIS, CMTM5, CLU, SPARC ITGA2B, ITGB3, ENSG00000289621, MYL9, CAPN1-AS1, MYL4, ENSG00000288758, DAB2, PDGFA-DT, CTTN PC_ 5 Positive: CDKN1C, HES4, FCGR3A, PELATON, CSF1R, IFITM3, SIGLEC10, TCF7L2, ZNF703, MS4A7 UICLM, ENSG00000287682, NEURL1, RHOC, FMNL2, CKB, FTL, CALHM6, HMOX1, BATF3 ACTB, MYOF, CCDC26, IFITM2, PAPSS2, RRAS, LST1, VMO1, SERPINA1, LRRC25 Negative: LINC02458, AKAP12, CA8, ENSG00000250696, SLC24A3, HDC, IL3RA, EPAS1, ENPP3, OSBPL1A TRPM6, CCR3, CSF2RB, SEMA3C, THSD7A, ATP10D, DACH1, CRPPA, ATP8B4, TMEM164 ABHD5, CLC, CR1, ITGB8, LIN7A, TAFA2, MBOAT2, GATA2, DAPK2, GCSAML You have several useful ways to visualize both cells and features that define the PCA, including VizDimReduction() , DimPlot() , and DimHeatmap() . DimPlot(pbmc, reduction = \"pca\") + NoLegend() DimHeatmap() draws a heatmap focusing on a principal component. Both cells and genes are sorted by their principal component scores DimHeatmap(pbmc, dims = 1:3, cells = 500, balanced = TRUE) DimHeatmap(pbmc, dims = 20:22, cells = 500, balanced = TRUE) Determine the \u2018dimensionality\u2019 of the dataset The elbow plot is a useful tool for determining the number of principal components (PCs) needed to capture the majority of variation in the data. It displays the standard deviation of each PC, with the \"elbow\" point typically serving as the threshold for selecting the most informative PCs. However, identifying the exact location of the elbow can be somewhat subjective. ElbowPlot(pbmc, ndims = 50) # Determine the percentage of variation associated with each PC pct_var <- pbmc[[\"pca\"]]@stdev / sum(pbmc[[\"pca\"]]@stdev) * 100 # Calculate cumulative percentages for each PC cumu_pct <- cumsum(pct_var) # Identify the first PC where cumulative percentage exceeds 90% and individual variance is less than 5% pc_number <- which(cumu_pct > 90 & pct_var < 5)[1] pc_number 41 Cluster the cells Seurat embeds cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected quasi-cliques or communities . Seurat first constructs a KNN graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). This step is performed using the FindNeighbors() function, and takes as input the previously defined dimensionality of the dataset. To cluster the cells, Seurat next applies modularity optimization techniques such as the Louvain algorithm (default) or SLM [SLM, Blondel et al., Journal of Statistical Mechanics], to iteratively group cells together, with the goal of optimizing the standard modularity function. The FindClusters() function implements this procedure, and contains a resolution parameter that sets the granularity of the downstream clustering, with increased values leading to a greater number of clusters. We find that setting this parameter between 1 typically returns good results for single-cell datasets of around 5k cells. Optimal resolution often increases for larger datasets. The clusters can be found using the Idents() function. pbmc <- FindNeighbors(pbmc, dims = 1:pc_number) pbmc <- FindClusters(pbmc, resolution = 0.1) Computing nearest neighbor graph Computing SNN Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck Number of nodes: 4559 Number of edges: 184776 Running Louvain algorithm... Maximum modularity in 10 random starts: 0.9713 Number of communities: 10 Elapsed time: 0 seconds # Look at cluster IDs of the first 5 cells head(Idents(pbmc), 5) .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} AAACCCATCAGATGCT-1 1 AAACGAAAGTGCTACT-1 0 AAACGAAGTCGTAATC-1 6 AAACGAAGTTGCCAAT-1 5 AAACGAATCCGAGGCT-1 4 Levels : .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' Run non-linear dimensional reduction (UMAP/tSNE) To visualize and explore these datasets, Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP. The goal of tSNE/UMAP is to learn underlying structure in the dataset, in order to place similar cells together in low-dimensional space. Therefore, cells that are grouped together within graph-based clusters determined above should co-localize on these dimension reduction plots. pbmc <- RunUMAP(pbmc, dims = 1:pc_number) 01:21:37 UMAP embedding parameters a = 0.9922 b = 1.112 01:21:37 Read 4559 rows and found 41 numeric columns 01:21:37 Using Annoy for neighbor search, n_neighbors = 30 01:21:38 Building Annoy index with metric = cosine, n_trees = 50 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * | 01:21:38 Writing NN index file to temp file /tmp/RtmpwNVWV1/file10a4d98f0d9 01:21:38 Searching Annoy index using 1 thread, search_k = 3000 01:21:40 Annoy recall = 100% 01:21:41 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30 01:21:43 Found 2 connected components, falling back to 'spca' initialization with init_sdev = 1 01:21:43 Using 'irlba' for PCA 01:21:43 PCA: 2 components explained 46.09% variance 01:21:43 Scaling init to sdev = 1 01:21:43 Commencing optimization for 500 epochs, with 188320 positive edges 01:21:49 Optimization finished DimPlot(pbmc, reduction = \"umap\") Finding differentially expressed features (cluster biomarkers) # find markers for every cluster compared to all remaining cells, report only the positive # ones pbmc.markers <- FindAllMarkers(pbmc, only.pos = TRUE) pbmc.markers %>% group_by(cluster) %>% dplyr::filter(avg_log2FC > 1) Calculating cluster 0 Calculating cluster 1 Calculating cluster 2 Calculating cluster 3 Calculating cluster 4 Calculating cluster 5 Calculating cluster 6 Calculating cluster 7 Calculating cluster 8 Calculating cluster 9 A grouped_df: 14138 \u00d7 7 p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene <dbl> <dbl> <dbl> <dbl> <dbl> <fct> <chr> 0.000000e+00 2.193938 0.974 0.426 0.000000e+00 0 IL32 3.852209e-275 1.679326 0.951 0.362 9.547700e-271 0 CD3D 9.596093e-260 1.803885 0.888 0.352 2.378392e-255 0 TRAC 4.781243e-252 1.573425 0.959 0.532 1.185031e-247 0 SYNE2 3.690404e-235 1.512388 0.917 0.348 9.146665e-231 0 CD3G 9.967907e-232 1.809323 0.910 0.485 2.470546e-227 0 RORA 1.117947e-227 1.378699 0.951 0.380 2.770831e-223 0 CD3E 1.039791e-208 2.253821 0.681 0.233 2.577123e-204 0 NIBAN1 2.027326e-187 1.595996 0.810 0.357 5.024728e-183 0 CD2 8.928063e-181 1.512822 0.846 0.383 2.212820e-176 0 IL7R 2.768362e-179 2.583397 0.463 0.091 6.861385e-175 0 PRDM1 2.609892e-166 1.825963 0.777 0.389 6.468617e-162 0 PPP1R16B 8.007361e-166 3.888615 0.310 0.031 1.984624e-161 0 TRGC2 1.861258e-163 1.694587 0.717 0.296 4.613128e-159 0 CD6 1.403718e-158 1.072541 0.969 0.807 3.479115e-154 0 PPP2R5C 9.430895e-158 2.200303 0.525 0.147 2.337447e-153 0 CD5 5.325382e-153 1.314341 0.835 0.433 1.319896e-148 0 SPOCK2 5.541697e-151 1.501378 0.757 0.363 1.373510e-146 0 GPRIN3 1.783366e-148 1.524168 0.815 0.492 4.420072e-144 0 LRRC8C 5.511823e-146 1.130197 0.937 0.772 1.366105e-141 0 EML4 4.406921e-145 1.807049 0.821 0.535 1.092255e-140 0 TNFAIP3 8.596339e-145 1.322956 0.800 0.391 2.130603e-140 0 LIME1 1.601435e-143 1.301753 0.861 0.505 3.969156e-139 0 ATXN1 3.308730e-140 4.011786 0.283 0.033 8.200689e-136 0 GZMK 1.881698e-138 1.586776 0.770 0.413 4.663787e-134 0 PHACTR2 8.271921e-138 1.486293 0.791 0.479 2.050196e-133 0 TTC39C 8.346144e-135 3.699470 0.245 0.020 2.068592e-130 0 MIAT 2.291535e-126 1.420132 0.725 0.348 5.679570e-122 0 ANK3 2.583870e-126 2.075113 0.477 0.151 6.404121e-122 0 PBX4 3.042390e-125 1.333502 0.694 0.316 7.540564e-121 0 OPTN \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 0.009116629 3.631680 0.021 0.002 1 9 H4C1 0.009116629 3.608558 0.021 0.002 1 9 ENSG00000289291 0.009116629 3.605235 0.021 0.002 1 9 VAMP1-AS1 0.009116629 3.591495 0.021 0.002 1 9 ENSG00000249328 0.009116629 3.567020 0.021 0.002 1 9 ERICH2-DT 0.009116629 3.550000 0.021 0.002 1 9 NLRP10 0.009116629 3.518027 0.021 0.002 1 9 ENSG00000270087 0.009116629 3.496166 0.021 0.002 1 9 ENSG00000253593 0.009116629 3.393207 0.021 0.002 1 9 ADAM11 0.009116629 3.272524 0.021 0.002 1 9 ENSG00000228150 0.009116629 3.266281 0.021 0.002 1 9 LINC03065 0.009116629 3.221456 0.021 0.002 1 9 STARD13-AS 0.009116629 3.109640 0.021 0.002 1 9 FGGY-DT 0.009116629 2.116185 0.021 0.002 1 9 ENSG00000285751 0.009353183 1.486986 0.146 0.057 1 9 TRPM2 0.009560927 1.198107 0.083 0.024 1 9 SYCP3 0.009563781 1.367524 0.062 0.015 1 9 MAP7 0.009595402 1.283987 0.083 0.024 1 9 PPP1R13L 0.009686754 2.584749 0.042 0.008 1 9 PRRG2 0.009706714 2.407445 0.042 0.008 1 9 LINC02185 0.009746744 2.473951 0.042 0.008 1 9 LINC02901 0.009766814 2.300928 0.042 0.008 1 9 WNK3 0.009766814 1.640083 0.042 0.008 1 9 CALCRL-AS1 0.009786921 2.434878 0.042 0.008 1 9 ENSG00000272112 0.009786922 2.438294 0.042 0.008 1 9 ENSG00000277589 0.009847464 2.262934 0.042 0.008 1 9 PCDH15 0.009847464 2.064514 0.042 0.008 1 9 CIBAR1 0.009888011 2.173570 0.042 0.008 1 9 SEZ6 0.009908340 1.746860 0.042 0.008 1 9 RTKN 0.009993542 1.340809 0.146 0.059 1 9 ENSG00000287100 # find all markers distinguishing cluster 5 from clusters 0 and 3 cluster5.markers <- FindMarkers(pbmc, ident.1 = 5, ident.2 = c(0, 3)) head(cluster5.markers, n = 5) A data.frame: 5 \u00d7 5 p_val avg_log2FC pct.1 pct.2 p_val_adj <dbl> <dbl> <dbl> <dbl> <dbl> PTPRK 4.438261e-196 5.477436 0.594 0.020 1.100023e-191 NRCAM 9.537544e-196 7.815745 0.496 0.005 2.363880e-191 AIF1 1.738908e-192 4.287096 0.804 0.077 4.309884e-188 LINC02446 3.824707e-176 4.782107 0.638 0.039 9.479537e-172 NELL2 7.816637e-150 3.058779 0.969 0.213 1.937354e-145 VlnPlot(pbmc, features = c(\"PTPRK\", \"NRCAM\")) VlnPlot(pbmc, features = c(\"NKG7\", \"PF4\"), slot = \"counts\", log = TRUE) Warning message: \u201c\u001b[1m\u001b[22mThe `slot` argument of `VlnPlot()` is deprecated as of Seurat 5.0.0. \u001b[36m\u2139\u001b[39m Please use the `layer` argument instead.\u201d FeaturePlot(pbmc, features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\", \"PPBP\", \"CD8A\")) pbmc.markers %>% group_by(cluster) %>% dplyr::filter(avg_log2FC > 1) %>% slice_head(n = 10) %>% ungroup() -> top10 DoHeatmap(pbmc, features = top10$gene) + NoLegend() Cell type annotation using SingleR library(SingleCellExperiment ) sce <- as.SingleCellExperiment(pbmc) sce <- scater::logNormCounts(sce) sce class: SingleCellExperiment dim: 24785 4559 metadata(0): assays(3): counts logcounts scaledata rownames(24785): ENSG00000238009 ENSG00000241860 ... ENSG00000276345 ENSG00000278817 rowData names(0): colnames(4559): AAACCCATCAGATGCT-1 AAACGAAAGTGCTACT-1 ... TTTGTTGTCGAAGTGG-1 TTTGTTGTCGCATAGT-1 colData names(10): orig.ident nCount_RNA ... ident sizeFactor reducedDimNames(2): PCA UMAP mainExpName: RNA altExpNames(0): # Download and cache the normalized expression values of the data # stored in the Human Primary Cell Atlas. The data will be # downloaded from ExperimentHub, returning a SummarizedExperiment # object for further use. hpca <- HumanPrimaryCellAtlasData() # Obtain human bulk RNA-seq data from Blueprint and ENCODE blueprint <- BlueprintEncodeData() pred.hpca <- SingleR(test = sce, ref = hpca, labels = hpca$label.main) tab_hpca <- table(pred.hpca$pruned.labels) write.csv(sort(tab_hpca, decreasing=TRUE), 'pbmc_annotations_HPCA_general.csv', row.names=FALSE) tab_hpca B_cell BM DC Endothelial_cells 451 30 1 1 Erythroblast GMP HSC_-G-CSF HSC_CD34+ 60 2 11 1 Monocyte Neutrophils NK_cell Platelets 759 39 677 93 Pre-B_cell_CD34- T_cells 2 2350 Each row of the output DataFrame contains prediction results for a single cell. Labels are shown before (labels) and after pruning (pruned.labels), along with the associated scores. head(pred.hpca) DataFrame with 6 rows and 4 columns scores labels delta.next <matrix> <character> <numeric> AAACCCATCAGATGCT-1 0.1409902:0.3257687:0.281000:... T_cells 0.0708860 AAACGAAAGTGCTACT-1 0.1407268:0.3072562:0.264148:... T_cells 0.6026772 AAACGAAGTCGTAATC-1 0.0604399:0.0725122:0.184863:... Erythroblast 0.1268946 AAACGAAGTTGCCAAT-1 0.1585486:0.3228307:0.278787:... T_cells 0.6492489 AAACGAATCCGAGGCT-1 0.1166524:0.3565152:0.277855:... B_cell 0.0505309 AAACGAATCGAACGCC-1 0.1437411:0.3427680:0.299201:... NK_cell 0.3155681 pruned.labels <character> AAACCCATCAGATGCT-1 T_cells AAACGAAAGTGCTACT-1 T_cells AAACGAAGTCGTAATC-1 Erythroblast AAACGAAGTTGCCAAT-1 T_cells AAACGAATCCGAGGCT-1 B_cell AAACGAATCGAACGCC-1 NK_cell pred.blueprint <- SingleR(test = sce, ref = blueprint, labels = blueprint$label.main) tab_blueprint <- table(pred.blueprint$pruned.labels) write.csv(sort(tab_blueprint, decreasing=TRUE), 'pbmc_annotations_BlueprintENCODE_general.csv', row.names=FALSE) tab_blueprint B-cells CD4+ T-cells CD8+ T-cells DC 455 1749 576 3 Endothelial cells Eosinophils Erythrocytes HSC 1 50 128 4 Monocytes Neutrophils NK cells 768 3 692 head(pred.blueprint) DataFrame with 6 rows and 4 columns scores labels delta.next <matrix> <character> <numeric> AAACCCATCAGATGCT-1 0.2145648:0.1136181:0.437872:... CD4+ T-cells 0.0512150 AAACGAAAGTGCTACT-1 0.2311086:0.1664737:0.393066:... CD4+ T-cells 0.3283657 AAACGAAGTCGTAATC-1 0.0977069:0.0728724:0.100641:... Erythrocytes 0.0757261 AAACGAAGTTGCCAAT-1 0.2289000:0.1565938:0.423090:... CD8+ T-cells 0.0620951 AAACGAATCCGAGGCT-1 0.2353403:0.1291495:0.500443:... B-cells 0.1276654 AAACGAATCGAACGCC-1 0.2308036:0.1288775:0.417440:... NK cells 0.1486502 pruned.labels <character> AAACCCATCAGATGCT-1 CD4+ T-cells AAACGAAAGTGCTACT-1 CD4+ T-cells AAACGAAGTCGTAATC-1 Erythrocytes AAACGAAGTTGCCAAT-1 CD8+ T-cells AAACGAATCCGAGGCT-1 B-cells AAACGAATCGAACGCC-1 NK cells pbmc$singleR_hpca = pred.hpca$pruned.labels pbmc$singleR_blueprint = pred.blueprint$pruned.labels Idents(pbmc) = pbmc$singleR_hpca DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5, repel = TRUE) + NoLegend() # Change back to cluster snn_res.0.1 Idents(pbmc) = pbmc$`RNA_snn_res.0.1` Idents(pbmc) = pbmc$singleR_blueprint DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5, repel = TRUE) + NoLegend() # Change back to cluster snn_res.0.1 Idents(pbmc) = pbmc$`RNA_snn_res.0.1` Manual annotation Markers Cell Type IL7R, CCR7 Naive CD4+ T CD14, LYZ CD14+ Mono IL7R, S100A4 Memory CD4+ MS4A1 B CD8A CD8+ T FCGR3A, MS4A7 FCGR3A+ Mono GNLY, NKG7 NK FCER1A, CST3 DC PPBP Platelet table(Idents(pbmc)) 0 1 2 3 4 5 6 7 8 9 1215 938 761 662 465 224 98 94 54 48 FeaturePlot(pbmc, features = c(\"IL7R\", \"CD14\", \"CCR7\", \"S100A4\", \"MS4A1\")) DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5, repel = TRUE) + NoLegend() pbmc = RenameIdents(pbmc, \"2\"=\"CD14+ Mono\") pbmc = RenameIdents(pbmc, \"1\"=\"Naive CD4+ T\") pbmc = RenameIdents(pbmc, \"0\"=\"Memory CD4+\") ### Add more manual annotation based on your checking DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5, repel = TRUE) + NoLegend() Save the Seurat object saveRDS(pbmc, file = \"Seurat_object_pbmc_final.rds\") remotes::install_github(\"10xGenomics/loupeR\") loupeR::setup() Downloading GitHub repo 10xGenomics/loupeR@HEAD \u001b[36m\u2500\u2500\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m * checking for file \u2018/tmp/RtmpwNVWV1/remotes10a53185aac/10XGenomics-loupeR-a169417/DESCRIPTION\u2019 ... OK * preparing \u2018loupeR\u2019: * checking DESCRIPTION meta-information ... OK * checking for LF line-endings in source and make files and shell scripts * checking for empty or unneeded directories * building \u2018loupeR_1.1.2.tar.gz\u2019 Installing package into \u2018/content/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) Warning message in fun(libname, pkgname): \u201cPlease call `loupeR::setup()` to install the Louper executable and to agree to the EULA before continuing\u201d Installing Executable 2024/11/18 22:56:23 Downloading executable The LoupeR executable is subject to the 10x End User Software License, available at: https://10xgen.com/EULA Do you accept the End-User License Agreement (y/yes or n/no): yes EULA library(loupeR) create_loupe_from_seurat(pbmc, output_name = \"Seurat_object_pbmc_cloupe\") 2024/11/18 22:57:18 extracting matrix, clusters, and projections 2024/11/18 22:57:18 selected assay: RNA 2024/11/18 22:57:18 selected clusters: active_cluster orig.ident RNA_snn_res.0.1 seurat_clusters singleR_hpca singleR_blueprint 2024/11/18 22:57:18 selected projections: umap 2024/11/18 22:57:18 validating count matrix 2024/11/18 22:57:19 validating clusters 2024/11/18 22:57:19 validating projections 2024/11/18 22:57:19 creating temporary hdf5 file: /tmp/RtmpwNVWV1/file10aaeba1e8.h5 2024/11/18 22:57:23 invoking louper executable 2024/11/18 22:57:23 running command: \"/root/.local/share/R/loupeR/louper create --input='/tmp/RtmpwNVWV1/file10aaeba1e8.h5' --output='Seurat_object_pbmc_cloupe.cloupe'\" Reference https://monashbioinformaticsplatform.github.io/Single-Cell-Workshop/pbmc3k_tutorial.html https://bioinformatics.ccr.cancer.gov/docs/getting-started-with-scrna-seq/IntroToR_Seurat/ https://hbctraining.github.io/scRNA-seq/lessons/elbow_plot_metric.html","title":"Downstream analysis of 10x scRNA-seq data for human PBMC using Seurat"},{"location":"BIOI611_scRNA/#_1","text":"","title":""},{"location":"BIOI611_scRNA/#install-required-r-packages","text":"# # Install the remotes package # if (!requireNamespace(\"remotes\", quietly = TRUE)) { # install.packages(\"remotes\") # } # # Install Seurat # if (!requireNamespace(\"Seurat\", quietly = TRUE)) { # remotes::install_github(\"satijalab/seurat\", \"seurat5\", quiet = TRUE) # } # # Install BiocManager # if (!require(\"BiocManager\", quietly = TRUE)) # install.packages(\"BiocManager\") # # Install SingleR package # if (!require(\"hdf5r\", quietly = TRUE)){ # BiocManager::install(\"hdf5r\") # } # # Install SingleR package # if (!require(\"presto\", quietly = TRUE)){ # remotes::install_github(\"immunogenomics/presto\") # } # # Install SingleR package # if (!require(\"SingleR\", quietly = TRUE)){ # BiocManager::install(\"SingleR\") # } # if (!require(\"celldex\", quietly = TRUE)){ # BiocManager::install(\"celldex\") # } # if (!require(\"SingleCellExperiment\", quietly = TRUE)){ # BiocManager::install(\"SingleCellExperiment\") # } # if (!require(\"scater\", quietly = TRUE)){ # BiocManager::install(\"scater\") # } ## Installing the R packages could take around 51 minutes ## To speed up this process, you can download the R lib files ## saved from a working Google Colab session ## https://drive.google.com/file/d/1EQvZnsV6P0eNjbW0hwYhz0P5z0iH3bsL/view?usp=drive_link system(\"gdown 1EQvZnsV6P0eNjbW0hwYhz0P5z0iH3bsL\") system(\"md5sum R_lib4scRNA.tar.gz\", intern = TRUE) '5898c04fca5e680710cd6728ef9b1422 R_lib4scRNA.tar.gz' ## required by scater package system(\"apt-get install libx11-dev libcairo2-dev\") #, intern = TRUE) system(\"tar zxvf R_lib4scRNA.tar.gz\") .libPaths(c(\"/content/usr/local/lib/R/site-library\", .libPaths())) .libPaths() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '/content/usr/local/lib/R/site-library' '/usr/local/lib/R/site-library' '/usr/lib/R/site-library' '/usr/lib/R/library'","title":"Install required R packages"},{"location":"BIOI611_scRNA/#load-required-r-packages","text":"library(Seurat) library(dplyr) library(SingleR) library(celldex) library(scater) library(SingleCellExperiment) list.files() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'R_lib4scRNA.tar.gz' 'sample_data' 'usr' # https://drive.google.com/file/d/1-CvmcLvKMYW-OcLuGfFuGQMK2b5_VMFk/view?usp=drive_link # Download \"filtered_feature_bc_matrix.h5\" # Output of cellranger system(\"gdown 1-CvmcLvKMYW-OcLuGfFuGQMK2b5_VMFk\") system(\"md5sum filtered_feature_bc_matrix.h5\", intern = TRUE) '360fc0760ebb9e6dd253d808a427b20d filtered_feature_bc_matrix.h5' count_mtx_scrna <- Read10X_h5(\"filtered_feature_bc_matrix.h5\") # If you have the filtered_feature_bc_matrix/ folder, you can use # Read10X to create 'count_mtx_scrna' # system(\"mkdir filtered_feature_bc_matrix/; mv filtered_feature_bc_matrix.zip filtered_feature_bc_matrix\") # system(\"cd filtered_feature_bc_matrix; unzip filtered_feature_bc_matrix.zip\") # count_mtx_scrna <- Read10X(\"filtered_feature_bc_matrix/\") class(count_mtx_scrna) 'dgCMatrix' The dgCMatrix class is a specific data structure in R's Matrix package, designed to store sparse matrices in a memory-efficient format. Sparse matrices are those with many zeros, making them ideal for high-dimensional data in applications like bioinformatics, where gene expression matrices often contain a lot of zeroes. Why Use dgCMatrix? Memory Efficiency : Storing only non-zero values saves memory, especially in high-dimensional matrices. Computational Speed : Some operations on sparse matrices can be faster, as computations are limited to non-zero entries. print(format(object.size(count_mtx_scrna), units = \"MB\")) [1] \"168.7 Mb\" # Check a few genes in the first 20 cells count_mtx_scrna[c(\"CD3D\", \"TCL1A\", \"MS4A1\"), 100:140] [[ suppressing 41 column names \u2018AACCATGCACTCAAGT-1\u2019, \u2018AACCATGGTAGCTTGT-1\u2019, \u2018AACCATGTCAATCCGA-1\u2019 ... ]] 3 x 41 sparse Matrix of class \"dgCMatrix\" CD3D 8 1 . . . 3 . 2 10 . 3 . . . 2 7 1 . . . 1 1 . 8 . . 2 4 . . . 12 11 . TCL1A . . . . . . 6 . . . . . . . . . . . . . . . 10 . . . . . . . . . . . MS4A1 . . . . . . 9 . . 16 . . . . . . . . . . . . 5 . . . . . . . . . . . CD3D . 5 . . . 3 . TCL1A . . . . . . . MS4A1 20 . . . 39 . . # non-normalized da# Initialize the Seurat object with the raw count matrix pbmc <- CreateSeuratObject(counts = count_mtx_scrna, project = \"pbmc5k\", min.cells = 3, min.features = 200) pbmc An object of class Seurat 24785 features across 4884 samples within 1 assay Active assay: RNA (24785 features, 0 variable features) 1 layer present: counts","title":"Load required R packages"},{"location":"BIOI611_scRNA/#understand-seurat-object","text":"Seurat slots https://github.com/satijalab/seurat/wiki/seurat str(pbmc) Formal class 'Seurat' [package \"SeuratObject\"] with 13 slots ..@ assays :List of 1 .. ..$ RNA:Formal class 'Assay5' [package \"SeuratObject\"] with 8 slots .. .. .. ..@ layers :List of 1 .. .. .. .. ..$ counts:Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots .. .. .. .. .. .. ..@ i : int [1:14449622] 6 17 42 62 79 83 85 94 100 109 ... .. .. .. .. .. .. ..@ p : int [1:4885] 0 3378 5344 5581 8581 10897 13921 16902 20299 22669 ... .. .. .. .. .. .. ..@ Dim : int [1:2] 24785 4884 .. .. .. .. .. .. ..@ Dimnames:List of 2 .. .. .. .. .. .. .. ..$ : NULL .. .. .. .. .. .. .. ..$ : NULL .. .. .. .. .. .. ..@ x : num [1:14449622] 1 1 4 1 1 2 1 1 1 1 ... .. .. .. .. .. .. ..@ factors : list() .. .. .. ..@ cells :Formal class 'LogMap' [package \"SeuratObject\"] with 1 slot .. .. .. .. .. ..@ .Data: logi [1:4884, 1] TRUE TRUE TRUE TRUE TRUE TRUE ... .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2 .. .. .. .. .. .. .. ..$ : chr [1:4884] \"AAACCCATCAGATGCT-1\" \"AAACGAAAGTGCTACT-1\" \"AAACGAAGTCGTAATC-1\" \"AAACGAAGTTGCCAAT-1\" ... .. .. .. .. .. .. .. ..$ : chr \"counts\" .. .. .. .. .. ..$ dim : int [1:2] 4884 1 .. .. .. .. .. ..$ dimnames:List of 2 .. .. .. .. .. .. ..$ : chr [1:4884] \"AAACCCATCAGATGCT-1\" \"AAACGAAAGTGCTACT-1\" \"AAACGAAGTCGTAATC-1\" \"AAACGAAGTTGCCAAT-1\" ... .. .. .. .. .. .. ..$ : chr \"counts\" .. .. .. ..@ features :Formal class 'LogMap' [package \"SeuratObject\"] with 1 slot .. .. .. .. .. ..@ .Data: logi [1:24785, 1] TRUE TRUE TRUE TRUE TRUE TRUE ... .. .. .. .. .. .. ..- attr(*, \"dimnames\")=List of 2 .. .. .. .. .. .. .. ..$ : chr [1:24785] \"ENSG00000238009\" \"ENSG00000241860\" \"ENSG00000290385\" \"ENSG00000291215\" ... .. .. .. .. .. .. .. ..$ : chr \"counts\" .. .. .. .. .. ..$ dim : int [1:2] 24785 1 .. .. .. .. .. ..$ dimnames:List of 2 .. .. .. .. .. .. ..$ : chr [1:24785] \"ENSG00000238009\" \"ENSG00000241860\" \"ENSG00000290385\" \"ENSG00000291215\" ... .. .. .. .. .. .. ..$ : chr \"counts\" .. .. .. ..@ default : int 1 .. .. .. ..@ assay.orig: chr(0) .. .. .. ..@ meta.data :'data.frame': 24785 obs. of 0 variables .. .. .. ..@ misc :List of 1 .. .. .. .. ..$ calcN: logi TRUE .. .. .. ..@ key : chr \"rna_\" ..@ meta.data :'data.frame': 4884 obs. of 3 variables: .. ..$ orig.ident : Factor w/ 1 level \"pbmc5k\": 1 1 1 1 1 1 1 1 1 1 ... .. ..$ nCount_RNA : num [1:4884] 11578 5655 14728 10903 6174 ... .. ..$ nFeature_RNA: int [1:4884] 3378 1966 237 3000 2316 3024 2981 3397 2370 2811 ... ..@ active.assay: chr \"RNA\" ..@ active.ident: Factor w/ 1 level \"pbmc5k\": 1 1 1 1 1 1 1 1 1 1 ... .. ..- attr(*, \"names\")= chr [1:4884] \"AAACCCATCAGATGCT-1\" \"AAACGAAAGTGCTACT-1\" \"AAACGAAGTCGTAATC-1\" \"AAACGAAGTTGCCAAT-1\" ... ..@ graphs : list() ..@ neighbors : list() ..@ reductions : list() ..@ images : list() ..@ project.name: chr \"pbmc5k\" ..@ misc : list() ..@ version :Classes 'package_version', 'numeric_version' hidden list of 1 .. ..$ : int [1:3] 5 0 2 ..@ commands : list() ..@ tools : list() slotNames(pbmc) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'assays' 'meta.data' 'active.assay' 'active.ident' 'graphs' 'neighbors' 'reductions' 'images' 'project.name' 'misc' 'version' 'commands' 'tools'","title":"Understand Seurat object"},{"location":"BIOI611_scRNA/#access-seurat-object","text":"pbmc@active.assay 'RNA' class(pbmc@meta.data) head(pbmc@meta.data, 4) 'data.frame' A data.frame: 4 \u00d7 3 orig.ident nCount_RNA nFeature_RNA <fct> <dbl> <int> AAACCCATCAGATGCT-1 pbmc5k 11578 3378 AAACGAAAGTGCTACT-1 pbmc5k 5655 1966 AAACGAAGTCGTAATC-1 pbmc5k 14728 237 AAACGAAGTTGCCAAT-1 pbmc5k 10903 3000 colSums(pbmc@assays$RNA$counts)[1:3] .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} AAACCCATCAGATGCT-1 11578 AAACGAAAGTGCTACT-1 5655 AAACGAAGTCGTAATC-1 14728 Layers(pbmc) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'counts' 'data' 'scale.data'","title":"Access Seurat object"},{"location":"BIOI611_scRNA/#data-preprocessing","text":"# Use $ operator to add columns to object metadata. pbmc$percent.mt <- PercentageFeatureSet(pbmc, pattern = \"^MT-\") colnames(pbmc@meta.data) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'orig.ident' 'nCount_RNA' 'nFeature_RNA' 'percent.mt' head(pbmc, 4) A data.frame: 4 \u00d7 8 orig.ident nCount_RNA nFeature_RNA percent.mt RNA_snn_res.0.1 seurat_clusters singleR_hpca singleR_blueprint <fct> <dbl> <int> <dbl> <fct> <fct> <chr> <chr> AAACCCATCAGATGCT-1 pbmc5k 11578 3378 3.62756953 1 1 T_cells CD4+ T-cells AAACGAAAGTGCTACT-1 pbmc5k 5655 1966 4.29708223 0 0 T_cells CD4+ T-cells AAACGAAGTCGTAATC-1 pbmc5k 14728 237 0.02715915 6 6 Erythroblast Erythrocytes AAACGAAGTTGCCAAT-1 pbmc5k 10903 3000 4.89773457 5 5 T_cells CD8+ T-cells # Use violin plot to visualize QC metrics VlnPlot(pbmc, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3) Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d","title":"Data preprocessing"},{"location":"BIOI611_scRNA/#how-to-read-the-violin-plot","text":"Shape: Each violin plot shows the distribution of values for each feature across the cells in your dataset. The shape of the plot indicates the density of cells with particular values for that feature. Wider sections indicate more cells with those values. Narrow sections indicate fewer cells with those values. Vertical Axis: Represents the range of values for each feature. For instance: nFeature_RNA and nCount_RNA : Higher values suggest more gene diversity and RNA content, respectively. percent.mt : Higher values indicate higher mitochondrial content, which may point to stressed or dying cells. Horizontal Axis (Groups): If your dataset is separated into clusters or groups (e.g., cell types or conditions), each group will have its own violin, allowing you to compare distributions between groups.","title":"How to read the Violin Plot"},{"location":"BIOI611_scRNA/#how-to-interpret-qc-plot","text":"nFeature_RNA : The number of unique features (genes) detected per cell. Extremely high values could suggest potential doublets (two cells mistakenly captured as one), as two cells would have more unique genes combined. Low number of detected genes - potential ambient mRNA (not real cells) nCount_RNA : The total number of RNA molecules (or unique molecular identifiers, UMIs) detected per cell. Higher counts generally indicate higher RNA content, but they could also result from cell doublets. Cells with very low nCount_RNA might represent poor-quality cells with low RNA capture, while very high counts may also suggest doublets. percent.mt : The percentage of reads mapping to mitochondrial genes. High mitochondrial content often indicates cell stress or apoptosis, as damaged cells tend to release mitochondrial RNA. Filtering cells with high percent.mt values is common to exclude potentially dying cells. # FeatureScatter is typically used to visualize feature-feature relationships, but can be used # for anything calculated by the object, i.e. columns in object metadata, PC scores etc. plot1 <- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\") plot2 <- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\") plot1 + plot2 # Load necessary libraries library(Seurat) library(ggplot2) # Define the function to calculate median and MAD values calculate_thresholds <- function(seurat_obj) { # Extract relevant columns nFeature_values <- seurat_obj@meta.data$nFeature_RNA nCount_values <- seurat_obj@meta.data$nCount_RNA percent_mt_values <- seurat_obj@meta.data$percent.mt # Calculate medians and MADs nFeature_median <- median(nFeature_values, na.rm = TRUE) nFeature_mad <- mad(nFeature_values, constant = 1, na.rm = TRUE) nCount_median <- median(nCount_values, na.rm = TRUE) nCount_mad <- mad(nCount_values, constant = 1, na.rm = TRUE) percent_mt_median <- median(percent_mt_values, na.rm = TRUE) percent_mt_mad <- mad(percent_mt_values, constant = 1, na.rm = TRUE) # Calculate thresholds for horizontal lines thresholds <- list( nFeature_upper = nFeature_median + 4 * nFeature_mad, nFeature_lower = nFeature_median - 4 * nFeature_mad, nCount_upper = nCount_median + 4 * nCount_mad, nCount_lower = nCount_median - 4 * nCount_mad, percent_mt_upper = percent_mt_median + 4 * percent_mt_mad ) return(thresholds) } # Calculate thresholds thresholds <- calculate_thresholds(pbmc) thresholds $nFeature_upper 5243.5 $nFeature_lower 583.5 $nCount_upper 19044 $nCount_lower -1224 $percent_mt_upper 8.44783722411371 vplot1 <- VlnPlot(pbmc, features = c(\"nFeature_RNA\"), ncol = 2) + geom_hline(yintercept = thresholds$nFeature_upper, color = \"blue\", linetype = \"solid\") + geom_hline(yintercept = thresholds$nFeature_lower, color = \"blue\", linetype = \"solid\") + theme(legend.position=\"none\") vplot2 <- VlnPlot(pbmc, features = c(\"percent.mt\"), ncol = 2) + geom_hline(yintercept = thresholds$percent_mt_upper, color = \"blue\", linetype = \"solid\") + theme(legend.position=\"none\") vplot1 + vplot2 Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d","title":"How to interpret QC plot"},{"location":"BIOI611_scRNA/#filter-out-potential-doublets-empty-droplets-and-dying-cells","text":"pbmc <- subset(pbmc, subset = nFeature_RNA > thresholds$nCount_lower & nFeature_RNA < thresholds$nFeature_upper & percent.mt < thresholds$percent_mt_upper) # Use violin plot to visualize QC metrics after QC VlnPlot(pbmc, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3) Instead of using an arbitrary number, you can also use statistical algorithm to predict doublets and empty droplets to filter the cells, such as DoubletFinder and EmptyDrops .","title":"Filter out potential doublets, empty droplets and dying cells"},{"location":"BIOI611_scRNA/#normalization-and-scaling-of-the-data","text":"","title":"Normalization and Scaling of the data"},{"location":"BIOI611_scRNA/#normalization","text":"After removing unwanted cells from the dataset, the next step is to normalize the data. By default, a global-scaling normalization method \u201cLogNormalize\u201d that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. In Seurat v5, Normalized values are stored in pbmc[[\"RNA\"]]$data . pbmc <- NormalizeData(pbmc) # normalization.method = \"LogNormalize\", scale.factor = 10000 Normalizing layer: counts While this method of normalization is standard and widely used in scRNA-seq analysis, global-scaling relies on an assumption that each cell originally contains the same number of RNA molecules. Next, we identify a subset of features that show high variation across cells in the dataset\u2014meaning they are highly expressed in some cells and lowly expressed in others. Prior work, including our own, has shown that focusing on these variable genes in downstream analyses can enhance the detection of biological signals in single-cell datasets. The approach used in Seurat improves upon previous versions by directly modeling the inherent mean-variance relationship in single-cell data. This method is implemented in the FindVariableFeatures() function, which, by default, selects 2,000 variable features per dataset. These features will then be used in downstream analyses, such as PCA. pbmc <- FindVariableFeatures(pbmc, selection.method = \"vst\", nfeatures = 2000) Finding variable features for layer counts # Identify the 10 most highly variable genes top10 <- head(VariableFeatures(pbmc), 10) options(repr.plot.width=10, repr.plot.height= 6) # plot variable features with and without labels plot1 <- VariableFeaturePlot(pbmc) plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE) plot1 + plot2 When using repel, set xnudge and ynudge to 0 for optimal results Warning message in scale_x_log10(): \u201c\u001b[1m\u001b[22m\u001b[32mlog-10\u001b[39m transformation introduced infinite values.\u201d Warning message in scale_x_log10(): \u201c\u001b[1m\u001b[22m\u001b[32mlog-10\u001b[39m transformation introduced infinite values.\u201d","title":"Normalization"},{"location":"BIOI611_scRNA/#scaling-the-data","text":"Next, we apply a linear transformation ( scaling ) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData() function: Shifts the expression of each gene, so that the mean expression across cells is 0 Scales the expression of each gene, so that the variance across cells is 1 This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate The results of this are stored in pbmc[[\"RNA\"]]$scale.data By default, only variable features are scaled. You can specify the features argument to scale additional features. all.genes <- rownames(pbmc) pbmc <- ScaleData(pbmc, features = all.genes) Centering and scaling data matrix","title":"Scaling the data"},{"location":"BIOI611_scRNA/#perform-linear-dimensional-reduction","text":"pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc)) PC_ 1 Positive: CD247, IL32, IL7R, RORA, CAMK4, LTB, INPP4B, STAT4, BCL2, ANK3 ZEB1, LEF1, TRBC1, CARD11, THEMIS, BACH2, MLLT3, RNF125, RASGRF2, NR3C2 NELL2, PDE3B, LINC01934, ENSG00000290067, PRKCA, TAFA1, PYHIN1, CTSW, CSGALNACT1, SAMD3 Negative: LYZ, FCN1, IRAK3, SLC8A1, CLEC7A, PLXDC2, IFI30, S100A9, SPI1, CYBB MNDA, LRMDA, FGL2, VCAN, CTSS, RBM47, CSF3R, MCTP1, NCF2, TYMP CYRIA, CST3, HCK, SLC11A1, WDFY3, S100A8, MS4A6A, MPEG1, LST1, CSTA PC_ 2 Positive: CD247, S100A4, STAT4, NKG7, CST7, CTSW, GZMA, SYTL3, RNF125, SAMD3 NCALD, MYO1F, MYBL1, KLRD1, PLCB1, TGFBR3, PRF1, GNLY, RAP1GAP2, RORA CCL5, HOPX, FGFBP2, YES1, PYHIN1, FNDC3B, GNG2, SYNE1, KLRF1, SPON2 Negative: BANK1, MS4A1, CD79A, FCRL1, PAX5, IGHM, AFF3, LINC00926, NIBAN3, EBF1 IGHD, BLK, CD22, OSBPL10, HLA-DQA1, COL19A1, GNG7, KHDRBS2, RUBCNL, TNFRSF13C COBLL1, RALGPS2, TCL1A, BCL11A, CDK14, CD79B, PLEKHG1, HLA-DQB1, IGKC, BLNK PC_ 3 Positive: TUBB1, GP9, GP1BB, PF4, CAVIN2, GNG11, NRGN, PPBP, RGS18, PRKAR2B H2AC6, ACRBP, PTCRA, TMEM40, TREML1, CLU, LEF1, GPX1, CMTM5, SMANTIS MPIG6B, CAMK4, MPP1, SPARC, ENSG00000289621, ITGB3, MYL9, MYL4, ITGA2B, F13A1 Negative: NKG7, CST7, GNLY, PRF1, KLRD1, GZMA, KLRF1, MCTP2, GZMB, FGFBP2 HOPX, SPON2, C1orf21, TGFBR3, VAV3, MYBL1, CTSW, SYNE1, NCALD, IL2RB SAMD3, GNG2, BNC2, CEP78, YES1, RAP1GAP2, PDGFD, LINC02384, CARD11, CLIC3 PC_ 4 Positive: CAMK4, INPP4B, IL7R, LEF1, PRKCA, PDE3B, MAML2, LTB, ANK3, PLCL1 BCL2, CDC14A, THEMIS, FHIT, NELL2, VIM, ENSG00000290067, MLLT3, TSHZ2, NR3C2 IL32, CMTM8, ENSG00000249806, ZEB1, SESN3, CSGALNACT1, TAFA1, LEF1-AS1, SLC16A10, LDLRAD4 Negative: GP1BB, GP9, TUBB1, PF4, CAVIN2, GNG11, PPBP, H2AC6, PTCRA, NRGN ACRBP, TMEM40, PRKAR2B, RGS18, TREML1, MPIG6B, SMANTIS, CMTM5, CLU, SPARC ITGA2B, ITGB3, ENSG00000289621, MYL9, CAPN1-AS1, MYL4, ENSG00000288758, DAB2, PDGFA-DT, CTTN PC_ 5 Positive: CDKN1C, HES4, FCGR3A, PELATON, CSF1R, IFITM3, SIGLEC10, TCF7L2, ZNF703, MS4A7 UICLM, ENSG00000287682, NEURL1, RHOC, FMNL2, CKB, FTL, CALHM6, HMOX1, BATF3 ACTB, MYOF, CCDC26, IFITM2, PAPSS2, RRAS, LST1, VMO1, SERPINA1, LRRC25 Negative: LINC02458, AKAP12, CA8, ENSG00000250696, SLC24A3, HDC, IL3RA, EPAS1, ENPP3, OSBPL1A TRPM6, CCR3, CSF2RB, SEMA3C, THSD7A, ATP10D, DACH1, CRPPA, ATP8B4, TMEM164 ABHD5, CLC, CR1, ITGB8, LIN7A, TAFA2, MBOAT2, GATA2, DAPK2, GCSAML You have several useful ways to visualize both cells and features that define the PCA, including VizDimReduction() , DimPlot() , and DimHeatmap() . DimPlot(pbmc, reduction = \"pca\") + NoLegend() DimHeatmap() draws a heatmap focusing on a principal component. Both cells and genes are sorted by their principal component scores DimHeatmap(pbmc, dims = 1:3, cells = 500, balanced = TRUE) DimHeatmap(pbmc, dims = 20:22, cells = 500, balanced = TRUE)","title":"Perform linear dimensional reduction"},{"location":"BIOI611_scRNA/#determine-the-dimensionality-of-the-dataset","text":"The elbow plot is a useful tool for determining the number of principal components (PCs) needed to capture the majority of variation in the data. It displays the standard deviation of each PC, with the \"elbow\" point typically serving as the threshold for selecting the most informative PCs. However, identifying the exact location of the elbow can be somewhat subjective. ElbowPlot(pbmc, ndims = 50) # Determine the percentage of variation associated with each PC pct_var <- pbmc[[\"pca\"]]@stdev / sum(pbmc[[\"pca\"]]@stdev) * 100 # Calculate cumulative percentages for each PC cumu_pct <- cumsum(pct_var) # Identify the first PC where cumulative percentage exceeds 90% and individual variance is less than 5% pc_number <- which(cumu_pct > 90 & pct_var < 5)[1] pc_number 41","title":"Determine the \u2018dimensionality\u2019 of the dataset"},{"location":"BIOI611_scRNA/#cluster-the-cells","text":"Seurat embeds cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected quasi-cliques or communities . Seurat first constructs a KNN graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). This step is performed using the FindNeighbors() function, and takes as input the previously defined dimensionality of the dataset. To cluster the cells, Seurat next applies modularity optimization techniques such as the Louvain algorithm (default) or SLM [SLM, Blondel et al., Journal of Statistical Mechanics], to iteratively group cells together, with the goal of optimizing the standard modularity function. The FindClusters() function implements this procedure, and contains a resolution parameter that sets the granularity of the downstream clustering, with increased values leading to a greater number of clusters. We find that setting this parameter between 1 typically returns good results for single-cell datasets of around 5k cells. Optimal resolution often increases for larger datasets. The clusters can be found using the Idents() function. pbmc <- FindNeighbors(pbmc, dims = 1:pc_number) pbmc <- FindClusters(pbmc, resolution = 0.1) Computing nearest neighbor graph Computing SNN Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck Number of nodes: 4559 Number of edges: 184776 Running Louvain algorithm... Maximum modularity in 10 random starts: 0.9713 Number of communities: 10 Elapsed time: 0 seconds # Look at cluster IDs of the first 5 cells head(Idents(pbmc), 5) .dl-inline {width: auto; margin:0; padding: 0} .dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block} .dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex} .dl-inline>dt:not(:first-of-type) {padding-left: .5ex} AAACCCATCAGATGCT-1 1 AAACGAAAGTGCTACT-1 0 AAACGAAGTCGTAATC-1 6 AAACGAAGTTGCCAAT-1 5 AAACGAATCCGAGGCT-1 4 Levels : .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '0' '1' '2' '3' '4' '5' '6' '7' '8' '9'","title":"Cluster the cells"},{"location":"BIOI611_scRNA/#run-non-linear-dimensional-reduction-umaptsne","text":"To visualize and explore these datasets, Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP. The goal of tSNE/UMAP is to learn underlying structure in the dataset, in order to place similar cells together in low-dimensional space. Therefore, cells that are grouped together within graph-based clusters determined above should co-localize on these dimension reduction plots. pbmc <- RunUMAP(pbmc, dims = 1:pc_number) 01:21:37 UMAP embedding parameters a = 0.9922 b = 1.112 01:21:37 Read 4559 rows and found 41 numeric columns 01:21:37 Using Annoy for neighbor search, n_neighbors = 30 01:21:38 Building Annoy index with metric = cosine, n_trees = 50 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * | 01:21:38 Writing NN index file to temp file /tmp/RtmpwNVWV1/file10a4d98f0d9 01:21:38 Searching Annoy index using 1 thread, search_k = 3000 01:21:40 Annoy recall = 100% 01:21:41 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30 01:21:43 Found 2 connected components, falling back to 'spca' initialization with init_sdev = 1 01:21:43 Using 'irlba' for PCA 01:21:43 PCA: 2 components explained 46.09% variance 01:21:43 Scaling init to sdev = 1 01:21:43 Commencing optimization for 500 epochs, with 188320 positive edges 01:21:49 Optimization finished DimPlot(pbmc, reduction = \"umap\")","title":"Run non-linear dimensional reduction (UMAP/tSNE)"},{"location":"BIOI611_scRNA/#finding-differentially-expressed-features-cluster-biomarkers","text":"# find markers for every cluster compared to all remaining cells, report only the positive # ones pbmc.markers <- FindAllMarkers(pbmc, only.pos = TRUE) pbmc.markers %>% group_by(cluster) %>% dplyr::filter(avg_log2FC > 1) Calculating cluster 0 Calculating cluster 1 Calculating cluster 2 Calculating cluster 3 Calculating cluster 4 Calculating cluster 5 Calculating cluster 6 Calculating cluster 7 Calculating cluster 8 Calculating cluster 9 A grouped_df: 14138 \u00d7 7 p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene <dbl> <dbl> <dbl> <dbl> <dbl> <fct> <chr> 0.000000e+00 2.193938 0.974 0.426 0.000000e+00 0 IL32 3.852209e-275 1.679326 0.951 0.362 9.547700e-271 0 CD3D 9.596093e-260 1.803885 0.888 0.352 2.378392e-255 0 TRAC 4.781243e-252 1.573425 0.959 0.532 1.185031e-247 0 SYNE2 3.690404e-235 1.512388 0.917 0.348 9.146665e-231 0 CD3G 9.967907e-232 1.809323 0.910 0.485 2.470546e-227 0 RORA 1.117947e-227 1.378699 0.951 0.380 2.770831e-223 0 CD3E 1.039791e-208 2.253821 0.681 0.233 2.577123e-204 0 NIBAN1 2.027326e-187 1.595996 0.810 0.357 5.024728e-183 0 CD2 8.928063e-181 1.512822 0.846 0.383 2.212820e-176 0 IL7R 2.768362e-179 2.583397 0.463 0.091 6.861385e-175 0 PRDM1 2.609892e-166 1.825963 0.777 0.389 6.468617e-162 0 PPP1R16B 8.007361e-166 3.888615 0.310 0.031 1.984624e-161 0 TRGC2 1.861258e-163 1.694587 0.717 0.296 4.613128e-159 0 CD6 1.403718e-158 1.072541 0.969 0.807 3.479115e-154 0 PPP2R5C 9.430895e-158 2.200303 0.525 0.147 2.337447e-153 0 CD5 5.325382e-153 1.314341 0.835 0.433 1.319896e-148 0 SPOCK2 5.541697e-151 1.501378 0.757 0.363 1.373510e-146 0 GPRIN3 1.783366e-148 1.524168 0.815 0.492 4.420072e-144 0 LRRC8C 5.511823e-146 1.130197 0.937 0.772 1.366105e-141 0 EML4 4.406921e-145 1.807049 0.821 0.535 1.092255e-140 0 TNFAIP3 8.596339e-145 1.322956 0.800 0.391 2.130603e-140 0 LIME1 1.601435e-143 1.301753 0.861 0.505 3.969156e-139 0 ATXN1 3.308730e-140 4.011786 0.283 0.033 8.200689e-136 0 GZMK 1.881698e-138 1.586776 0.770 0.413 4.663787e-134 0 PHACTR2 8.271921e-138 1.486293 0.791 0.479 2.050196e-133 0 TTC39C 8.346144e-135 3.699470 0.245 0.020 2.068592e-130 0 MIAT 2.291535e-126 1.420132 0.725 0.348 5.679570e-122 0 ANK3 2.583870e-126 2.075113 0.477 0.151 6.404121e-122 0 PBX4 3.042390e-125 1.333502 0.694 0.316 7.540564e-121 0 OPTN \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 0.009116629 3.631680 0.021 0.002 1 9 H4C1 0.009116629 3.608558 0.021 0.002 1 9 ENSG00000289291 0.009116629 3.605235 0.021 0.002 1 9 VAMP1-AS1 0.009116629 3.591495 0.021 0.002 1 9 ENSG00000249328 0.009116629 3.567020 0.021 0.002 1 9 ERICH2-DT 0.009116629 3.550000 0.021 0.002 1 9 NLRP10 0.009116629 3.518027 0.021 0.002 1 9 ENSG00000270087 0.009116629 3.496166 0.021 0.002 1 9 ENSG00000253593 0.009116629 3.393207 0.021 0.002 1 9 ADAM11 0.009116629 3.272524 0.021 0.002 1 9 ENSG00000228150 0.009116629 3.266281 0.021 0.002 1 9 LINC03065 0.009116629 3.221456 0.021 0.002 1 9 STARD13-AS 0.009116629 3.109640 0.021 0.002 1 9 FGGY-DT 0.009116629 2.116185 0.021 0.002 1 9 ENSG00000285751 0.009353183 1.486986 0.146 0.057 1 9 TRPM2 0.009560927 1.198107 0.083 0.024 1 9 SYCP3 0.009563781 1.367524 0.062 0.015 1 9 MAP7 0.009595402 1.283987 0.083 0.024 1 9 PPP1R13L 0.009686754 2.584749 0.042 0.008 1 9 PRRG2 0.009706714 2.407445 0.042 0.008 1 9 LINC02185 0.009746744 2.473951 0.042 0.008 1 9 LINC02901 0.009766814 2.300928 0.042 0.008 1 9 WNK3 0.009766814 1.640083 0.042 0.008 1 9 CALCRL-AS1 0.009786921 2.434878 0.042 0.008 1 9 ENSG00000272112 0.009786922 2.438294 0.042 0.008 1 9 ENSG00000277589 0.009847464 2.262934 0.042 0.008 1 9 PCDH15 0.009847464 2.064514 0.042 0.008 1 9 CIBAR1 0.009888011 2.173570 0.042 0.008 1 9 SEZ6 0.009908340 1.746860 0.042 0.008 1 9 RTKN 0.009993542 1.340809 0.146 0.059 1 9 ENSG00000287100 # find all markers distinguishing cluster 5 from clusters 0 and 3 cluster5.markers <- FindMarkers(pbmc, ident.1 = 5, ident.2 = c(0, 3)) head(cluster5.markers, n = 5) A data.frame: 5 \u00d7 5 p_val avg_log2FC pct.1 pct.2 p_val_adj <dbl> <dbl> <dbl> <dbl> <dbl> PTPRK 4.438261e-196 5.477436 0.594 0.020 1.100023e-191 NRCAM 9.537544e-196 7.815745 0.496 0.005 2.363880e-191 AIF1 1.738908e-192 4.287096 0.804 0.077 4.309884e-188 LINC02446 3.824707e-176 4.782107 0.638 0.039 9.479537e-172 NELL2 7.816637e-150 3.058779 0.969 0.213 1.937354e-145 VlnPlot(pbmc, features = c(\"PTPRK\", \"NRCAM\")) VlnPlot(pbmc, features = c(\"NKG7\", \"PF4\"), slot = \"counts\", log = TRUE) Warning message: \u201c\u001b[1m\u001b[22mThe `slot` argument of `VlnPlot()` is deprecated as of Seurat 5.0.0. \u001b[36m\u2139\u001b[39m Please use the `layer` argument instead.\u201d FeaturePlot(pbmc, features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\", \"PPBP\", \"CD8A\")) pbmc.markers %>% group_by(cluster) %>% dplyr::filter(avg_log2FC > 1) %>% slice_head(n = 10) %>% ungroup() -> top10 DoHeatmap(pbmc, features = top10$gene) + NoLegend()","title":"Finding differentially expressed features (cluster biomarkers)"},{"location":"BIOI611_scRNA/#cell-type-annotation-using-singler","text":"library(SingleCellExperiment ) sce <- as.SingleCellExperiment(pbmc) sce <- scater::logNormCounts(sce) sce class: SingleCellExperiment dim: 24785 4559 metadata(0): assays(3): counts logcounts scaledata rownames(24785): ENSG00000238009 ENSG00000241860 ... ENSG00000276345 ENSG00000278817 rowData names(0): colnames(4559): AAACCCATCAGATGCT-1 AAACGAAAGTGCTACT-1 ... TTTGTTGTCGAAGTGG-1 TTTGTTGTCGCATAGT-1 colData names(10): orig.ident nCount_RNA ... ident sizeFactor reducedDimNames(2): PCA UMAP mainExpName: RNA altExpNames(0): # Download and cache the normalized expression values of the data # stored in the Human Primary Cell Atlas. The data will be # downloaded from ExperimentHub, returning a SummarizedExperiment # object for further use. hpca <- HumanPrimaryCellAtlasData() # Obtain human bulk RNA-seq data from Blueprint and ENCODE blueprint <- BlueprintEncodeData() pred.hpca <- SingleR(test = sce, ref = hpca, labels = hpca$label.main) tab_hpca <- table(pred.hpca$pruned.labels) write.csv(sort(tab_hpca, decreasing=TRUE), 'pbmc_annotations_HPCA_general.csv', row.names=FALSE) tab_hpca B_cell BM DC Endothelial_cells 451 30 1 1 Erythroblast GMP HSC_-G-CSF HSC_CD34+ 60 2 11 1 Monocyte Neutrophils NK_cell Platelets 759 39 677 93 Pre-B_cell_CD34- T_cells 2 2350 Each row of the output DataFrame contains prediction results for a single cell. Labels are shown before (labels) and after pruning (pruned.labels), along with the associated scores. head(pred.hpca) DataFrame with 6 rows and 4 columns scores labels delta.next <matrix> <character> <numeric> AAACCCATCAGATGCT-1 0.1409902:0.3257687:0.281000:... T_cells 0.0708860 AAACGAAAGTGCTACT-1 0.1407268:0.3072562:0.264148:... T_cells 0.6026772 AAACGAAGTCGTAATC-1 0.0604399:0.0725122:0.184863:... Erythroblast 0.1268946 AAACGAAGTTGCCAAT-1 0.1585486:0.3228307:0.278787:... T_cells 0.6492489 AAACGAATCCGAGGCT-1 0.1166524:0.3565152:0.277855:... B_cell 0.0505309 AAACGAATCGAACGCC-1 0.1437411:0.3427680:0.299201:... NK_cell 0.3155681 pruned.labels <character> AAACCCATCAGATGCT-1 T_cells AAACGAAAGTGCTACT-1 T_cells AAACGAAGTCGTAATC-1 Erythroblast AAACGAAGTTGCCAAT-1 T_cells AAACGAATCCGAGGCT-1 B_cell AAACGAATCGAACGCC-1 NK_cell pred.blueprint <- SingleR(test = sce, ref = blueprint, labels = blueprint$label.main) tab_blueprint <- table(pred.blueprint$pruned.labels) write.csv(sort(tab_blueprint, decreasing=TRUE), 'pbmc_annotations_BlueprintENCODE_general.csv', row.names=FALSE) tab_blueprint B-cells CD4+ T-cells CD8+ T-cells DC 455 1749 576 3 Endothelial cells Eosinophils Erythrocytes HSC 1 50 128 4 Monocytes Neutrophils NK cells 768 3 692 head(pred.blueprint) DataFrame with 6 rows and 4 columns scores labels delta.next <matrix> <character> <numeric> AAACCCATCAGATGCT-1 0.2145648:0.1136181:0.437872:... CD4+ T-cells 0.0512150 AAACGAAAGTGCTACT-1 0.2311086:0.1664737:0.393066:... CD4+ T-cells 0.3283657 AAACGAAGTCGTAATC-1 0.0977069:0.0728724:0.100641:... Erythrocytes 0.0757261 AAACGAAGTTGCCAAT-1 0.2289000:0.1565938:0.423090:... CD8+ T-cells 0.0620951 AAACGAATCCGAGGCT-1 0.2353403:0.1291495:0.500443:... B-cells 0.1276654 AAACGAATCGAACGCC-1 0.2308036:0.1288775:0.417440:... NK cells 0.1486502 pruned.labels <character> AAACCCATCAGATGCT-1 CD4+ T-cells AAACGAAAGTGCTACT-1 CD4+ T-cells AAACGAAGTCGTAATC-1 Erythrocytes AAACGAAGTTGCCAAT-1 CD8+ T-cells AAACGAATCCGAGGCT-1 B-cells AAACGAATCGAACGCC-1 NK cells pbmc$singleR_hpca = pred.hpca$pruned.labels pbmc$singleR_blueprint = pred.blueprint$pruned.labels Idents(pbmc) = pbmc$singleR_hpca DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5, repel = TRUE) + NoLegend() # Change back to cluster snn_res.0.1 Idents(pbmc) = pbmc$`RNA_snn_res.0.1` Idents(pbmc) = pbmc$singleR_blueprint DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5, repel = TRUE) + NoLegend() # Change back to cluster snn_res.0.1 Idents(pbmc) = pbmc$`RNA_snn_res.0.1`","title":"Cell type annotation using SingleR"},{"location":"BIOI611_scRNA/#manual-annotation","text":"Markers Cell Type IL7R, CCR7 Naive CD4+ T CD14, LYZ CD14+ Mono IL7R, S100A4 Memory CD4+ MS4A1 B CD8A CD8+ T FCGR3A, MS4A7 FCGR3A+ Mono GNLY, NKG7 NK FCER1A, CST3 DC PPBP Platelet table(Idents(pbmc)) 0 1 2 3 4 5 6 7 8 9 1215 938 761 662 465 224 98 94 54 48 FeaturePlot(pbmc, features = c(\"IL7R\", \"CD14\", \"CCR7\", \"S100A4\", \"MS4A1\")) DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5, repel = TRUE) + NoLegend() pbmc = RenameIdents(pbmc, \"2\"=\"CD14+ Mono\") pbmc = RenameIdents(pbmc, \"1\"=\"Naive CD4+ T\") pbmc = RenameIdents(pbmc, \"0\"=\"Memory CD4+\") ### Add more manual annotation based on your checking DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5, repel = TRUE) + NoLegend()","title":"Manual annotation"},{"location":"BIOI611_scRNA/#save-the-seurat-object","text":"saveRDS(pbmc, file = \"Seurat_object_pbmc_final.rds\") remotes::install_github(\"10xGenomics/loupeR\") loupeR::setup() Downloading GitHub repo 10xGenomics/loupeR@HEAD \u001b[36m\u2500\u2500\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m * checking for file \u2018/tmp/RtmpwNVWV1/remotes10a53185aac/10XGenomics-loupeR-a169417/DESCRIPTION\u2019 ... OK * preparing \u2018loupeR\u2019: * checking DESCRIPTION meta-information ... OK * checking for LF line-endings in source and make files and shell scripts * checking for empty or unneeded directories * building \u2018loupeR_1.1.2.tar.gz\u2019 Installing package into \u2018/content/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) Warning message in fun(libname, pkgname): \u201cPlease call `loupeR::setup()` to install the Louper executable and to agree to the EULA before continuing\u201d Installing Executable 2024/11/18 22:56:23 Downloading executable The LoupeR executable is subject to the 10x End User Software License, available at: https://10xgen.com/EULA Do you accept the End-User License Agreement (y/yes or n/no): yes EULA library(loupeR) create_loupe_from_seurat(pbmc, output_name = \"Seurat_object_pbmc_cloupe\") 2024/11/18 22:57:18 extracting matrix, clusters, and projections 2024/11/18 22:57:18 selected assay: RNA 2024/11/18 22:57:18 selected clusters: active_cluster orig.ident RNA_snn_res.0.1 seurat_clusters singleR_hpca singleR_blueprint 2024/11/18 22:57:18 selected projections: umap 2024/11/18 22:57:18 validating count matrix 2024/11/18 22:57:19 validating clusters 2024/11/18 22:57:19 validating projections 2024/11/18 22:57:19 creating temporary hdf5 file: /tmp/RtmpwNVWV1/file10aaeba1e8.h5 2024/11/18 22:57:23 invoking louper executable 2024/11/18 22:57:23 running command: \"/root/.local/share/R/loupeR/louper create --input='/tmp/RtmpwNVWV1/file10aaeba1e8.h5' --output='Seurat_object_pbmc_cloupe.cloupe'\"","title":"Save the Seurat object"},{"location":"BIOI611_scRNA/#reference","text":"https://monashbioinformaticsplatform.github.io/Single-Cell-Workshop/pbmc3k_tutorial.html https://bioinformatics.ccr.cancer.gov/docs/getting-started-with-scrna-seq/IntroToR_Seurat/ https://hbctraining.github.io/scRNA-seq/lessons/elbow_plot_metric.html","title":"Reference"},{"location":"BIOI611_scRNA_cele/","text":"The following note is designed to give you an overview of comparative analyses on complex cell types that are possible using the Seurat integration procedure. Install required R packages # # Install the remotes package # if (!requireNamespace(\"remotes\", quietly = TRUE)) { # install.packages(\"remotes\") # } # # Install Seurat # if (!requireNamespace(\"Seurat\", quietly = TRUE)) { # remotes::install_github(\"satijalab/seurat\", \"seurat5\", quiet = TRUE) # } # # Install BiocManager # if (!require(\"BiocManager\", quietly = TRUE)) # install.packages(\"BiocManager\") # # Install SingleR package # if (!require(\"hdf5r\", quietly = TRUE)){ # BiocManager::install(\"hdf5r\") # } # # Install SingleR package # if (!require(\"presto\", quietly = TRUE)){ # remotes::install_github(\"immunogenomics/presto\") # } # # Install SingleR package # if (!require(\"SingleR\", quietly = TRUE)){ # BiocManager::install(\"SingleR\") # } # if (!require(\"celldex\", quietly = TRUE)){ # BiocManager::install(\"celldex\") # } # if (!require(\"SingleCellExperiment\", quietly = TRUE)){ # BiocManager::install(\"SingleCellExperiment\") # } # if (!require(\"scater\", quietly = TRUE)){ # BiocManager::install(\"scater\") # } ## Installing the R packages could take around 51 minutes ## To speed up this process, you can download the R lib files ## saved from a working Google Colab session ## https://drive.google.com/file/d/1EQvZnsV6P0eNjbW0hwYhz0P5z0iH3bsL/view?usp=drive_link system(\"gdown 1EQvZnsV6P0eNjbW0hwYhz0P5z0iH3bsL\") system(\"md5sum R_lib4scRNA.tar.gz\", intern = TRUE) '5898c04fca5e680710cd6728ef9b1422 R_lib4scRNA.tar.gz' ## required by scater package system(\"apt-get install libx11-dev libcairo2-dev\") #, intern = TRUE) system(\"tar zxvf R_lib4scRNA.tar.gz\") .libPaths(c(\"/content/usr/local/lib/R/site-library\", .libPaths())) .libPaths() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '/content/usr/local/lib/R/site-library' '/usr/local/lib/R/site-library' '/usr/lib/R/site-library' '/usr/lib/R/library' Load required R packages library(Seurat) library(dplyr) library(SingleR) library(celldex) library(scater) library(SingleCellExperiment) Loading required package: SeuratObject Loading required package: sp Attaching package: \u2018SeuratObject\u2019 The following objects are masked from \u2018package:base\u2019: intersect, t Attaching package: \u2018dplyr\u2019 The following objects are masked from \u2018package:stats\u2019: filter, lag The following objects are masked from \u2018package:base\u2019: intersect, setdiff, setequal, union Loading required package: SummarizedExperiment Loading required package: MatrixGenerics Loading required package: matrixStats Attaching package: \u2018matrixStats\u2019 The following object is masked from \u2018package:dplyr\u2019: count Attaching package: \u2018MatrixGenerics\u2019 The following objects are masked from \u2018package:matrixStats\u2019: colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse, colCounts, colCummaxs, colCummins, colCumprods, colCumsums, colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs, colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats, colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds, colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads, colWeightedMeans, colWeightedMedians, colWeightedSds, colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet, rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods, rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps, rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins, rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks, rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars, rowWeightedMads, rowWeightedMeans, rowWeightedMedians, rowWeightedSds, rowWeightedVars Loading required package: GenomicRanges Loading required package: stats4 Loading required package: BiocGenerics Attaching package: \u2018BiocGenerics\u2019 The following objects are masked from \u2018package:dplyr\u2019: combine, intersect, setdiff, union The following object is masked from \u2018package:SeuratObject\u2019: intersect The following objects are masked from \u2018package:stats\u2019: IQR, mad, sd, var, xtabs The following objects are masked from \u2018package:base\u2019: anyDuplicated, aperm, append, as.data.frame, basename, cbind, colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rownames, sapply, saveRDS, setdiff, table, tapply, union, unique, unsplit, which.max, which.min Loading required package: S4Vectors Attaching package: \u2018S4Vectors\u2019 The following objects are masked from \u2018package:dplyr\u2019: first, rename The following object is masked from \u2018package:utils\u2019: findMatches The following objects are masked from \u2018package:base\u2019: expand.grid, I, unname Loading required package: IRanges Attaching package: \u2018IRanges\u2019 The following objects are masked from \u2018package:dplyr\u2019: collapse, desc, slice The following object is masked from \u2018package:sp\u2019: %over% Loading required package: GenomeInfoDb Loading required package: Biobase Welcome to Bioconductor Vignettes contain introductory material; view with 'browseVignettes()'. To cite Bioconductor, see 'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'. Attaching package: \u2018Biobase\u2019 The following object is masked from \u2018package:MatrixGenerics\u2019: rowMedians The following objects are masked from \u2018package:matrixStats\u2019: anyMissing, rowMedians Attaching package: \u2018SummarizedExperiment\u2019 The following object is masked from \u2018package:Seurat\u2019: Assays The following object is masked from \u2018package:SeuratObject\u2019: Assays Attaching package: \u2018celldex\u2019 The following objects are masked from \u2018package:SingleR\u2019: BlueprintEncodeData, DatabaseImmuneCellExpressionData, HumanPrimaryCellAtlasData, ImmGenData, MonacoImmuneData, MouseRNAseqData, NovershternHematopoieticData Loading required package: SingleCellExperiment Loading required package: scuttle Loading required package: ggplot2 list.files() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'R_lib4scRNA.tar.gz' 'sample_data' 'usr' # https://drive.google.com/drive/folders/1lp6kSGFyYYAswfAyG07DgELQ2G2Ja51Q?usp=sharing # Download \"filtered_feature_bc_matrix.h5\" # Output of cellranger system(\"gdown --folder 1lp6kSGFyYYAswfAyG07DgELQ2G2Ja51Q\", intern = TRUE) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'Processing file 1ezH8P0iRpV9fsOOqrqStPxI5-q54Ge9B filtered_feature_bc_matrix_300min.h5' 'Processing file 1hu9c2BhKb5bEYXrPlG_mkSQ219eG-E2K filtered_feature_bc_matrix_400min.h5' 'Processing file 16bSSWAn5Fg_sZgajA4JbuZPoVgulGt_5 filtered_feature_bc_matrix_500min.h5' system(\"md5sum ./cele_cellranger_mtx/*.h5\", intern = TRUE) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'e0fd344696c5188e55aeb359efd7a8c1 ./cele_cellranger_mtx/filtered_feature_bc_matrix_300min.h5' 'd087ff62ba449586858c058117aa0438 ./cele_cellranger_mtx/filtered_feature_bc_matrix_400min.h5' 'efb8a9ef4898918e53a53878531f64ce ./cele_cellranger_mtx/filtered_feature_bc_matrix_500min.h5' # Specify the directory containing the .h5 files mtx_directory <- \"./cele_cellranger_mtx\" # List all .h5 files in the specified directory mtx_file_paths <- list.files(path = mtx_directory, pattern = \"\\\\.h5$\", full.names = TRUE) # Print the file paths mtx_file_paths .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} './cele_cellranger_mtx/filtered_feature_bc_matrix_300min.h5' './cele_cellranger_mtx/filtered_feature_bc_matrix_400min.h5' './cele_cellranger_mtx/filtered_feature_bc_matrix_500min.h5' # Read the files into a list count_mtx_list <- lapply(mtx_file_paths, Read10X_h5) names(count_mtx_list) <- c(\"300min\", \"400min\", \"500min\") names(count_mtx_list) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '300min' '400min' '500min' lapply(count_mtx_list, class) $`300min` 'dgCMatrix' $`400min` 'dgCMatrix' $`500min` 'dgCMatrix' print(format(object.size(count_mtx_list), units = \"MB\")) [1] \"829.8 Mb\" sample_names <- names(count_mtx_list) seurat_obj_list <- list() for (i in seq_along(count_mtx_list)) { seurat_obj <- CreateSeuratObject(counts = count_mtx_list[[i]], project = sample_names[i]) seurat_obj_list[[sample_names[i]]] <- seurat_obj } Warning message: \u201cFeature names cannot have underscores ('_'), replacing with dashes ('-')\u201d Warning message: \u201cFeature names cannot have underscores ('_'), replacing with dashes ('-')\u201d Warning message: \u201cFeature names cannot have underscores ('_'), replacing with dashes ('-')\u201d seurat_obj_list $`300min` An object of class Seurat 19985 features across 25996 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts $`400min` An object of class Seurat 19985 features across 37944 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts $`500min` An object of class Seurat 19985 features across 14378 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts rm(count_mtx_list); gc(); A matrix: 2 \u00d7 6 of type dbl used (Mb) gc trigger (Mb) max used (Mb) Ncells 10810136 577.4 19318554 1031.8 14556029 777.4 Vcells 127080778 969.6 301745553 2302.2 301081234 2297.1 Access Seurat object seurat_obj_list$'300min'@active.assay 'RNA' class(seurat_obj_list$'300min'@meta.data) head(seurat_obj_list$'300min'@meta.data, 4) 'data.frame' A data.frame: 4 \u00d7 3 orig.ident nCount_RNA nFeature_RNA <fct> <dbl> <int> AAACCTGAGACAATAC-1 300min 1630 803 AAACCTGAGACACTAA-1 300min 3147 1365 AAACCTGAGACGCTTT-1 300min 892 586 AAACCTGAGAGGGCTT-1 300min 1666 1033 seurat_obj_list$'300min'@meta.data$orig.ident = \"300min\" seurat_obj_list$'400min'@meta.data$orig.ident = \"400min\" seurat_obj_list$'500min'@meta.data$orig.ident = \"500min\" head(seurat_obj_list$'300min'@meta.data, 4) A data.frame: 4 \u00d7 3 orig.ident nCount_RNA nFeature_RNA <chr> <dbl> <int> AAACCTGAGACAATAC-1 300min 1630 803 AAACCTGAGACACTAA-1 300min 3147 1365 AAACCTGAGACGCTTT-1 300min 892 586 AAACCTGAGAGGGCTT-1 300min 1666 1033 Layers(seurat_obj_list$'300min') 'counts' seurat_obj_list$'300min'@version [1] \u20185.0.2\u2019 Data preprocessing Ensembl biomart can be used to extract the mitochodria genes: https://useast.ensembl.org/info/website/archives/assembly.html Gene stable ID Gene name WBGene00000829 ctb-1 WBGene00010957 nduo-6 WBGene00010958 WBGene00010958 WBGene00010959 WBGene00010959 WBGene00010960 atp-6 WBGene00010961 nduo-2 WBGene00010962 ctc-3 WBGene00010963 nduo-4 WBGene00010964 ctc-1 WBGene00010965 ctc-2 WBGene00010966 nduo-3 WBGene00010967 nduo-5 # Define the mitochondria gene names as an R vector mt_gene_names <- c( \"ctb-1\", \"nduo-6\", \"WBGene00010958\", \"WBGene00010959\", \"atp-6\", \"nduo-2\", \"ctc-3\", \"nduo-4\", \"ctc-1\", \"ctc-2\", \"nduo-3\", \"nduo-5\" ) mt_genes <- mt_gene_names[mt_gene_names %in% rownames(seurat_obj_list$'300min')] mt_genes .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'ctb-1' 'nduo-6' 'WBGene00010958' 'WBGene00010959' 'atp-6' 'nduo-2' 'ctc-3' 'nduo-4' 'ctc-1' 'ctc-2' 'nduo-3' 'nduo-5' # Function to calculate percentage of mitochondrial genes add_mt_percentage <- function(seurat_obj, mt_genes) { # Calculate percentage of mitochondrial genes seurat_obj$percent.mt <- PercentageFeatureSet(seurat_obj, features = mt_genes) return(seurat_obj) } seurat_obj_list <- lapply(seurat_obj_list, add_mt_percentage, mt_genes = mt_genes) qc_features <- c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\") VlnPlot(seurat_obj_list$'300min', features = qc_features, ncol = 3, pt.size=0) VlnPlot(seurat_obj_list$'400min', features = qc_features, ncol = 3, pt.size=0) VlnPlot(seurat_obj_list$'500min', features = qc_features, ncol = 3, pt.size=0) Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d How to interpret QC plot nFeature_RNA : The number of unique features (genes) detected per cell. Extremely high values could suggest potential doublets (two cells mistakenly captured as one), as two cells would have more unique genes combined. Low number of detected genes - potential ambient mRNA (not real cells) nCount_RNA : The total number of RNA molecules (or unique molecular identifiers, UMIs) detected per cell. Higher counts generally indicate higher RNA content, but they could also result from cell doublets. Cells with very low nCount_RNA might represent poor-quality cells with low RNA capture, while very high counts may also suggest doublets. percent.mt : The percentage of reads mapping to mitochondrial genes. High mitochondrial content often indicates cell stress or apoptosis, as damaged cells tend to release mitochondrial RNA. Filtering cells with high percent.mt values is common to exclude potentially dying cells. # FeatureScatter is typically used to visualize feature-feature relationships, but can be used # for anything calculated by the object, i.e. columns in object metadata, PC scores etc. plot1 <- FeatureScatter(seurat_obj_list$'300min', feature1 = \"nCount_RNA\", feature2 = \"percent.mt\") plot2 <- FeatureScatter(seurat_obj_list$'300min', feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\") plot1 + plot2 Filter out potential doublets, empty droplets and dying cells # Load necessary libraries library(Seurat) library(ggplot2) # Define the function to calculate median and MAD values calculate_thresholds <- function(seurat_obj) { # Extract relevant columns nFeature_values <- seurat_obj@meta.data$nFeature_RNA nCount_values <- seurat_obj@meta.data$nCount_RNA percent_mt_values <- seurat_obj@meta.data$percent.mt # Calculate medians and MADs nFeature_median <- median(nFeature_values, na.rm = TRUE) nFeature_mad <- mad(nFeature_values, constant = 1, na.rm = TRUE) nCount_median <- median(nCount_values, na.rm = TRUE) nCount_mad <- mad(nCount_values, constant = 1, na.rm = TRUE) percent_mt_median <- median(percent_mt_values, na.rm = TRUE) percent_mt_mad <- mad(percent_mt_values, constant = 1, na.rm = TRUE) # Calculate thresholds for horizontal lines thresholds <- list( nFeature_upper = nFeature_median + 4 * nFeature_mad, nFeature_lower = nFeature_median - 4 * nFeature_mad, nCount_upper = nCount_median + 4 * nCount_mad, nCount_lower = nCount_median - 4 * nCount_mad, percent_mt_upper = percent_mt_median + 4 * percent_mt_mad ) return(thresholds) } # Define a function to filter Seurat objects filter_seurat_obj <- function(seurat_obj) { # Calculate thresholds thresholds <- calculate_thresholds(seurat_obj) # Apply filtering seurat_obj <- subset( seurat_obj, subset = nFeature_RNA > thresholds$nFeature_lower & nFeature_RNA < thresholds$nFeature_upper & percent.mt < thresholds$percent_mt_upper ) # return(seurat_obj) } # Apply filtering to each Seurat object in the list seurat_obj_list <- lapply(seurat_obj_list, filter_seurat_obj) VlnPlot(seurat_obj_list$'300min', features = qc_features, ncol = 3, pt.size=0) VlnPlot(seurat_obj_list$'400min', features = qc_features, ncol = 3, pt.size=0) VlnPlot(seurat_obj_list$'500min', features = qc_features, ncol = 3, pt.size=0) Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d RandomSubsetSeurat <- function(seurat_obj, subset_size, seed = NULL) { # Optionally set a random seed for reproducibility if (!is.null(seed)) { set.seed(seed) } # Get all cell names total_cells <- Cells(seurat_obj) # Ensure subset size is not larger than the total number of cells if (subset_size > length(total_cells)) { stop(\"Subset size exceeds the total number of cells in the Seurat object.\") } # Randomly sample a subset of cell names subset_cells <- sample(total_cells, size = subset_size) # Create a new Seurat object with the subsetted cells subset_seurat_obj <- subset(seurat_obj, cells = subset_cells) return(subset_seurat_obj) } \u26a0\ufe0f Important This is included only to reduce the memory used. In real project, you don't want to perform this step. Instead, you should request larger memory computing resources. seurat_obj_list <- lapply(seurat_obj_list, RandomSubsetSeurat, subset_size = 2000, seed = 123) seurat_obj_list $`300min` An object of class Seurat 19985 features across 2000 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts $`400min` An object of class Seurat 19985 features across 2000 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts $`500min` An object of class Seurat 19985 features across 2000 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts so_merged <- merge(seurat_obj_list$'300min', c(seurat_obj_list$'400min', seurat_obj_list$'500min'), add.cell.ids = c(\"300min\", \"400min\", \"500min\"), project = \"scRNA_cele\") so_merged Layers(so_merged) table(so_merged$orig.ident) An object of class Seurat 19985 features across 6000 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 3 layers present: counts.300min, counts.400min, counts.500min .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'counts.300min' 'counts.400min' 'counts.500min' 300min 400min 500min 2000 2000 2000 #rm(seurat_obj_list); gc(); Instead of using an arbitrary number, you can also use statistical algorithm to predict doublets and empty droplets to filter the cells, such as DoubletFinder and EmptyDrops . Normalization, ccaling of the data and linear dimensional reduction Normalization After removing unwanted cells from the dataset, the next step is to normalize the data. By default, a global-scaling normalization method \u201cLogNormalize\u201d that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. In Seurat v5, Normalized values are stored in pbmc[[\"RNA\"]]$data . While this method of normalization is standard and widely used in scRNA-seq analysis, global-scaling relies on an assumption that each cell originally contains the same number of RNA molecules. Next, we identify a subset of features that show high variation across cells in the dataset\u2014meaning they are highly expressed in some cells and lowly expressed in others. Prior work, including our own, has shown that focusing on these variable genes in downstream analyses can enhance the detection of biological signals in single-cell datasets. The approach used in Seurat improves upon previous versions by directly modeling the inherent mean-variance relationship in single-cell data. This method is implemented in the FindVariableFeatures() function, which, by default, selects 2,000 variable features per dataset. These features will then be used in downstream analyses, such as PCA. Scaling the data Next, we apply a linear transformation ( scaling ) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData() function: Shifts the expression of each gene, so that the mean expression across cells is 0 Scales the expression of each gene, so that the variance across cells is 1 This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate The results of this are stored in pbmc[[\"RNA\"]]$scale.data By default, only variable features are scaled. You can specify the features argument to scale additional features. # run standard anlaysis workflow so_merged <- NormalizeData(so_merged) so_merged <- FindVariableFeatures(so_merged) so_merged <- ScaleData(so_merged) so_merged <- RunPCA(so_merged) Normalizing layer: counts.300min Normalizing layer: counts.400min Normalizing layer: counts.500min Finding variable features for layer counts.300min Finding variable features for layer counts.400min Finding variable features for layer counts.500min Centering and scaling data matrix PC_ 1 Positive: noah-1, noah-2, dpy-2, dpy-3, mlt-11, col-76, mlt-8, dpy-7, dpy-10, hch-1 col-121, dpy-17, dpy-14, txdc-12.2, sym-1, C01H6.8, Y41D4B.6, sqt-3, Y23H5B.8, K02E10.4 acn-1, C05C8.7, C26B9.3, R148.5, C48E7.1, dsl-6, inx-12, cpg-24, R05D3.9, F37C4.4 Negative: ost-1, pat-10, D2092.4, mlc-3, let-2, unc-15, lev-11, emb-9, tni-1, set-18 tnt-3, sgn-1, test-1, hsp-12.1, unc-98, cpn-3, sgcb-1, F53F10.1, spp-15, mup-2 Y71F9AR.2, mlc-1, C29F5.1, mlc-2, clik-1, stn-2, mig-18, F21H7.3, unc-60, Y73F8A.26 PC_ 2 Positive: asp-4, enpl-1, C50F4.6, T02E9.5, his-24, atz-1, R07E5.17, C03C10.5, nphp-1, hil-3 tmem-231, mksr-2, tctn-1, fmi-1, jbts-14, osm-5, bbs-9, ift-81, fbxb-66, K02B12.2 mks-2, ift-20, K07C11.10, che-13, R01H2.8, ifta-2, F48E3.9, arl-3, ccep-290, tmem-17 Negative: unc-15, sgn-1, D2092.4, C29F5.1, let-2, lev-11, tnt-3, mlc-2, mup-2, mlc-1 tni-1, test-1, mig-18, clik-1, hsp-12.1, mlc-3, ttn-1, F21H7.3, sgca-1, emb-9 set-18, icl-1, ost-1, myo-3, unc-54, sgcb-1, hsp-12.2, unc-98, stn-2, Y71F9AR.2 PC_ 3 Positive: mks-2, arl-3, mksr-2, ift-81, ifta-2, dylt-2, tmem-231, K07C11.10, che-13, ift-20 ccep-290, bbs-5, osm-5, C33A12.4, ift-74, R01H2.8, Y102A11A.9, bbs-9, tctn-1, lgc-20 dyf-1, mks-1, T02G5.3, dyf-3, arl-13, nphp-1, tmem-17, Y17D7B.10, bbs-2, F01E11.3 Negative: his-24, Y37E3.30, atz-1, lbp-1, C01G6.3, cht-1, ttr-50, clec-266, Y65A5A.1, enpl-1 hil-3, clec-196, idh-1, dsl-3, fbxb-66, cpg-20, F53B3.5, Y71F9AL.7, fbn-1, E01G4.5 pmt-2, ZK512.1, cutl-2, Y43F8B.2, cpg-24, F55C9.5, Y71F9AL.6, W04H10.6, fbxb-101, lam-3 PC_ 4 Positive: arl-3, ifta-2, mks-2, mksr-2, tmem-231, ift-81, che-13, K07C11.10, ift-20, dylt-2 Y55D5A.1, bbs-9, ift-74, ccep-290, tctn-1, dsl-3, cutl-2, T02G5.3, R01H2.8, bbs-5 osm-5, nphp-1, dyf-1, lgc-20, dyf-3, arl-13, mks-1, Y102A11A.9, tmem-17, bbs-2 Negative: mab-7, wrt-2, abu-13, mlt-9, sups-1, clec-180, Y73E7A.8, C01G6.9, wrt-1, R07E3.6 Y54G2A.76, K08B12.1, mam-3, T19A5.3, glf-1, ZC449.1, H03E18.1, M03B6.3, ZK154.1, Y11D7A.9 pqn-32, F01D5.6, C35A5.11, F33D4.6, C52G5.2, grl-15, T03D8.6, F23H12.5, cut-6, ZC123.1 PC_ 5 Positive: F33H2.8, nhr-127, F37A4.3, bus-17, nhr-270, sams-1, bus-12, F18A11.2, W04H10.6, oac-51 elt-1, F54B11.10, T13H10.2, nhr-218, rocf-1, Y6D1A.2, txdc-12.1, T04G9.4, F32H2.6, subs-4 fbn-1, F13G3.3, T03G6.1, nhr-94, C35A5.5, fbxa-52, fasn-1, nstp-3, W03B1.3, bus-8 Negative: Y41D4B.6, B0205.4, C06C3.4, T01D1.8, F43D9.1, F11E6.9, F31C3.6, dsl-6, ttr-2, T19C4.1 F46G11.6, K02E10.4, best-14, nhx-1, ifa-3, T25B9.1, F46F11.7, Y45F10B.59, F15B9.8, C24B5.4 T19B10.5, clec-78, cpt-4, C49F5.13, srm-1, H41C03.1, B0393.5, C53A5.2, ttr-3, far-5 DimPlot(so_merged, reduction = \"pca\", split.by = 'orig.ident', label.color = \"black\") + NoLegend() so_merged <- FindNeighbors(so_merged, dims = 1:30, reduction = \"pca\") so_merged <- FindClusters(so_merged, resolution = 2, cluster.name = \"unintegrated_clusters\") Computing nearest neighbor graph Computing SNN Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck Number of nodes: 6000 Number of edges: 197290 Running Louvain algorithm... Maximum modularity in 10 random starts: 0.8357 Number of communities: 37 Elapsed time: 0 seconds You have several useful ways to visualize both cells and features that define the PCA, including VizDimReduction() , DimPlot() , and DimHeatmap() . DimHeatmap() draws a heatmap focusing on a principal component. Both cells and genes are sorted by their principal component scores Perform analysis without integration To visualize and explore these datasets, Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP. The goal of tSNE/UMAP is to learn underlying structure in the dataset, in order to place similar cells together in low-dimensional space. Therefore, cells that are grouped together within graph-based clusters determined above should co-localize on these dimension reduction plots. so_merged <- RunUMAP(so_merged, dims = 1:30, reduction = \"pca\", reduction.name = \"umap.unintegrated\") Warning message: \u201cThe default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric To use Python UMAP via reticulate, set umap.method to 'umap-learn' and metric to 'correlation' This message will be shown once per session\u201d 22:47:06 UMAP embedding parameters a = 0.9922 b = 1.112 22:47:06 Read 6000 rows and found 30 numeric columns 22:47:06 Using Annoy for neighbor search, n_neighbors = 30 22:47:06 Building Annoy index with metric = cosine, n_trees = 50 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * | 22:47:07 Writing NN index file to temp file /tmp/Rtmp9vMJuf/file43d447d49a3 22:47:07 Searching Annoy index using 1 thread, search_k = 3000 22:47:10 Annoy recall = 100% 22:47:11 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30 22:47:15 Initializing from normalized Laplacian + noise (using RSpectra) 22:47:15 Commencing optimization for 500 epochs, with 241186 positive edges 22:47:25 Optimization finished DimPlot(so_merged, reduction = \"umap.unintegrated\", split.by = c(\"orig.ident\")) FeaturePlot(so_merged, feature=\"ham-1\", pt.size = 0.1, split.by = c(\"orig.ident\")) FeaturePlot(so_merged, feature=\"egl-21\", pt.size = 0.1, split.by = c(\"orig.ident\")) FeaturePlot(so_merged, feature=\"dsl-3\", pt.size = 0.1, split.by = c(\"orig.ident\")) Perform integration Seurat v5 enables streamlined integrative analysis using the IntegrateLayers function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches: Anchor-based CCA integration (method=CCAIntegration) Harmony (method=HarmonyIntegration) Anchor-based RPCA integration (method=RPCAIntegration) FastMNN (method= FastMNNIntegration) scVI (method=scVIIntegration) Canonical correlation analysis: CCA Reciprocal PCA: RPCA CCAIntegration integration method that is available in the Seurat package utilizes the canonical correlation analysis (CCA). This method expects \u201ccorrespondences\u201d or shared biological states among at least a subset of single cells across the groups. so_merged_integ <- IntegrateLayers(object = so_merged, method = CCAIntegration, orig.reduction = \"pca\", new.reduction = \"integrated.cca\", verbose = FALSE) Once integrative analysis is complete, you can rejoin the layers - which collapses the individual datasets together and recreates the original counts and data layers. You will need to do this before performing any differential expression analysis. However, you can always resplit the layers in case you would like to reperform integrative analysis. # re-join layers after integration so_merged_integ[[\"RNA\"]] <- JoinLayers(so_merged_integ[[\"RNA\"]]) so_merged_integ <- FindNeighbors(so_merged_integ, reduction = \"integrated.cca\", dims = 1:30) so_merged_integ <- FindClusters(so_merged_integ, resolution = 2) Computing nearest neighbor graph Computing SNN Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck Number of nodes: 6000 Number of edges: 203509 Running Louvain algorithm... Maximum modularity in 10 random starts: 0.8373 Number of communities: 37 Elapsed time: 1 seconds so_merged_integ <- RunUMAP(so_merged_integ, dims = 1:30, reduction = \"integrated.cca\") 22:48:04 UMAP embedding parameters a = 0.9922 b = 1.112 22:48:04 Read 6000 rows and found 30 numeric columns 22:48:04 Using Annoy for neighbor search, n_neighbors = 30 22:48:04 Building Annoy index with metric = cosine, n_trees = 50 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * | 22:48:06 Writing NN index file to temp file /tmp/Rtmp9vMJuf/file43d7e00c0c4 22:48:06 Searching Annoy index using 1 thread, search_k = 3000 22:48:09 Annoy recall = 100% 22:48:10 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30 22:48:13 Initializing from normalized Laplacian + noise (using RSpectra) 22:48:13 Commencing optimization for 500 epochs, with 243916 positive edges 22:48:24 Optimization finished DimPlot(so_merged_integ, reduction = \"umap\", split.by = c(\"orig.ident\")) DefaultAssay(so_merged_integ) 'RNA' markers <- FindAllMarkers(so_merged_integ) Calculating cluster 0 Calculating cluster 1 Calculating cluster 2 Calculating cluster 3 Calculating cluster 4 Calculating cluster 5 Calculating cluster 6 Calculating cluster 7 Calculating cluster 8 Calculating cluster 9 Calculating cluster 10 Calculating cluster 11 Calculating cluster 12 Calculating cluster 13 Calculating cluster 14 Calculating cluster 15 Calculating cluster 16 Calculating cluster 17 Calculating cluster 18 Calculating cluster 19 Calculating cluster 20 Calculating cluster 21 Calculating cluster 22 Calculating cluster 23 Calculating cluster 24 Calculating cluster 25 Calculating cluster 26 Calculating cluster 27 Calculating cluster 28 Calculating cluster 29 Calculating cluster 30 Calculating cluster 31 Calculating cluster 32 Calculating cluster 33 Calculating cluster 34 Calculating cluster 35 Calculating cluster 36 markers %>% group_by(cluster) %>% dplyr::filter(avg_log2FC > 1) %>% slice_head(n = 2) %>% ungroup() -> top2 DoHeatmap(so_merged_integ, features = top2$gene) + NoLegend() Warning message in DoHeatmap(so_merged_integ, features = top2$gene): \u201cThe following features were omitted as they were not found in the scale.data slot for the RNA assay: nmur-3, timp-1, acp-6, C14A4.6, skpo-2, mltn-13, srw-12, F59C6.8, T03G11.9, C02F5.2, C33D9.10, lev-9, C08F1.6, cank-26, egl-21\u201d head(markers) A data.frame: 6 \u00d7 7 p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene <dbl> <dbl> <dbl> <dbl> <dbl> <fct> <chr> F36H1.11 0.000000e+00 5.450659 0.570 0.048 0.000000e+00 0 F36H1.11 egl-21 1.563079e-282 3.984563 0.577 0.058 3.123813e-278 0 egl-21 T10B5.4 1.850416e-276 3.373848 0.792 0.138 3.698057e-272 0 T10B5.4 madd-4 1.841569e-242 4.579571 0.420 0.030 3.680376e-238 0 madd-4 F28E10.1 8.224195e-225 3.734330 0.746 0.167 1.643605e-220 0 F28E10.1 C31H5.5 8.048185e-222 4.466041 0.411 0.034 1.608430e-217 0 C31H5.5 FeaturePlot(so_merged_integ, reduction = \"umap\", feature=\"ham-1\", pt.size = 0.1, split.by = c(\"orig.ident\")) so_merged_integ An object of class Seurat 19985 features across 6000 samples within 1 assay Active assay: RNA (19985 features, 2000 variable features) 3 layers present: data, counts, scale.data 4 dimensional reductions calculated: pca, umap.unintegrated, integrated.cca, umap FeaturePlot(so_merged_integ, reduction = \"umap\", feature=\"egl-21\", pt.size = 0.1, split.by = c(\"orig.ident\")) FeaturePlot(so_merged_integ, reduction = \"umap\", feature=\"dsl-3\", pt.size = 0.1, split.by = c(\"orig.ident\")) With the integrated Seurat object, you can perform cell type annotation using marker genes. \u26a0\ufe0f Important In this class, we will not perform cell type annotation for this dataset. With the notebook for analyzing the human PBMC data, you will be able to perform cell type annnotation if needed. In the next section, you will learn how to perform trajectory and pseudotime analysis. You will directly utilize the annotation performed by the authors who generated this dataset in the Science paper . The data can be obtained using the URLs below: ## count matrix https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_expression.rds ## metadata https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_colData.rds ## gene list https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_rowData.rds Save the Seurat object saveRDS(so_merged_integ, file = \"Seurat_object_10x_cele_final.rds\") remotes::install_github(\"10xGenomics/loupeR\") loupeR::setup() Downloading GitHub repo 10xGenomics/loupeR@HEAD promises (1.3.0 -> 1.3.2 ) [CRAN] later (1.3.2 -> 1.4.1 ) [CRAN] progressr (0.15.0 -> 0.15.1) [CRAN] Installing 3 packages: promises, later, progressr Installing packages into \u2018/content/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) \u001b[36m\u2500\u2500\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m * checking for file \u2018/tmp/Rtmp9vMJuf/remotes43d20adbcde/10XGenomics-loupeR-a169417/DESCRIPTION\u2019 ... OK * preparing \u2018loupeR\u2019: * checking DESCRIPTION meta-information ... OK * checking for LF line-endings in source and make files and shell scripts * checking for empty or unneeded directories * building \u2018loupeR_1.1.2.tar.gz\u2019 Installing package into \u2018/content/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) Warning message in fun(libname, pkgname): \u201cPlease call `loupeR::setup()` to install the Louper executable and to agree to the EULA before continuing\u201d Installing Executable 2024/12/02 22:51:21 Downloading executable The LoupeR executable is subject to the 10x End User Software License, available at: https://10xgen.com/EULA Do you accept the End-User License Agreement (y/yes or n/no): yes EULA library(loupeR) create_loupe_from_seurat(so_merged_integ, output_name = \"Seurat_object_10x_cele_merged_integ\", force = TRUE) 2024/12/02 22:56:56 extracting matrix, clusters, and projections 2024/12/02 22:56:56 selected assay: RNA 2024/12/02 22:56:56 selected clusters: active_cluster orig.ident unintegrated_clusters seurat_clusters RNA_snn_res.2 2024/12/02 22:56:56 selected projections: umap.unintegrated umap 2024/12/02 22:56:56 validating count matrix 2024/12/02 22:56:56 validating clusters 2024/12/02 22:56:56 validating projections 2024/12/02 22:56:56 creating temporary hdf5 file: /tmp/Rtmp9vMJuf/file43d561ea60d.h5 2024/12/02 22:56:59 invoking louper executable 2024/12/02 22:56:59 running command: \"/root/.local/share/R/loupeR/louper create --input='/tmp/Rtmp9vMJuf/file43d561ea60d.h5' --output='Seurat_object_10x_cele_merged_integ.cloupe' --force\" Reference https://monashbioinformaticsplatform.github.io/Single-Cell-Workshop/pbmc3k_tutorial.html https://bioinformatics.ccr.cancer.gov/docs/getting-started-with-scrna-seq/IntroToR_Seurat/ https://hbctraining.github.io/scRNA-seq/lessons/elbow_plot_metric.html https://satijalab.org/seurat/articles/integration_introduction","title":"Downstream analysis of 10x scRNA-seq data for C. elegans data"},{"location":"BIOI611_scRNA_cele/#_1","text":"The following note is designed to give you an overview of comparative analyses on complex cell types that are possible using the Seurat integration procedure.","title":""},{"location":"BIOI611_scRNA_cele/#install-required-r-packages","text":"# # Install the remotes package # if (!requireNamespace(\"remotes\", quietly = TRUE)) { # install.packages(\"remotes\") # } # # Install Seurat # if (!requireNamespace(\"Seurat\", quietly = TRUE)) { # remotes::install_github(\"satijalab/seurat\", \"seurat5\", quiet = TRUE) # } # # Install BiocManager # if (!require(\"BiocManager\", quietly = TRUE)) # install.packages(\"BiocManager\") # # Install SingleR package # if (!require(\"hdf5r\", quietly = TRUE)){ # BiocManager::install(\"hdf5r\") # } # # Install SingleR package # if (!require(\"presto\", quietly = TRUE)){ # remotes::install_github(\"immunogenomics/presto\") # } # # Install SingleR package # if (!require(\"SingleR\", quietly = TRUE)){ # BiocManager::install(\"SingleR\") # } # if (!require(\"celldex\", quietly = TRUE)){ # BiocManager::install(\"celldex\") # } # if (!require(\"SingleCellExperiment\", quietly = TRUE)){ # BiocManager::install(\"SingleCellExperiment\") # } # if (!require(\"scater\", quietly = TRUE)){ # BiocManager::install(\"scater\") # } ## Installing the R packages could take around 51 minutes ## To speed up this process, you can download the R lib files ## saved from a working Google Colab session ## https://drive.google.com/file/d/1EQvZnsV6P0eNjbW0hwYhz0P5z0iH3bsL/view?usp=drive_link system(\"gdown 1EQvZnsV6P0eNjbW0hwYhz0P5z0iH3bsL\") system(\"md5sum R_lib4scRNA.tar.gz\", intern = TRUE) '5898c04fca5e680710cd6728ef9b1422 R_lib4scRNA.tar.gz' ## required by scater package system(\"apt-get install libx11-dev libcairo2-dev\") #, intern = TRUE) system(\"tar zxvf R_lib4scRNA.tar.gz\") .libPaths(c(\"/content/usr/local/lib/R/site-library\", .libPaths())) .libPaths() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '/content/usr/local/lib/R/site-library' '/usr/local/lib/R/site-library' '/usr/lib/R/site-library' '/usr/lib/R/library'","title":"Install required R packages"},{"location":"BIOI611_scRNA_cele/#load-required-r-packages","text":"library(Seurat) library(dplyr) library(SingleR) library(celldex) library(scater) library(SingleCellExperiment) Loading required package: SeuratObject Loading required package: sp Attaching package: \u2018SeuratObject\u2019 The following objects are masked from \u2018package:base\u2019: intersect, t Attaching package: \u2018dplyr\u2019 The following objects are masked from \u2018package:stats\u2019: filter, lag The following objects are masked from \u2018package:base\u2019: intersect, setdiff, setequal, union Loading required package: SummarizedExperiment Loading required package: MatrixGenerics Loading required package: matrixStats Attaching package: \u2018matrixStats\u2019 The following object is masked from \u2018package:dplyr\u2019: count Attaching package: \u2018MatrixGenerics\u2019 The following objects are masked from \u2018package:matrixStats\u2019: colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse, colCounts, colCummaxs, colCummins, colCumprods, colCumsums, colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs, colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats, colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds, colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads, colWeightedMeans, colWeightedMedians, colWeightedSds, colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet, rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods, rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps, rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins, rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks, rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars, rowWeightedMads, rowWeightedMeans, rowWeightedMedians, rowWeightedSds, rowWeightedVars Loading required package: GenomicRanges Loading required package: stats4 Loading required package: BiocGenerics Attaching package: \u2018BiocGenerics\u2019 The following objects are masked from \u2018package:dplyr\u2019: combine, intersect, setdiff, union The following object is masked from \u2018package:SeuratObject\u2019: intersect The following objects are masked from \u2018package:stats\u2019: IQR, mad, sd, var, xtabs The following objects are masked from \u2018package:base\u2019: anyDuplicated, aperm, append, as.data.frame, basename, cbind, colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rownames, sapply, saveRDS, setdiff, table, tapply, union, unique, unsplit, which.max, which.min Loading required package: S4Vectors Attaching package: \u2018S4Vectors\u2019 The following objects are masked from \u2018package:dplyr\u2019: first, rename The following object is masked from \u2018package:utils\u2019: findMatches The following objects are masked from \u2018package:base\u2019: expand.grid, I, unname Loading required package: IRanges Attaching package: \u2018IRanges\u2019 The following objects are masked from \u2018package:dplyr\u2019: collapse, desc, slice The following object is masked from \u2018package:sp\u2019: %over% Loading required package: GenomeInfoDb Loading required package: Biobase Welcome to Bioconductor Vignettes contain introductory material; view with 'browseVignettes()'. To cite Bioconductor, see 'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'. Attaching package: \u2018Biobase\u2019 The following object is masked from \u2018package:MatrixGenerics\u2019: rowMedians The following objects are masked from \u2018package:matrixStats\u2019: anyMissing, rowMedians Attaching package: \u2018SummarizedExperiment\u2019 The following object is masked from \u2018package:Seurat\u2019: Assays The following object is masked from \u2018package:SeuratObject\u2019: Assays Attaching package: \u2018celldex\u2019 The following objects are masked from \u2018package:SingleR\u2019: BlueprintEncodeData, DatabaseImmuneCellExpressionData, HumanPrimaryCellAtlasData, ImmGenData, MonacoImmuneData, MouseRNAseqData, NovershternHematopoieticData Loading required package: SingleCellExperiment Loading required package: scuttle Loading required package: ggplot2 list.files() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'R_lib4scRNA.tar.gz' 'sample_data' 'usr' # https://drive.google.com/drive/folders/1lp6kSGFyYYAswfAyG07DgELQ2G2Ja51Q?usp=sharing # Download \"filtered_feature_bc_matrix.h5\" # Output of cellranger system(\"gdown --folder 1lp6kSGFyYYAswfAyG07DgELQ2G2Ja51Q\", intern = TRUE) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'Processing file 1ezH8P0iRpV9fsOOqrqStPxI5-q54Ge9B filtered_feature_bc_matrix_300min.h5' 'Processing file 1hu9c2BhKb5bEYXrPlG_mkSQ219eG-E2K filtered_feature_bc_matrix_400min.h5' 'Processing file 16bSSWAn5Fg_sZgajA4JbuZPoVgulGt_5 filtered_feature_bc_matrix_500min.h5' system(\"md5sum ./cele_cellranger_mtx/*.h5\", intern = TRUE) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'e0fd344696c5188e55aeb359efd7a8c1 ./cele_cellranger_mtx/filtered_feature_bc_matrix_300min.h5' 'd087ff62ba449586858c058117aa0438 ./cele_cellranger_mtx/filtered_feature_bc_matrix_400min.h5' 'efb8a9ef4898918e53a53878531f64ce ./cele_cellranger_mtx/filtered_feature_bc_matrix_500min.h5' # Specify the directory containing the .h5 files mtx_directory <- \"./cele_cellranger_mtx\" # List all .h5 files in the specified directory mtx_file_paths <- list.files(path = mtx_directory, pattern = \"\\\\.h5$\", full.names = TRUE) # Print the file paths mtx_file_paths .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} './cele_cellranger_mtx/filtered_feature_bc_matrix_300min.h5' './cele_cellranger_mtx/filtered_feature_bc_matrix_400min.h5' './cele_cellranger_mtx/filtered_feature_bc_matrix_500min.h5' # Read the files into a list count_mtx_list <- lapply(mtx_file_paths, Read10X_h5) names(count_mtx_list) <- c(\"300min\", \"400min\", \"500min\") names(count_mtx_list) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '300min' '400min' '500min' lapply(count_mtx_list, class) $`300min` 'dgCMatrix' $`400min` 'dgCMatrix' $`500min` 'dgCMatrix' print(format(object.size(count_mtx_list), units = \"MB\")) [1] \"829.8 Mb\" sample_names <- names(count_mtx_list) seurat_obj_list <- list() for (i in seq_along(count_mtx_list)) { seurat_obj <- CreateSeuratObject(counts = count_mtx_list[[i]], project = sample_names[i]) seurat_obj_list[[sample_names[i]]] <- seurat_obj } Warning message: \u201cFeature names cannot have underscores ('_'), replacing with dashes ('-')\u201d Warning message: \u201cFeature names cannot have underscores ('_'), replacing with dashes ('-')\u201d Warning message: \u201cFeature names cannot have underscores ('_'), replacing with dashes ('-')\u201d seurat_obj_list $`300min` An object of class Seurat 19985 features across 25996 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts $`400min` An object of class Seurat 19985 features across 37944 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts $`500min` An object of class Seurat 19985 features across 14378 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts rm(count_mtx_list); gc(); A matrix: 2 \u00d7 6 of type dbl used (Mb) gc trigger (Mb) max used (Mb) Ncells 10810136 577.4 19318554 1031.8 14556029 777.4 Vcells 127080778 969.6 301745553 2302.2 301081234 2297.1","title":"Load required R packages"},{"location":"BIOI611_scRNA_cele/#access-seurat-object","text":"seurat_obj_list$'300min'@active.assay 'RNA' class(seurat_obj_list$'300min'@meta.data) head(seurat_obj_list$'300min'@meta.data, 4) 'data.frame' A data.frame: 4 \u00d7 3 orig.ident nCount_RNA nFeature_RNA <fct> <dbl> <int> AAACCTGAGACAATAC-1 300min 1630 803 AAACCTGAGACACTAA-1 300min 3147 1365 AAACCTGAGACGCTTT-1 300min 892 586 AAACCTGAGAGGGCTT-1 300min 1666 1033 seurat_obj_list$'300min'@meta.data$orig.ident = \"300min\" seurat_obj_list$'400min'@meta.data$orig.ident = \"400min\" seurat_obj_list$'500min'@meta.data$orig.ident = \"500min\" head(seurat_obj_list$'300min'@meta.data, 4) A data.frame: 4 \u00d7 3 orig.ident nCount_RNA nFeature_RNA <chr> <dbl> <int> AAACCTGAGACAATAC-1 300min 1630 803 AAACCTGAGACACTAA-1 300min 3147 1365 AAACCTGAGACGCTTT-1 300min 892 586 AAACCTGAGAGGGCTT-1 300min 1666 1033 Layers(seurat_obj_list$'300min') 'counts' seurat_obj_list$'300min'@version [1] \u20185.0.2\u2019","title":"Access Seurat object"},{"location":"BIOI611_scRNA_cele/#data-preprocessing","text":"Ensembl biomart can be used to extract the mitochodria genes: https://useast.ensembl.org/info/website/archives/assembly.html Gene stable ID Gene name WBGene00000829 ctb-1 WBGene00010957 nduo-6 WBGene00010958 WBGene00010958 WBGene00010959 WBGene00010959 WBGene00010960 atp-6 WBGene00010961 nduo-2 WBGene00010962 ctc-3 WBGene00010963 nduo-4 WBGene00010964 ctc-1 WBGene00010965 ctc-2 WBGene00010966 nduo-3 WBGene00010967 nduo-5 # Define the mitochondria gene names as an R vector mt_gene_names <- c( \"ctb-1\", \"nduo-6\", \"WBGene00010958\", \"WBGene00010959\", \"atp-6\", \"nduo-2\", \"ctc-3\", \"nduo-4\", \"ctc-1\", \"ctc-2\", \"nduo-3\", \"nduo-5\" ) mt_genes <- mt_gene_names[mt_gene_names %in% rownames(seurat_obj_list$'300min')] mt_genes .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'ctb-1' 'nduo-6' 'WBGene00010958' 'WBGene00010959' 'atp-6' 'nduo-2' 'ctc-3' 'nduo-4' 'ctc-1' 'ctc-2' 'nduo-3' 'nduo-5' # Function to calculate percentage of mitochondrial genes add_mt_percentage <- function(seurat_obj, mt_genes) { # Calculate percentage of mitochondrial genes seurat_obj$percent.mt <- PercentageFeatureSet(seurat_obj, features = mt_genes) return(seurat_obj) } seurat_obj_list <- lapply(seurat_obj_list, add_mt_percentage, mt_genes = mt_genes) qc_features <- c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\") VlnPlot(seurat_obj_list$'300min', features = qc_features, ncol = 3, pt.size=0) VlnPlot(seurat_obj_list$'400min', features = qc_features, ncol = 3, pt.size=0) VlnPlot(seurat_obj_list$'500min', features = qc_features, ncol = 3, pt.size=0) Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d","title":"Data preprocessing"},{"location":"BIOI611_scRNA_cele/#how-to-interpret-qc-plot","text":"nFeature_RNA : The number of unique features (genes) detected per cell. Extremely high values could suggest potential doublets (two cells mistakenly captured as one), as two cells would have more unique genes combined. Low number of detected genes - potential ambient mRNA (not real cells) nCount_RNA : The total number of RNA molecules (or unique molecular identifiers, UMIs) detected per cell. Higher counts generally indicate higher RNA content, but they could also result from cell doublets. Cells with very low nCount_RNA might represent poor-quality cells with low RNA capture, while very high counts may also suggest doublets. percent.mt : The percentage of reads mapping to mitochondrial genes. High mitochondrial content often indicates cell stress or apoptosis, as damaged cells tend to release mitochondrial RNA. Filtering cells with high percent.mt values is common to exclude potentially dying cells. # FeatureScatter is typically used to visualize feature-feature relationships, but can be used # for anything calculated by the object, i.e. columns in object metadata, PC scores etc. plot1 <- FeatureScatter(seurat_obj_list$'300min', feature1 = \"nCount_RNA\", feature2 = \"percent.mt\") plot2 <- FeatureScatter(seurat_obj_list$'300min', feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\") plot1 + plot2","title":"How to interpret QC plot"},{"location":"BIOI611_scRNA_cele/#filter-out-potential-doublets-empty-droplets-and-dying-cells","text":"# Load necessary libraries library(Seurat) library(ggplot2) # Define the function to calculate median and MAD values calculate_thresholds <- function(seurat_obj) { # Extract relevant columns nFeature_values <- seurat_obj@meta.data$nFeature_RNA nCount_values <- seurat_obj@meta.data$nCount_RNA percent_mt_values <- seurat_obj@meta.data$percent.mt # Calculate medians and MADs nFeature_median <- median(nFeature_values, na.rm = TRUE) nFeature_mad <- mad(nFeature_values, constant = 1, na.rm = TRUE) nCount_median <- median(nCount_values, na.rm = TRUE) nCount_mad <- mad(nCount_values, constant = 1, na.rm = TRUE) percent_mt_median <- median(percent_mt_values, na.rm = TRUE) percent_mt_mad <- mad(percent_mt_values, constant = 1, na.rm = TRUE) # Calculate thresholds for horizontal lines thresholds <- list( nFeature_upper = nFeature_median + 4 * nFeature_mad, nFeature_lower = nFeature_median - 4 * nFeature_mad, nCount_upper = nCount_median + 4 * nCount_mad, nCount_lower = nCount_median - 4 * nCount_mad, percent_mt_upper = percent_mt_median + 4 * percent_mt_mad ) return(thresholds) } # Define a function to filter Seurat objects filter_seurat_obj <- function(seurat_obj) { # Calculate thresholds thresholds <- calculate_thresholds(seurat_obj) # Apply filtering seurat_obj <- subset( seurat_obj, subset = nFeature_RNA > thresholds$nFeature_lower & nFeature_RNA < thresholds$nFeature_upper & percent.mt < thresholds$percent_mt_upper ) # return(seurat_obj) } # Apply filtering to each Seurat object in the list seurat_obj_list <- lapply(seurat_obj_list, filter_seurat_obj) VlnPlot(seurat_obj_list$'300min', features = qc_features, ncol = 3, pt.size=0) VlnPlot(seurat_obj_list$'400min', features = qc_features, ncol = 3, pt.size=0) VlnPlot(seurat_obj_list$'500min', features = qc_features, ncol = 3, pt.size=0) Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d Warning message: \u201cDefault search for \"data\" layer in \"RNA\" assay yielded no results; utilizing \"counts\" layer instead.\u201d RandomSubsetSeurat <- function(seurat_obj, subset_size, seed = NULL) { # Optionally set a random seed for reproducibility if (!is.null(seed)) { set.seed(seed) } # Get all cell names total_cells <- Cells(seurat_obj) # Ensure subset size is not larger than the total number of cells if (subset_size > length(total_cells)) { stop(\"Subset size exceeds the total number of cells in the Seurat object.\") } # Randomly sample a subset of cell names subset_cells <- sample(total_cells, size = subset_size) # Create a new Seurat object with the subsetted cells subset_seurat_obj <- subset(seurat_obj, cells = subset_cells) return(subset_seurat_obj) } \u26a0\ufe0f Important This is included only to reduce the memory used. In real project, you don't want to perform this step. Instead, you should request larger memory computing resources. seurat_obj_list <- lapply(seurat_obj_list, RandomSubsetSeurat, subset_size = 2000, seed = 123) seurat_obj_list $`300min` An object of class Seurat 19985 features across 2000 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts $`400min` An object of class Seurat 19985 features across 2000 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts $`500min` An object of class Seurat 19985 features across 2000 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 1 layer present: counts so_merged <- merge(seurat_obj_list$'300min', c(seurat_obj_list$'400min', seurat_obj_list$'500min'), add.cell.ids = c(\"300min\", \"400min\", \"500min\"), project = \"scRNA_cele\") so_merged Layers(so_merged) table(so_merged$orig.ident) An object of class Seurat 19985 features across 6000 samples within 1 assay Active assay: RNA (19985 features, 0 variable features) 3 layers present: counts.300min, counts.400min, counts.500min .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'counts.300min' 'counts.400min' 'counts.500min' 300min 400min 500min 2000 2000 2000 #rm(seurat_obj_list); gc(); Instead of using an arbitrary number, you can also use statistical algorithm to predict doublets and empty droplets to filter the cells, such as DoubletFinder and EmptyDrops .","title":"Filter out potential doublets, empty droplets and dying cells"},{"location":"BIOI611_scRNA_cele/#normalization-ccaling-of-the-data-and-linear-dimensional-reduction","text":"","title":"Normalization, ccaling of the data and linear dimensional reduction"},{"location":"BIOI611_scRNA_cele/#normalization","text":"After removing unwanted cells from the dataset, the next step is to normalize the data. By default, a global-scaling normalization method \u201cLogNormalize\u201d that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. In Seurat v5, Normalized values are stored in pbmc[[\"RNA\"]]$data . While this method of normalization is standard and widely used in scRNA-seq analysis, global-scaling relies on an assumption that each cell originally contains the same number of RNA molecules. Next, we identify a subset of features that show high variation across cells in the dataset\u2014meaning they are highly expressed in some cells and lowly expressed in others. Prior work, including our own, has shown that focusing on these variable genes in downstream analyses can enhance the detection of biological signals in single-cell datasets. The approach used in Seurat improves upon previous versions by directly modeling the inherent mean-variance relationship in single-cell data. This method is implemented in the FindVariableFeatures() function, which, by default, selects 2,000 variable features per dataset. These features will then be used in downstream analyses, such as PCA.","title":"Normalization"},{"location":"BIOI611_scRNA_cele/#scaling-the-data","text":"Next, we apply a linear transformation ( scaling ) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData() function: Shifts the expression of each gene, so that the mean expression across cells is 0 Scales the expression of each gene, so that the variance across cells is 1 This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate The results of this are stored in pbmc[[\"RNA\"]]$scale.data By default, only variable features are scaled. You can specify the features argument to scale additional features. # run standard anlaysis workflow so_merged <- NormalizeData(so_merged) so_merged <- FindVariableFeatures(so_merged) so_merged <- ScaleData(so_merged) so_merged <- RunPCA(so_merged) Normalizing layer: counts.300min Normalizing layer: counts.400min Normalizing layer: counts.500min Finding variable features for layer counts.300min Finding variable features for layer counts.400min Finding variable features for layer counts.500min Centering and scaling data matrix PC_ 1 Positive: noah-1, noah-2, dpy-2, dpy-3, mlt-11, col-76, mlt-8, dpy-7, dpy-10, hch-1 col-121, dpy-17, dpy-14, txdc-12.2, sym-1, C01H6.8, Y41D4B.6, sqt-3, Y23H5B.8, K02E10.4 acn-1, C05C8.7, C26B9.3, R148.5, C48E7.1, dsl-6, inx-12, cpg-24, R05D3.9, F37C4.4 Negative: ost-1, pat-10, D2092.4, mlc-3, let-2, unc-15, lev-11, emb-9, tni-1, set-18 tnt-3, sgn-1, test-1, hsp-12.1, unc-98, cpn-3, sgcb-1, F53F10.1, spp-15, mup-2 Y71F9AR.2, mlc-1, C29F5.1, mlc-2, clik-1, stn-2, mig-18, F21H7.3, unc-60, Y73F8A.26 PC_ 2 Positive: asp-4, enpl-1, C50F4.6, T02E9.5, his-24, atz-1, R07E5.17, C03C10.5, nphp-1, hil-3 tmem-231, mksr-2, tctn-1, fmi-1, jbts-14, osm-5, bbs-9, ift-81, fbxb-66, K02B12.2 mks-2, ift-20, K07C11.10, che-13, R01H2.8, ifta-2, F48E3.9, arl-3, ccep-290, tmem-17 Negative: unc-15, sgn-1, D2092.4, C29F5.1, let-2, lev-11, tnt-3, mlc-2, mup-2, mlc-1 tni-1, test-1, mig-18, clik-1, hsp-12.1, mlc-3, ttn-1, F21H7.3, sgca-1, emb-9 set-18, icl-1, ost-1, myo-3, unc-54, sgcb-1, hsp-12.2, unc-98, stn-2, Y71F9AR.2 PC_ 3 Positive: mks-2, arl-3, mksr-2, ift-81, ifta-2, dylt-2, tmem-231, K07C11.10, che-13, ift-20 ccep-290, bbs-5, osm-5, C33A12.4, ift-74, R01H2.8, Y102A11A.9, bbs-9, tctn-1, lgc-20 dyf-1, mks-1, T02G5.3, dyf-3, arl-13, nphp-1, tmem-17, Y17D7B.10, bbs-2, F01E11.3 Negative: his-24, Y37E3.30, atz-1, lbp-1, C01G6.3, cht-1, ttr-50, clec-266, Y65A5A.1, enpl-1 hil-3, clec-196, idh-1, dsl-3, fbxb-66, cpg-20, F53B3.5, Y71F9AL.7, fbn-1, E01G4.5 pmt-2, ZK512.1, cutl-2, Y43F8B.2, cpg-24, F55C9.5, Y71F9AL.6, W04H10.6, fbxb-101, lam-3 PC_ 4 Positive: arl-3, ifta-2, mks-2, mksr-2, tmem-231, ift-81, che-13, K07C11.10, ift-20, dylt-2 Y55D5A.1, bbs-9, ift-74, ccep-290, tctn-1, dsl-3, cutl-2, T02G5.3, R01H2.8, bbs-5 osm-5, nphp-1, dyf-1, lgc-20, dyf-3, arl-13, mks-1, Y102A11A.9, tmem-17, bbs-2 Negative: mab-7, wrt-2, abu-13, mlt-9, sups-1, clec-180, Y73E7A.8, C01G6.9, wrt-1, R07E3.6 Y54G2A.76, K08B12.1, mam-3, T19A5.3, glf-1, ZC449.1, H03E18.1, M03B6.3, ZK154.1, Y11D7A.9 pqn-32, F01D5.6, C35A5.11, F33D4.6, C52G5.2, grl-15, T03D8.6, F23H12.5, cut-6, ZC123.1 PC_ 5 Positive: F33H2.8, nhr-127, F37A4.3, bus-17, nhr-270, sams-1, bus-12, F18A11.2, W04H10.6, oac-51 elt-1, F54B11.10, T13H10.2, nhr-218, rocf-1, Y6D1A.2, txdc-12.1, T04G9.4, F32H2.6, subs-4 fbn-1, F13G3.3, T03G6.1, nhr-94, C35A5.5, fbxa-52, fasn-1, nstp-3, W03B1.3, bus-8 Negative: Y41D4B.6, B0205.4, C06C3.4, T01D1.8, F43D9.1, F11E6.9, F31C3.6, dsl-6, ttr-2, T19C4.1 F46G11.6, K02E10.4, best-14, nhx-1, ifa-3, T25B9.1, F46F11.7, Y45F10B.59, F15B9.8, C24B5.4 T19B10.5, clec-78, cpt-4, C49F5.13, srm-1, H41C03.1, B0393.5, C53A5.2, ttr-3, far-5 DimPlot(so_merged, reduction = \"pca\", split.by = 'orig.ident', label.color = \"black\") + NoLegend() so_merged <- FindNeighbors(so_merged, dims = 1:30, reduction = \"pca\") so_merged <- FindClusters(so_merged, resolution = 2, cluster.name = \"unintegrated_clusters\") Computing nearest neighbor graph Computing SNN Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck Number of nodes: 6000 Number of edges: 197290 Running Louvain algorithm... Maximum modularity in 10 random starts: 0.8357 Number of communities: 37 Elapsed time: 0 seconds You have several useful ways to visualize both cells and features that define the PCA, including VizDimReduction() , DimPlot() , and DimHeatmap() . DimHeatmap() draws a heatmap focusing on a principal component. Both cells and genes are sorted by their principal component scores","title":"Scaling the data"},{"location":"BIOI611_scRNA_cele/#perform-analysis-without-integration","text":"To visualize and explore these datasets, Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP. The goal of tSNE/UMAP is to learn underlying structure in the dataset, in order to place similar cells together in low-dimensional space. Therefore, cells that are grouped together within graph-based clusters determined above should co-localize on these dimension reduction plots. so_merged <- RunUMAP(so_merged, dims = 1:30, reduction = \"pca\", reduction.name = \"umap.unintegrated\") Warning message: \u201cThe default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric To use Python UMAP via reticulate, set umap.method to 'umap-learn' and metric to 'correlation' This message will be shown once per session\u201d 22:47:06 UMAP embedding parameters a = 0.9922 b = 1.112 22:47:06 Read 6000 rows and found 30 numeric columns 22:47:06 Using Annoy for neighbor search, n_neighbors = 30 22:47:06 Building Annoy index with metric = cosine, n_trees = 50 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * | 22:47:07 Writing NN index file to temp file /tmp/Rtmp9vMJuf/file43d447d49a3 22:47:07 Searching Annoy index using 1 thread, search_k = 3000 22:47:10 Annoy recall = 100% 22:47:11 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30 22:47:15 Initializing from normalized Laplacian + noise (using RSpectra) 22:47:15 Commencing optimization for 500 epochs, with 241186 positive edges 22:47:25 Optimization finished DimPlot(so_merged, reduction = \"umap.unintegrated\", split.by = c(\"orig.ident\")) FeaturePlot(so_merged, feature=\"ham-1\", pt.size = 0.1, split.by = c(\"orig.ident\")) FeaturePlot(so_merged, feature=\"egl-21\", pt.size = 0.1, split.by = c(\"orig.ident\")) FeaturePlot(so_merged, feature=\"dsl-3\", pt.size = 0.1, split.by = c(\"orig.ident\"))","title":"Perform analysis without integration"},{"location":"BIOI611_scRNA_cele/#perform-integration","text":"Seurat v5 enables streamlined integrative analysis using the IntegrateLayers function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches: Anchor-based CCA integration (method=CCAIntegration) Harmony (method=HarmonyIntegration) Anchor-based RPCA integration (method=RPCAIntegration) FastMNN (method= FastMNNIntegration) scVI (method=scVIIntegration) Canonical correlation analysis: CCA Reciprocal PCA: RPCA CCAIntegration integration method that is available in the Seurat package utilizes the canonical correlation analysis (CCA). This method expects \u201ccorrespondences\u201d or shared biological states among at least a subset of single cells across the groups. so_merged_integ <- IntegrateLayers(object = so_merged, method = CCAIntegration, orig.reduction = \"pca\", new.reduction = \"integrated.cca\", verbose = FALSE) Once integrative analysis is complete, you can rejoin the layers - which collapses the individual datasets together and recreates the original counts and data layers. You will need to do this before performing any differential expression analysis. However, you can always resplit the layers in case you would like to reperform integrative analysis. # re-join layers after integration so_merged_integ[[\"RNA\"]] <- JoinLayers(so_merged_integ[[\"RNA\"]]) so_merged_integ <- FindNeighbors(so_merged_integ, reduction = \"integrated.cca\", dims = 1:30) so_merged_integ <- FindClusters(so_merged_integ, resolution = 2) Computing nearest neighbor graph Computing SNN Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck Number of nodes: 6000 Number of edges: 203509 Running Louvain algorithm... Maximum modularity in 10 random starts: 0.8373 Number of communities: 37 Elapsed time: 1 seconds so_merged_integ <- RunUMAP(so_merged_integ, dims = 1:30, reduction = \"integrated.cca\") 22:48:04 UMAP embedding parameters a = 0.9922 b = 1.112 22:48:04 Read 6000 rows and found 30 numeric columns 22:48:04 Using Annoy for neighbor search, n_neighbors = 30 22:48:04 Building Annoy index with metric = cosine, n_trees = 50 0% 10 20 30 40 50 60 70 80 90 100% [----|----|----|----|----|----|----|----|----|----| * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * | 22:48:06 Writing NN index file to temp file /tmp/Rtmp9vMJuf/file43d7e00c0c4 22:48:06 Searching Annoy index using 1 thread, search_k = 3000 22:48:09 Annoy recall = 100% 22:48:10 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30 22:48:13 Initializing from normalized Laplacian + noise (using RSpectra) 22:48:13 Commencing optimization for 500 epochs, with 243916 positive edges 22:48:24 Optimization finished DimPlot(so_merged_integ, reduction = \"umap\", split.by = c(\"orig.ident\")) DefaultAssay(so_merged_integ) 'RNA' markers <- FindAllMarkers(so_merged_integ) Calculating cluster 0 Calculating cluster 1 Calculating cluster 2 Calculating cluster 3 Calculating cluster 4 Calculating cluster 5 Calculating cluster 6 Calculating cluster 7 Calculating cluster 8 Calculating cluster 9 Calculating cluster 10 Calculating cluster 11 Calculating cluster 12 Calculating cluster 13 Calculating cluster 14 Calculating cluster 15 Calculating cluster 16 Calculating cluster 17 Calculating cluster 18 Calculating cluster 19 Calculating cluster 20 Calculating cluster 21 Calculating cluster 22 Calculating cluster 23 Calculating cluster 24 Calculating cluster 25 Calculating cluster 26 Calculating cluster 27 Calculating cluster 28 Calculating cluster 29 Calculating cluster 30 Calculating cluster 31 Calculating cluster 32 Calculating cluster 33 Calculating cluster 34 Calculating cluster 35 Calculating cluster 36 markers %>% group_by(cluster) %>% dplyr::filter(avg_log2FC > 1) %>% slice_head(n = 2) %>% ungroup() -> top2 DoHeatmap(so_merged_integ, features = top2$gene) + NoLegend() Warning message in DoHeatmap(so_merged_integ, features = top2$gene): \u201cThe following features were omitted as they were not found in the scale.data slot for the RNA assay: nmur-3, timp-1, acp-6, C14A4.6, skpo-2, mltn-13, srw-12, F59C6.8, T03G11.9, C02F5.2, C33D9.10, lev-9, C08F1.6, cank-26, egl-21\u201d head(markers) A data.frame: 6 \u00d7 7 p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene <dbl> <dbl> <dbl> <dbl> <dbl> <fct> <chr> F36H1.11 0.000000e+00 5.450659 0.570 0.048 0.000000e+00 0 F36H1.11 egl-21 1.563079e-282 3.984563 0.577 0.058 3.123813e-278 0 egl-21 T10B5.4 1.850416e-276 3.373848 0.792 0.138 3.698057e-272 0 T10B5.4 madd-4 1.841569e-242 4.579571 0.420 0.030 3.680376e-238 0 madd-4 F28E10.1 8.224195e-225 3.734330 0.746 0.167 1.643605e-220 0 F28E10.1 C31H5.5 8.048185e-222 4.466041 0.411 0.034 1.608430e-217 0 C31H5.5 FeaturePlot(so_merged_integ, reduction = \"umap\", feature=\"ham-1\", pt.size = 0.1, split.by = c(\"orig.ident\")) so_merged_integ An object of class Seurat 19985 features across 6000 samples within 1 assay Active assay: RNA (19985 features, 2000 variable features) 3 layers present: data, counts, scale.data 4 dimensional reductions calculated: pca, umap.unintegrated, integrated.cca, umap FeaturePlot(so_merged_integ, reduction = \"umap\", feature=\"egl-21\", pt.size = 0.1, split.by = c(\"orig.ident\")) FeaturePlot(so_merged_integ, reduction = \"umap\", feature=\"dsl-3\", pt.size = 0.1, split.by = c(\"orig.ident\")) With the integrated Seurat object, you can perform cell type annotation using marker genes. \u26a0\ufe0f Important In this class, we will not perform cell type annotation for this dataset. With the notebook for analyzing the human PBMC data, you will be able to perform cell type annnotation if needed. In the next section, you will learn how to perform trajectory and pseudotime analysis. You will directly utilize the annotation performed by the authors who generated this dataset in the Science paper . The data can be obtained using the URLs below: ## count matrix https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_expression.rds ## metadata https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_colData.rds ## gene list https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_rowData.rds","title":"Perform integration"},{"location":"BIOI611_scRNA_cele/#save-the-seurat-object","text":"saveRDS(so_merged_integ, file = \"Seurat_object_10x_cele_final.rds\") remotes::install_github(\"10xGenomics/loupeR\") loupeR::setup() Downloading GitHub repo 10xGenomics/loupeR@HEAD promises (1.3.0 -> 1.3.2 ) [CRAN] later (1.3.2 -> 1.4.1 ) [CRAN] progressr (0.15.0 -> 0.15.1) [CRAN] Installing 3 packages: promises, later, progressr Installing packages into \u2018/content/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) \u001b[36m\u2500\u2500\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m * checking for file \u2018/tmp/Rtmp9vMJuf/remotes43d20adbcde/10XGenomics-loupeR-a169417/DESCRIPTION\u2019 ... OK * preparing \u2018loupeR\u2019: * checking DESCRIPTION meta-information ... OK * checking for LF line-endings in source and make files and shell scripts * checking for empty or unneeded directories * building \u2018loupeR_1.1.2.tar.gz\u2019 Installing package into \u2018/content/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) Warning message in fun(libname, pkgname): \u201cPlease call `loupeR::setup()` to install the Louper executable and to agree to the EULA before continuing\u201d Installing Executable 2024/12/02 22:51:21 Downloading executable The LoupeR executable is subject to the 10x End User Software License, available at: https://10xgen.com/EULA Do you accept the End-User License Agreement (y/yes or n/no): yes EULA library(loupeR) create_loupe_from_seurat(so_merged_integ, output_name = \"Seurat_object_10x_cele_merged_integ\", force = TRUE) 2024/12/02 22:56:56 extracting matrix, clusters, and projections 2024/12/02 22:56:56 selected assay: RNA 2024/12/02 22:56:56 selected clusters: active_cluster orig.ident unintegrated_clusters seurat_clusters RNA_snn_res.2 2024/12/02 22:56:56 selected projections: umap.unintegrated umap 2024/12/02 22:56:56 validating count matrix 2024/12/02 22:56:56 validating clusters 2024/12/02 22:56:56 validating projections 2024/12/02 22:56:56 creating temporary hdf5 file: /tmp/Rtmp9vMJuf/file43d561ea60d.h5 2024/12/02 22:56:59 invoking louper executable 2024/12/02 22:56:59 running command: \"/root/.local/share/R/loupeR/louper create --input='/tmp/Rtmp9vMJuf/file43d561ea60d.h5' --output='Seurat_object_10x_cele_merged_integ.cloupe' --force\"","title":"Save the Seurat object"},{"location":"BIOI611_scRNA_cele/#reference","text":"https://monashbioinformaticsplatform.github.io/Single-Cell-Workshop/pbmc3k_tutorial.html https://bioinformatics.ccr.cancer.gov/docs/getting-started-with-scrna-seq/IntroToR_Seurat/ https://hbctraining.github.io/scRNA-seq/lessons/elbow_plot_metric.html https://satijalab.org/seurat/articles/integration_introduction","title":"Reference"},{"location":"BIOI611_scRNA_seq_cele_cellranger/","text":"Data availability Data can be obtained from the link below: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE126954 GSM3618670 UW synchronized 300 min post bleach GSM3618671 UW synchronized 400 min post bleach GSM3618672 UW synchronized 500 min post bleach batch 1 GSM3618673 UW synchronized 500 min post bleach batch 2 GSM3618674 UPenn mixed embryo batch r17 GSM3618675 UPenn mixed embryo batch b01 GSM3618676 UPenn mixed embryo batch b02 In this class, you will only work on: 300 min post bleach , 400 min post bleach and 500 min post bleach batch 1 An copy of the data has been stored here: /scratch/zt1/project/bioi611/shared/raw_data/10x_cele_data/scRNA/ If you want to download and prepare the files yourself, Here is the process: For each sample, fetch the sra files using prefectch For example: export PATH=/scratch/zt1/project/bioi611/shared/software/sratoolkit.3.1.1-centos_linux64/bin:$PATH prefetch SRR8611967 Convert sra file to fastq files fasterq-dump --outdir <output_folder> --include-technical --split-files <sra_file> Prepare the genome You don't need to run this step. The content in this part is to show you if you want to prepare the reference genome for cellranger, how you can prepare. ## /scratch/zt1/project/bioi611/shared/reference/cellranger_mkref/ $ cat /scratch/zt1/project/bioi611/shared/reference/cellranger_mkref/scRNA_cellranger_mkref.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH -n 1 #SBATCH -c 26 #SBATCH --mem=250g #SBATCH --job-name=scRNA_cellranger_mkref #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out export PATH=/scratch/zt1/project/bioi611/shared/software/cellranger-8.0.1/bin:$PATH cellranger mkgtf ../Caenorhabditis_elegans.WBcel235.111.gtf \\ Caenorhabditis_elegans.WBcel235.111.filtered.gtf \\ --attribute=gene_biotype:protein_coding > scRNA_cellranger_mkref.filter_gtf.log 2>&1 cellranger mkref --genome=Caenorhabditis_elegans_genome \\ --fasta=../Caenorhabditis_elegans.WBcel235.dna.toplevel.fa \\ --genes=Caenorhabditis_elegans.WBcel235.111.filtered.gtf \\ > scRNA_cellranger_mkref.log 2>&1 Run cellranger count sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_cele_cellranger_count.Uwsync_300min.sub sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_cele_cellranger_count.Uwsync_400min.sub sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_cele_cellranger_count.Uwsync_500min.sub Aggregate the cellranger count results Many experiments generate data for multiple samples. Depending on the experimental design, these samples may represent replicates from the same set of cells, cells from different tissues or time points from the same individual, or cells from different individuals. These samples could be processed through various Gel Bead-in Emulsion (GEM) wells wells or multiplexed within the same GEM well on Chromium instruments. To work with data from multiple GEM wells, you can aggregate and analyze the outputs from multiple runs of each of these pipelines using cellranger aggr . sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_cele_cellranger_aggr.sub","title":"Initial analysis of 10x scRNA-seq data for C. elegans using cellranger"},{"location":"BIOI611_scRNA_seq_cele_cellranger/#_1","text":"","title":""},{"location":"BIOI611_scRNA_seq_cele_cellranger/#data-availability","text":"Data can be obtained from the link below: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE126954 GSM3618670 UW synchronized 300 min post bleach GSM3618671 UW synchronized 400 min post bleach GSM3618672 UW synchronized 500 min post bleach batch 1 GSM3618673 UW synchronized 500 min post bleach batch 2 GSM3618674 UPenn mixed embryo batch r17 GSM3618675 UPenn mixed embryo batch b01 GSM3618676 UPenn mixed embryo batch b02 In this class, you will only work on: 300 min post bleach , 400 min post bleach and 500 min post bleach batch 1 An copy of the data has been stored here: /scratch/zt1/project/bioi611/shared/raw_data/10x_cele_data/scRNA/ If you want to download and prepare the files yourself, Here is the process: For each sample, fetch the sra files using prefectch For example: export PATH=/scratch/zt1/project/bioi611/shared/software/sratoolkit.3.1.1-centos_linux64/bin:$PATH prefetch SRR8611967 Convert sra file to fastq files fasterq-dump --outdir <output_folder> --include-technical --split-files <sra_file>","title":"Data availability"},{"location":"BIOI611_scRNA_seq_cele_cellranger/#prepare-the-genome","text":"You don't need to run this step. The content in this part is to show you if you want to prepare the reference genome for cellranger, how you can prepare. ## /scratch/zt1/project/bioi611/shared/reference/cellranger_mkref/ $ cat /scratch/zt1/project/bioi611/shared/reference/cellranger_mkref/scRNA_cellranger_mkref.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH -n 1 #SBATCH -c 26 #SBATCH --mem=250g #SBATCH --job-name=scRNA_cellranger_mkref #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out export PATH=/scratch/zt1/project/bioi611/shared/software/cellranger-8.0.1/bin:$PATH cellranger mkgtf ../Caenorhabditis_elegans.WBcel235.111.gtf \\ Caenorhabditis_elegans.WBcel235.111.filtered.gtf \\ --attribute=gene_biotype:protein_coding > scRNA_cellranger_mkref.filter_gtf.log 2>&1 cellranger mkref --genome=Caenorhabditis_elegans_genome \\ --fasta=../Caenorhabditis_elegans.WBcel235.dna.toplevel.fa \\ --genes=Caenorhabditis_elegans.WBcel235.111.filtered.gtf \\ > scRNA_cellranger_mkref.log 2>&1","title":"Prepare the genome"},{"location":"BIOI611_scRNA_seq_cele_cellranger/#run-cellranger-count","text":"sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_cele_cellranger_count.Uwsync_300min.sub sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_cele_cellranger_count.Uwsync_400min.sub sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_cele_cellranger_count.Uwsync_500min.sub","title":"Run cellranger count"},{"location":"BIOI611_scRNA_seq_cele_cellranger/#aggregate-the-cellranger-count-results","text":"Many experiments generate data for multiple samples. Depending on the experimental design, these samples may represent replicates from the same set of cells, cells from different tissues or time points from the same individual, or cells from different individuals. These samples could be processed through various Gel Bead-in Emulsion (GEM) wells wells or multiplexed within the same GEM well on Chromium instruments. To work with data from multiple GEM wells, you can aggregate and analyze the outputs from multiple runs of each of these pipelines using cellranger aggr . sbatch /scratch/zt1/project/bioi611/shared/scripts/scRNA_10x_cele_cellranger_aggr.sub","title":"Aggregate the cellranger count results"},{"location":"FASTQ_PHRED/","text":"What is PHRED Scores A Phred score is a measure of the probability that a base call in a DNA sequencing read is incorrect. It is a logarithmic scale, meaning that a small change in the Phred score represents a large change in the probability of an error. \\[Q = -10 \\cdot \\log_{10}(P)\\] Where: Q is the PHRED score. P is the probability that the base was called incorrectly. For example: Q = 20 : This corresponds to a 1 in 100 probability of an incorrect base call, or an accuracy of 99%. Q = 30 : This corresponds to a 1 in 1000 probability of an incorrect base call, or an accuracy of 99.9%. Q = 40 : This corresponds to a 1 in 10,000 probability of an incorrect base call, or an accuracy of 99.99%. # Print the header cat(sprintf(\"%-5s\\t\\t%-10s\\n\", \"Phred\", \"Prob of\")) cat(sprintf(\"%-5s\\t\\t%-10s\\n\", \"score\", \"Incorrect call\")) # Loop through Phred scores from 0 to 41 for (phred in 0:41) { cat(sprintf(\"%-5d\\t\\t%0.5f\\n\", phred, 10^(phred / -10))) } What is ASCII ASCII (American Standard Code for Information Interchange) is used to represent characters in computers. We can represent Phred scores using ASCII characters. The advantage is that the quality information can be esisly stored in text based FASTQ file. Not all ASCII characters are printable. The first printable ASCII character is ! and the decimal code for the character for ! is 33. # Store output in a vector to fit on a slide output <- c(sprintf(\"%-8s %-8s\", \"Character\", \"ASCII #\")) # Loop through ASCII values from 33 to 89 for (i in 33:89) { output <- c(output, sprintf(\"%-8s %-8d\", intToUtf8(i), i)) } # Print the output in a single block (e.g., to fit on a slide) cat(paste(output, collapse = \"\\n\")) Phred scores in FASTQ file In a FASTQ file, Phred scores are represented as ASCII characters. These characters are converted back to numeric values (PHRED scores) based on the encoding scheme used: PHRED+33 Encoding (Sanger/Illumina 1.8+) : The ASCII character for a quality score Q is calculated as: ASCII character=chr(Q+33) For example: A PHRED score of 30 is encoded as chr(30 + 33) = chr(63) , which corresponds to the ASCII character ? . PHRED+64 Encoding (Illumina 1.3-1.7) : The ASCII character for a quality score QQQ is calculated as: ASCII character=chr(Q+64) For example: A PHRED score of 30 is encoded as chr(30 + 64) = chr(94) , which corresponds to the ASCII character ^ . # Print the header cat(sprintf(\"%-5s\\t\\t%-10s\\t%-6s\\t\\t%-10s\\n\", \"Phred\", \"Prob. of\", \"ASCII\", \"ASCII\")) cat(sprintf(\"%-5s\\t\\t%-10s\\t%-6s\\t%-10s\\n\", \"score\", \"Error\", \"Phred+33\", \"Phred+64\")) # Loop through Phred scores from 0 to 41 for (phred in 0:41) { # Calculate the probability of error prob_error <- 10^(phred / -10) # Convert Phred scores to ASCII characters ascii_phred33 <- intToUtf8(phred + 33) ascii_phred64 <- intToUtf8(phred + 64) # Print the results in a formatted table cat(sprintf(\"%-5d\\t\\t%0.5f\\t\\t%-6s\\t\\t%-10s\\n\", phred, prob_error, ascii_phred33, ascii_phred64)) }","title":"PRED Score in Bioinformatics"},{"location":"FASTQ_PHRED/#what-is-phred-scores","text":"A Phred score is a measure of the probability that a base call in a DNA sequencing read is incorrect. It is a logarithmic scale, meaning that a small change in the Phred score represents a large change in the probability of an error. \\[Q = -10 \\cdot \\log_{10}(P)\\] Where: Q is the PHRED score. P is the probability that the base was called incorrectly. For example: Q = 20 : This corresponds to a 1 in 100 probability of an incorrect base call, or an accuracy of 99%. Q = 30 : This corresponds to a 1 in 1000 probability of an incorrect base call, or an accuracy of 99.9%. Q = 40 : This corresponds to a 1 in 10,000 probability of an incorrect base call, or an accuracy of 99.99%. # Print the header cat(sprintf(\"%-5s\\t\\t%-10s\\n\", \"Phred\", \"Prob of\")) cat(sprintf(\"%-5s\\t\\t%-10s\\n\", \"score\", \"Incorrect call\")) # Loop through Phred scores from 0 to 41 for (phred in 0:41) { cat(sprintf(\"%-5d\\t\\t%0.5f\\n\", phred, 10^(phred / -10))) }","title":"What is PHRED Scores"},{"location":"FASTQ_PHRED/#what-is-ascii","text":"ASCII (American Standard Code for Information Interchange) is used to represent characters in computers. We can represent Phred scores using ASCII characters. The advantage is that the quality information can be esisly stored in text based FASTQ file. Not all ASCII characters are printable. The first printable ASCII character is ! and the decimal code for the character for ! is 33. # Store output in a vector to fit on a slide output <- c(sprintf(\"%-8s %-8s\", \"Character\", \"ASCII #\")) # Loop through ASCII values from 33 to 89 for (i in 33:89) { output <- c(output, sprintf(\"%-8s %-8d\", intToUtf8(i), i)) } # Print the output in a single block (e.g., to fit on a slide) cat(paste(output, collapse = \"\\n\"))","title":"What is ASCII"},{"location":"FASTQ_PHRED/#phred-scores-in-fastq-file","text":"In a FASTQ file, Phred scores are represented as ASCII characters. These characters are converted back to numeric values (PHRED scores) based on the encoding scheme used: PHRED+33 Encoding (Sanger/Illumina 1.8+) : The ASCII character for a quality score Q is calculated as: ASCII character=chr(Q+33) For example: A PHRED score of 30 is encoded as chr(30 + 33) = chr(63) , which corresponds to the ASCII character ? . PHRED+64 Encoding (Illumina 1.3-1.7) : The ASCII character for a quality score QQQ is calculated as: ASCII character=chr(Q+64) For example: A PHRED score of 30 is encoded as chr(30 + 64) = chr(94) , which corresponds to the ASCII character ^ . # Print the header cat(sprintf(\"%-5s\\t\\t%-10s\\t%-6s\\t\\t%-10s\\n\", \"Phred\", \"Prob. of\", \"ASCII\", \"ASCII\")) cat(sprintf(\"%-5s\\t\\t%-10s\\t%-6s\\t%-10s\\n\", \"score\", \"Error\", \"Phred+33\", \"Phred+64\")) # Loop through Phred scores from 0 to 41 for (phred in 0:41) { # Calculate the probability of error prob_error <- 10^(phred / -10) # Convert Phred scores to ASCII characters ascii_phred33 <- intToUtf8(phred + 33) ascii_phred64 <- intToUtf8(phred + 64) # Print the results in a formatted table cat(sprintf(\"%-5d\\t\\t%0.5f\\t\\t%-6s\\t\\t%-10s\\n\", phred, prob_error, ascii_phred33, ascii_phred64)) }","title":"Phred scores in FASTQ file"},{"location":"Phred_FQ/","text":"What is PHRED Scores A Phred score is a measure of the probability that a base call in a DNA sequencing read is incorrect. It is a logarithmic scale, meaning that a small change in the Phred score represents a large change in the probability of an error. \\(Q = -10 \\cdot \\log_{10}(P)\\) Where: Q is the PHRED score. P is the probability that the base was called incorrectly. For example: Q = 20 : This corresponds to a 1 in 100 probability of an incorrect base call, or an accuracy of 99%. Q = 30 : This corresponds to a 1 in 1000 probability of an incorrect base call, or an accuracy of 99.9%. Q = 40 : This corresponds to a 1 in 10,000 probability of an incorrect base call, or an accuracy of 99.99%. # Print the header cat(sprintf(\"%-5s\\t\\t%-10s\\n\", \"Phred\", \"Prob of\")) cat(sprintf(\"%-5s\\t\\t%-10s\\n\", \"score\", \"Incorrect call\")) # Loop through Phred scores from 0 to 41 for (phred in 0:41) { cat(sprintf(\"%-5d\\t\\t%0.5f\\n\", phred, 10^(phred / -10))) } Phred Prob of score Incorrect call 0 1.00000 1 0.79433 2 0.63096 3 0.50119 4 0.39811 5 0.31623 6 0.25119 7 0.19953 8 0.15849 9 0.12589 10 0.10000 11 0.07943 12 0.06310 13 0.05012 14 0.03981 15 0.03162 16 0.02512 17 0.01995 18 0.01585 19 0.01259 20 0.01000 21 0.00794 22 0.00631 23 0.00501 24 0.00398 25 0.00316 26 0.00251 27 0.00200 28 0.00158 29 0.00126 30 0.00100 31 0.00079 32 0.00063 33 0.00050 34 0.00040 35 0.00032 36 0.00025 37 0.00020 38 0.00016 39 0.00013 40 0.00010 41 0.00008 What is ASCII ASCII (American Standard Code for Information Interchange) is used to represent characters in computers. We can represent Phred scores using ASCII characters. The advantage is that the quality information can be esisly stored in text based FASTQ file. Not all ASCII characters are printable. The first printable ASCII character is ! and the decimal code for the character for ! is 33. # Store output in a vector to fit on a slide output <- c(sprintf(\"%-8s %-8s\", \"Character\", \"ASCII #\")) # Loop through ASCII values from 33 to 89 for (i in 33:89) { output <- c(output, sprintf(\"%-8s %-8d\", intToUtf8(i), i)) } # Print the output in a single block (e.g., to fit on a slide) cat(paste(output, collapse = \"\\n\")) Character ASCII # ! 33 \" 34 # 35 $ 36 % 37 & 38 ' 39 ( 40 ) 41 * 42 + 43 , 44 - 45 . 46 / 47 0 48 1 49 2 50 3 51 4 52 5 53 6 54 7 55 8 56 9 57 : 58 ; 59 < 60 = 61 > 62 ? 63 @ 64 A 65 B 66 C 67 D 68 E 69 F 70 G 71 H 72 I 73 J 74 K 75 L 76 M 77 N 78 O 79 P 80 Q 81 R 82 S 83 T 84 U 85 V 86 W 87 X 88 Y 89 Phred scores in FASTQ file In a FASTQ file, Phred scores are represented as ASCII characters. These characters are converted back to numeric values (PHRED scores) based on the encoding scheme used: PHRED+33 Encoding (Sanger/Illumina 1.8+) : The ASCII character for a quality score Q is calculated as: ASCII character=chr(Q+33) For example: A PHRED score of 30 is encoded as chr(30 + 33) = chr(63) , which corresponds to the ASCII character ? . PHRED+64 Encoding (Illumina 1.3-1.7) : The ASCII character for a quality score QQQ is calculated as: ASCII character=chr(Q+64) For example: A PHRED score of 30 is encoded as chr(30 + 64) = chr(94) , which corresponds to the ASCII character ^ . # Print the header cat(sprintf(\"%-5s\\t\\t%-10s\\t%-6s\\t\\t%-10s\\n\", \"Phred\", \"Prob. of\", \"ASCII\", \"ASCII\")) cat(sprintf(\"%-5s\\t\\t%-10s\\t%-6s\\t%-10s\\n\", \"score\", \"Error\", \"Phred+33\", \"Phred+64\")) # Loop through Phred scores from 0 to 41 for (phred in 0:41) { # Calculate the probability of error prob_error <- 10^(phred / -10) # Convert Phred scores to ASCII characters ascii_phred33 <- intToUtf8(phred + 33) ascii_phred64 <- intToUtf8(phred + 64) # Print the results in a formatted table cat(sprintf(\"%-5d\\t\\t%0.5f\\t\\t%-6s\\t\\t%-10s\\n\", phred, prob_error, ascii_phred33, ascii_phred64)) } Phred Prob. of ASCII ASCII score Error Phred+33 Phred+64 0 1.00000 ! @ 1 0.79433 \" A 2 0.63096 # B 3 0.50119 $ C 4 0.39811 % D 5 0.31623 & E 6 0.25119 ' F 7 0.19953 ( G 8 0.15849 ) H 9 0.12589 * I 10 0.10000 + J 11 0.07943 , K 12 0.06310 - L 13 0.05012 . M 14 0.03981 / N 15 0.03162 0 O 16 0.02512 1 P 17 0.01995 2 Q 18 0.01585 3 R 19 0.01259 4 S 20 0.01000 5 T 21 0.00794 6 U 22 0.00631 7 V 23 0.00501 8 W 24 0.00398 9 X 25 0.00316 : Y 26 0.00251 ; Z 27 0.00200 < [ 28 0.00158 = \\ 29 0.00126 > ] 30 0.00100 ? ^ 31 0.00079 @ _ 32 0.00063 A ` 33 0.00050 B a 34 0.00040 C b 35 0.00032 D c 36 0.00025 E d 37 0.00020 F e 38 0.00016 G f 39 0.00013 H g 40 0.00010 I h 41 0.00008 J i","title":"Phred score in FASTQ"},{"location":"Phred_FQ/#what-is-phred-scores","text":"A Phred score is a measure of the probability that a base call in a DNA sequencing read is incorrect. It is a logarithmic scale, meaning that a small change in the Phred score represents a large change in the probability of an error. \\(Q = -10 \\cdot \\log_{10}(P)\\) Where: Q is the PHRED score. P is the probability that the base was called incorrectly. For example: Q = 20 : This corresponds to a 1 in 100 probability of an incorrect base call, or an accuracy of 99%. Q = 30 : This corresponds to a 1 in 1000 probability of an incorrect base call, or an accuracy of 99.9%. Q = 40 : This corresponds to a 1 in 10,000 probability of an incorrect base call, or an accuracy of 99.99%. # Print the header cat(sprintf(\"%-5s\\t\\t%-10s\\n\", \"Phred\", \"Prob of\")) cat(sprintf(\"%-5s\\t\\t%-10s\\n\", \"score\", \"Incorrect call\")) # Loop through Phred scores from 0 to 41 for (phred in 0:41) { cat(sprintf(\"%-5d\\t\\t%0.5f\\n\", phred, 10^(phred / -10))) } Phred Prob of score Incorrect call 0 1.00000 1 0.79433 2 0.63096 3 0.50119 4 0.39811 5 0.31623 6 0.25119 7 0.19953 8 0.15849 9 0.12589 10 0.10000 11 0.07943 12 0.06310 13 0.05012 14 0.03981 15 0.03162 16 0.02512 17 0.01995 18 0.01585 19 0.01259 20 0.01000 21 0.00794 22 0.00631 23 0.00501 24 0.00398 25 0.00316 26 0.00251 27 0.00200 28 0.00158 29 0.00126 30 0.00100 31 0.00079 32 0.00063 33 0.00050 34 0.00040 35 0.00032 36 0.00025 37 0.00020 38 0.00016 39 0.00013 40 0.00010 41 0.00008","title":"What is PHRED Scores"},{"location":"Phred_FQ/#what-is-ascii","text":"ASCII (American Standard Code for Information Interchange) is used to represent characters in computers. We can represent Phred scores using ASCII characters. The advantage is that the quality information can be esisly stored in text based FASTQ file. Not all ASCII characters are printable. The first printable ASCII character is ! and the decimal code for the character for ! is 33. # Store output in a vector to fit on a slide output <- c(sprintf(\"%-8s %-8s\", \"Character\", \"ASCII #\")) # Loop through ASCII values from 33 to 89 for (i in 33:89) { output <- c(output, sprintf(\"%-8s %-8d\", intToUtf8(i), i)) } # Print the output in a single block (e.g., to fit on a slide) cat(paste(output, collapse = \"\\n\")) Character ASCII # ! 33 \" 34 # 35 $ 36 % 37 & 38 ' 39 ( 40 ) 41 * 42 + 43 , 44 - 45 . 46 / 47 0 48 1 49 2 50 3 51 4 52 5 53 6 54 7 55 8 56 9 57 : 58 ; 59 < 60 = 61 > 62 ? 63 @ 64 A 65 B 66 C 67 D 68 E 69 F 70 G 71 H 72 I 73 J 74 K 75 L 76 M 77 N 78 O 79 P 80 Q 81 R 82 S 83 T 84 U 85 V 86 W 87 X 88 Y 89","title":"What is ASCII"},{"location":"Phred_FQ/#phred-scores-in-fastq-file","text":"In a FASTQ file, Phred scores are represented as ASCII characters. These characters are converted back to numeric values (PHRED scores) based on the encoding scheme used: PHRED+33 Encoding (Sanger/Illumina 1.8+) : The ASCII character for a quality score Q is calculated as: ASCII character=chr(Q+33) For example: A PHRED score of 30 is encoded as chr(30 + 33) = chr(63) , which corresponds to the ASCII character ? . PHRED+64 Encoding (Illumina 1.3-1.7) : The ASCII character for a quality score QQQ is calculated as: ASCII character=chr(Q+64) For example: A PHRED score of 30 is encoded as chr(30 + 64) = chr(94) , which corresponds to the ASCII character ^ . # Print the header cat(sprintf(\"%-5s\\t\\t%-10s\\t%-6s\\t\\t%-10s\\n\", \"Phred\", \"Prob. of\", \"ASCII\", \"ASCII\")) cat(sprintf(\"%-5s\\t\\t%-10s\\t%-6s\\t%-10s\\n\", \"score\", \"Error\", \"Phred+33\", \"Phred+64\")) # Loop through Phred scores from 0 to 41 for (phred in 0:41) { # Calculate the probability of error prob_error <- 10^(phred / -10) # Convert Phred scores to ASCII characters ascii_phred33 <- intToUtf8(phred + 33) ascii_phred64 <- intToUtf8(phred + 64) # Print the results in a formatted table cat(sprintf(\"%-5d\\t\\t%0.5f\\t\\t%-6s\\t\\t%-10s\\n\", phred, prob_error, ascii_phred33, ascii_phred64)) } Phred Prob. of ASCII ASCII score Error Phred+33 Phred+64 0 1.00000 ! @ 1 0.79433 \" A 2 0.63096 # B 3 0.50119 $ C 4 0.39811 % D 5 0.31623 & E 6 0.25119 ' F 7 0.19953 ( G 8 0.15849 ) H 9 0.12589 * I 10 0.10000 + J 11 0.07943 , K 12 0.06310 - L 13 0.05012 . M 14 0.03981 / N 15 0.03162 0 O 16 0.02512 1 P 17 0.01995 2 Q 18 0.01585 3 R 19 0.01259 4 S 20 0.01000 5 T 21 0.00794 6 U 22 0.00631 7 V 23 0.00501 8 W 24 0.00398 9 X 25 0.00316 : Y 26 0.00251 ; Z 27 0.00200 < [ 28 0.00158 = \\ 29 0.00126 > ] 30 0.00100 ? ^ 31 0.00079 @ _ 32 0.00063 A ` 33 0.00050 B a 34 0.00040 C b 35 0.00032 D c 36 0.00025 E d 37 0.00020 F e 38 0.00016 G f 39 0.00013 H g 40 0.00010 I h 41 0.00008 J i","title":"Phred scores in FASTQ file"},{"location":"acknowlegement/","text":"Acknowledgement Gene ontology and pathway analysis: PowerPoint slides: https://bioinformatics.ccr.cancer.gov/docs/b4b/Module3_Pathway_Analysis/Slides_for_lesson17/","title":"Acknowlegement"},{"location":"acknowlegement/#_1","text":"","title":""},{"location":"acknowlegement/#acknowledgement","text":"Gene ontology and pathway analysis: PowerPoint slides: https://bioinformatics.ccr.cancer.gov/docs/b4b/Module3_Pathway_Analysis/Slides_for_lesson17/","title":"Acknowledgement"},{"location":"basic_linux/","text":"Linux for Bioinformatics Navigating in Linux file system You are in your home directory after you log into the system and are directed to the shell command prompt. This section will show you hot to explore Linux file system using shell commands. Path To understand Linux file system, you can image it as a tree structure. In Linux, a path is a unique location of a file or a directory in the file system. For convenience, Linux file system is usually thought of in a tree structure. On a standard Linux system you will find the layout generally follows the scheme presented below. The tree of the file system starts at the trunk or slash, indicated by a forward slash ( / ). This directory, containing all underlying directories and files, is also called the root directory or \u201cthe root\u201d of the file system. %%bash ## In your account, you will see a folder ## with you account ID as the name cd ~ echo $HOME /home/xie186 Relative and absolute path Absolute path An absolute path is defined as the location of a file or directory from the root directory(/). An absolute path starts from the root of the tree ( / ). Here are some examples: /home/xie186 /home/xie186/.bashrc Relative path Relative path is a path related to the present working directory: data/sample1/ and ../doc/ . If you want to get the absolute path based on relative path , you can use readlink with parameter -f : pwd readlink -f ../ Once we enter into a Linux file system, we need to 1) know where we are; 2) how to get where we want; 3) how to know what files or directories we have in a particular path. Check where you are using command pwd In order to know where we are, we need to use pwd command. The command pwd is short for \u201cprint name of current/working directory\u201d. It will return the full path of current directory. Command pwd is almost always used by itself. This means you only need to type pwd and press ENTER %%bash pwd Listing the contents using command ls After you know where you are, then you want to know what you have in that directory, we can use command ls to list directory contents Its syntax is: ls [option]... [file]... ls with no option will list files and directories in bare format. Bare format means the detailed information (type, size, modified date and time, permissions and links etc) won\u2019t be viewed. When you use ls by itself, it will list files and directories in the current directory. ls ~/ ls -a ls -ld Linux command options can be combined without a space between them and with a single - (dash). The following command is a faster way to use the l and a options and gives the same output as the Linux command shown above. ls -lt ~/.bashrc -rw-r--r--. 1 xie186 zt-bioi611 1067 Aug 22 22:27 /home/xie186/.bashrc Change directory using command cd Unlike pwd , when you use cd you usually need to provide the path (either absolute or relative path) which we want to enter. If you didn\u2019t provide any path information, you will change to home directory by default. Path Shortcuts Description Single dot . The current folder Double dots .. The folder above the current folder Tilde character ~ Home directory (normally the directory:/home/my_login_name) Dash - Your last working directory Here are some examples: cd ~ pwd ls ls ../ ## pwd cd ../ pwd cd ./ pwd Each directory has two entries in it at the start, with names . (a link to itself) and .. (a link to its parent directory). The exception, of course, is the root directory, where the .. directory also refers to the root directory. Sometimes you go to a new directory and do something, then you remember that you need to go to the previous working direcotry. To get back instantly, use a dash. %%bash # This is our current directory pwd # Let us go our home diretory cd ~ # Check where we are pwd # Let us go to your previous working directory cd - # Check where we are now pwd /home/xie186/BIOI611_lab/docs /home/xie186 /home/xie186/BIOI611_lab/docs /home/xie186/BIOI611_lab/docs Manipulations of files and directories In Linux, manipulations of files and directories are the most frequent work. In this section, you will learn how to copy, rename, remove, and create files and directories. Command line cp In Linux, command cp can help you copy files and directories into a target directory. Command line mv Move files/folders and rename file/folders using mv : # move file from one location to another mv file1 target_direcotry/ # rename mv file1 file2 mv file1 file2 file3 target_direcotry/ Command mkdir The syntax is shown as below: mkdir [OPTION ...] DIRECTORY ... Multiple directories can be specified when calling mkdir mkdir directory1 directory2 mkdir -p foo/bar/baz How to defining complex directory trees with one command: mkdir -p project/{software,results,doc/{html,info,pdf},scripts} Then you can view the directory using tree . Command rm You can use rm to remove both files and directories. ## You can remove one file. rm file1 ## `rm` can remove multiple files simutaneously rm file2 file3 You can also use 'rm' to remove a folder. If a folder is empty, you can remove it using rm with -r . rm -r FOLDER If a folder is not empty, you can remove it using rm with -r and -f . mkdir test_folder rm -r test_folder View text files in Linux Commands cat , more and less The command cat is short for concatenate files and print on the standard output. The syntax is shown as below: cat [OPTION]... [FILE]... For small text file, cat can be used to view the files on the standard output. The command more is old utility. When the text passed to it is too large to fit on one screen, it pages it. You can scroll down but not up. The syntaxt of more is shown below: more [options] file [...] The command less was written by a man who was fed up with more\u2019s inability to scroll backwards through a file. He turned less into an open source project and over time, various individuals added new features to it. less is massive now. That\u2019s why some small embedded systems have more but not less. For comparison, less\u2019s source is over 27000 lines long. more implementations are generally only a little over 2000 lines long. The syntaxt of less is shown below: less [options] file [...] Command head and tail The command head is used to output the first part of files. By default, it outputs the first 10 lines of the file. head [OPTION]... [FILE]... Here is an exmaple of printing the first 5 files of the file: head -n 5 code_perl/variable_assign.pl In fact, the letter n does not even need to be used at all. Just the hyphen and the integer (with no intervening space) are sufficient to tell head how many lines to return. Thus, the following would produce the same result as the above commands: head -5 target_file.txt The command tail is used to output the last part of files. By default, it prints the last 10 lines of the file to standard output. The syntax is shown below: tail [OPTION]... [FILE]... Here is an exmaple of printing the last 5 files of the file: tail -5 target_file.txt To view lines from a specific point in a file, you can use -n +NUMBER with the tail command. For example, here is an example of viewing the file from the 2nd line of the line. tail -n +2 target_file.txt Auto-completion In most Shell environment, programmable completion feature will also improve your speed of typing. It permits typing a partial name of command or a partial file (or directory), then pressing TAB key to auto-complete the command. If there are more than one possible completions, then TAB will list all of them. A handy autocomplete feature also exists. Type one or more letters, press the Tab key twice, and then a list of functions starting with these letters appears. For example: type so , press the Tab key twice, and then you get the list as: soelim sort sotruss soundstretch source Demonstration of programmable completion feature. File permissions In Linux, file permissions are a vital aspect of system security and resource management. This is particularly important in bioinformatics, where large datasets and scripts are often shared across teams. Permissions determine who can read, write, or execute a file, ensuring that critical data is not accidentally modified or deleted. Three Permission Categories : User (u): The owner of the file. Group (g): A group of users who share access to the file. Other (o): All other users on the system. Permission Types : Read (r): Ability to view the contents of a file. Write (w): Ability to modify or delete the file. Execute (x): Ability to run the file as a program (for scripts or executables). %%bash groups $USER animako eunal gstewar1 mjames17 mjeakle nmilza rahooper xie186 : zt-bioi611 zt-bioi611_mgr animako : zt-bioi611 eunal : zt-bioi611 gstewar1 : zt-bioi611 mjames17 : zt-bioi611 mjeakle : zt-bioi611 nmilza : zt-bioi611 rahooper : zt-bioi611 %%bash mkdir -p ~/test_permission/ touch ~/test_permission/test.txt ls -l ~/test_permission/ rm -rf ~/test_permission/ total 0 -rw-r--r--. 1 xie186 zt-bioi611 0 Sep 8 22:52 test.txt Here, the first character represents the type of file (e.g., - for a regular file or d for a directory), followed by three groups of three characters, each representing the permissions for the user , group , and others , respectively. Examples: -rwxr-xr-- : The owner has read , write , and execute permissions. The group has read and execute permissions, while others can only read the file. drwxr-x--- : A directory where the owner can read, write, and access (execute). The group can only read and access, while others have no permissions. Modify file permissions using the chmod command. Permissions can be set in two ways: Symbolic Mode: In symbolic mode, you modify permissions by referencing the categories (user, group, other) and specifying whether you're adding (+), removing (-), or setting (=) permissions. # Add execute permission for the user: chmod u+x filename # Remove write permission for the group: chmod g-w filename # Set read-only permission for others: chmod o=r filename Symbolic mode is intuitive and flexible, especially when you want to make precise adjustments to permissions without affecting other categories. This is useful for common file-sharing tasks in bioinformatics where you need to tweak access for specific collaborators. Numeric Mode (Octal representation): In numeric mode, file permissions are set using a three-digit number. Each digit represents the permissions for user , group , and other , respectively. The digits are calculated by adding the values of the read , write , and execute` permissions: Read (r) = 4 Write (w) = 2 Execute (x) = 1 Example Permission Breakdown: Read (r), Write (w), and Execute (x) for user = 7 Read (r) and Execute (x) for group = 5 Read (r) only for others = 4 chmod 754 filename An example to help you understand executable : %%bash printf '#!/user/bin/python\\nprint(\"Hello, Welcome to Course BIOI611!\")' > ~/test.py %%bash ls -l ~/test.py python ~/test.py -rw-r--r--. 1 xie186 zt-bioi611 61 Sep 8 23:06 /home/xie186/test.py Hello, Welcome to Course BIOI611! Error message below will be thrown out if you consider ~/test.py as a program: bash: line 1: /home/xie186/test.py: No such file or directory %%bash chmod u+x ~/test.py ls -l ~/test.py python ~/test.py rm ~/test.py -rwxr--r--. 1 xie186 zt-bioi611 61 Sep 8 23:06 /home/xie186/test.py Hello, Welcome to Course BIOI611! Disk Usage of Files and Directories The Linux du (short for Disk Usage) is a standard Unix/Linux command, used to check the information of disk usage of files and directories on a machine. The du command has many parameter options that can be used to get the results in many formats. The du command also displays the files and directory sizes in a recursively manner. %%bash du -h ~/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref 2.5G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref %%bash du -ah ~/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref 2.9M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/sjdbList.fromGTF.out.tab 7.5K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/Log.out 936M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/SA 1.5G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/SAindex 3.0M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/transcriptInfo.tab 2.3M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/sjdbList.out.tab 1.5M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/geneInfo.tab 1.0K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/genomeParameters.txt 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/chrLength.txt 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/chrNameLength.txt 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/chrStart.txt 7.6M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/exonGeTrInfo.tab 3.1M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/exonInfo.tab 2.8M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/sjdbInfo.txt 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/chrName.txt 119M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/Genome 2.5G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref %%bash du -csh /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/* 19G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/raw_data 0 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/raw_data_smart_seq 1.5K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s1_download_data.sub 575K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s1_download_smart_seq-7478223-xie186.err 0 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s1_download_smart_seq-7478223-xie186.out 8.5K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s1_download_smart_seq.sub 2.5K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s2_star.sub 34G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_align 2.5G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/test.sub 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/test.txt 55G total Symbolic link Symbolic link, similar to shortcuts, can point to another file/folder. ln -s <path_to_files/folder_to_be_linked> <symlink_to_be_created> ls -l <symlink> unlink <symlink> File Management and Data Handling Compressing and decompressing files (gzip, gunzip, tar). Compress one file: %%bash perl -e 'for($i=0; $i<10000; ++$i){ print \"test\\n\";}' > test.txt du -h test.txt gzip test.txt du -h test.txt.gz gunzip test.txt ls test.txt rm test.txt 52K test.txt 4.0K test.txt.gz test.txt Compress multiple files: %%bash perl -e 'for($i=0; $i<10000; ++$i){ print \"test\\n\";}' > test1.txt perl -e 'for($i=0; $i<10000; ++$i){ print \"test\\n\";}' > test2.txt du -h test1.txt test2.txt tar zcvf test.tar.gz test1.txt test2.txt du -sh test.tar.gz ls test1.txt test2.txt 52K test1.txt 52K test2.txt test1.txt test2.txt 4.0K test.tar.gz test1.txt test2.txt z : This option tells tar to compress the archive using gzip. The resulting archive will have a .gz extension to indicate that it has been compressed with the gzip utility. c : This option stands for create. It instructs tar to create a new archive. v : This stands for verbose. When used, tar will display detailed information about the files being added to the archive, such as their names. f : This stands for file. It tells tar that the next argument (test.tar.gz) is the name of the archive file to create. %%bash tar tvf test.tar.gz rm test.tar.gz test1.txt test2.txt -rw-r--r-- xie186/zt-bioi611 50000 2024-08-25 21:52 test1.txt -rw-r--r-- xie186/zt-bioi611 50000 2024-08-25 21:52 test2.txt t : List the contents of archive.tar. v : Display additional details about each file (like file permissions, size, and modification date). f : Specifies that archive.tar is the archive file to operate on. To uncompress a tar.gz file, use tar zxvf : tar zxvf test.tar.gz Transferring files within the network Basic Syntax of scp : scp [options] source destination Copy a Local File to a Remote Server scp file.txt username@remote_host:/path/to/destination/ Alternative command is rsync . File searching, filtering, and text processing Command find The find command is designed for comprehensive file and directory sesarches. find [path] [options] [expression] %%bash find /home/xie186/scratch/bioi611/bulk_RNAseq -name \"*.fastq.gz\" /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day7_rep3.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day1_rep3.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day1_rep1.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day7_rep1.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day1_rep2.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day7_rep2.fastq.gz Text data counts wc %%bash find /home/xie186/scratch/bioi611/bulk_RNAseq -name \"*.fastq.gz\" |wc -l 6 Pipe | In Linux and Unix-based systems, the pipe ( | ) is used in the command line to redirect the output of one command as the input to another command. This allows you to chain commands together and perform more complex tasks in a single line. %%bash grep '>' ~/scratch/bioi611/reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa |wc -l 7 Column filering Command cut can be used to print selected parts of lines from each FILE to standard output. %%bash wget -O GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz \"https://ncbi.nlm.nih.gov/geo/download/?type=rnaseq_counts&acc=GSE102537&format=file&file=GSE102537_raw_counts_GRCh38.p13_NCBI.tsv.gz\" --2024-08-25 21:08:03-- https://ncbi.nlm.nih.gov/geo/download/?type=rnaseq_counts&acc=GSE102537&format=file&file=GSE102537_raw_counts_GRCh38.p13_NCBI.tsv.gz Resolving ncbi.nlm.nih.gov (ncbi.nlm.nih.gov)... 2607:f220:41e:4290::110, 130.14.29.110 Connecting to ncbi.nlm.nih.gov (ncbi.nlm.nih.gov)|2607:f220:41e:4290::110|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 349584 (341K) [application/octet-stream] Saving to: \u2018GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz\u2019 0K .......... .......... .......... .......... .......... 14% 6.66M 0s 50K .......... .......... .......... .......... .......... 29% 16.9M 0s 100K .......... .......... .......... .......... .......... 43% 27.5M 0s 150K .......... .......... .......... .......... .......... 58% 10.1M 0s 200K .......... .......... .......... .......... .......... 73% 17.2M 0s 250K .......... .......... .......... .......... .......... 87% 37.6M 0s 300K .......... .......... .......... .......... . 100% 10.5M=0.02s 2024-08-25 21:08:04 (13.4 MB/s) - \u2018GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz\u2019 saved [349584/349584] %%bash zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |head GeneID GSM2740270 GSM2740272 GSM2740273 GSM2740274 GSM2740275 100287102 9 17 14 14 19 653635 336 470 467 310 370 102466751 8 56 46 31 31 107985730 0 2 2 3 3 100302278 0 1 0 0 2 645520 0 3 8 4 7 79501 0 2 2 1 4 100996442 16 25 34 20 28 729737 19 39 33 22 26 %%bash zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |cut -f1,2,3 |head GeneID GSM2740270 GSM2740272 100287102 9 17 653635 336 470 102466751 8 56 107985730 0 2 100302278 0 1 645520 0 3 79501 0 2 100996442 16 25 729737 19 39 Row filtering %%bash grep '>' ~/scratch/bioi611/reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa >I dna:chromosome chromosome:WBcel235:I:1:15072434:1 REF >II dna:chromosome chromosome:WBcel235:II:1:15279421:1 REF >III dna:chromosome chromosome:WBcel235:III:1:13783801:1 REF >IV dna:chromosome chromosome:WBcel235:IV:1:17493829:1 REF >V dna:chromosome chromosome:WBcel235:V:1:20924180:1 REF >X dna:chromosome chromosome:WBcel235:X:1:17718942:1 REF >MtDNA dna:chromosome chromosome:WBcel235:MtDNA:1:13794:1 REF %%bash zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |wc -l zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |awk '$2>500' |wc -l zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |awk '$2>500 && $3>500' |wc -l 39377 8773 3820 Text processing %%bash grep '>' ~/scratch/bioi611/reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa |sed 's/>//' |sed 's/ .*//' I II III IV V X MtDNA Regular Expressions Regular expressions are sequences of characters that define search patterns. They are commonly used for string matching, searching, and text processing. Regex is used in text editors, programming languages, command-line tools (like grep and sed ), and many bioinformatics tools to search, replace, or extract data from text. Metacharacters: Special characters that have specific meanings in regex syntax. . (dot): Matches any single character except a newline. Example: A.G matches \"AAG\", \"ATG\", \"ACG\", etc. ^ : Matches the start of a line. Example: ^A matches any line starting with \"A\". $ : Matches the end of a line. Example: end$ matches any line ending with \"end\". * : Matches 0 or more occurrences of the preceding character. Example: ca*t matches \"ct\", \"cat\", \"caat\", \"caaat\", etc. + : Matches 1 or more occurrences of the preceding character. Example: ca+t matches \"cat\", \"caat\", \"caaat\", etc. ? : Matches 0 or 1 occurrence of the preceding character. Example: colou?r matches both \"color\" and \"colour\". [] : Matches any one of the characters inside the brackets. Example: [aeiou] matches any vowel. | : Alternation (OR) operator. Example: cat|dog matches either \"cat\" or \"dog\". Character Classes: Represents a set of characters. \\d : Matches any digit (equivalent to [0-9]). \\w : Matches any word character (alphanumeric or underscore). \\s : Matches any whitespace character (spaces, tabs, etc.). \\D : Matches any non-digit character. \\W : Matches any non-word character. \\S : Matches any non-whitespace character. Quantifiers: Specify the number of occurrences to match {n} : Matches exactly n occurrences. Example: A{3} matches \"AAA\". {n,} : Matches n or more occurrences. Example: T{2,} matches \"TT\", \"TTT\", \"TTTT\", etc. {n,m} : Matches between n and m occurrences. Example: G{1,3} matches \"G\", \"GG\", or \"GGG\". An example of the command line used %%bash grep -v '#' ~/scratch/bioi611/reference/Caenorhabditis_elegans.WBcel235.111.gtf \\ |awk '$3==\"gene\"' \\ |sed 's/.*gene_biotype \"//' \\ |sed 's/\";//'|sort |uniq -c \\ | sort -k1,1n 22 rRNA 100 antisense_RNA 129 snRNA 194 lincRNA 261 miRNA 346 snoRNA 634 tRNA 2128 pseudogene 7764 ncRNA 15363 piRNA 19985 protein_coding Environment variables Environment variables are dynamic values that affect the behavior of processes and programs in Linux. They are commonly used to store configuration data and are essential in bioinformatics workflows for defining paths to software, libraries, and datasets. Commonly Used Environment Variables: PATH : The PATH variable specifies directories where the system looks for executable files when a command is run. %%bash echo $PATH /cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/texlive/bin/x86_64-linux:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/imagemagick/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/graphviz/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/ghostscript/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/ffmpeg/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/mpi-nocuda/linux-rhel8-zen2/gcc/11.3.0/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/nompi-nocuda/linux-rhel8-zen2/gcc/11.3.0/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/linux-rhel8-x86_64/gcc-rh8-8.5.0/gcc-11.3.0-oedkmii7vhd6rbnqm6xufmg7d3jx4w6l/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/linux-rhel8-zen2/gcc-11.3.0/py-jupyter-1.0.0-trwwgzwljql55mhmaygcuxb3nvaevjsu/bin:/software/acigs-utilities/bin:/home/xie186/miniforge3/bin:/home/xie186/miniforge3/condabin:/home/xie186/SHELL.bioi611/software/STAR_2.7.11b/Linux_x86_64_static:/home/xie186/.local/bin:/home/xie186/bin:/software/acigs-utilities/bin:/usr/share/Modules/bin:/usr/lib/heimdal/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/symas/bin:/opt/dell/srvadmin/bin HOME : The HOME variable stores the path to the user\u2019s home directory. %%bash echo $HOME /home/xie186 %%bash echo $SHELL /bin/bash Setting Environment Variables: Temporarily setting a variable (valid only for the current shell session): export PATH=value:PATH Permanently setting a variable: To make the environment variable persistent across sessions, it needs to be added to configuration files like .bashrc or .bash_profile . Example: Add the following line to .bashrc : Software installation Installation via Conda Conda is a popular package management system, especially in bioinformatics, due to its ability to create isolated environments. This is crucial when working with tools that have conflicting dependencies. Install conda/miniforge Go to: https://github.com/conda-forge/miniforge/releases Download the corresponding installtion file %%bash uname -m x86_64 wget https://github.com/conda-forge/miniforge/releases/download/24.7.1-0/Mambaforge-24.7.1-0-Linux-x86_64.sh Create conda environment and install software conda create -n bioi611 conda activate bioi611 conda install bioconda::fastqc==0.11.8 Installation via Source Code (Manual Compilation) git clone https://github.com/lh3/bwa.git cd bwa; make ./bwa index ref.fa Using Container for Bioinformatics Tools Understanding Containers and Using Singularity What Are Containers? Containers are lightweight, portable environments that bundle software and all its dependencies so that it runs consistently on any system. Think of a container as a \"self-contained laboratory\" \u2014 it has all the reagents (software, libraries, dependencies) you need, already prepared. In Bioinformatics, where different tools depend on specific versions of Python, R, or system libraries, containers ensure: Reproducibility: The same tool produces the same results on any computer or HPC. Portability: You can run the same environment locally, in the cloud, or on a supercomputer. Isolation: Tools run in separate environments, avoiding conflicts between software packages. Docker vs. Singularity Feature Docker Singularity Designed for Cloud, local systems HPC, clusters Requires root privileges Yes No (runs safely in user space) Image format .tar / .img (Docker images) .sif (Singularity Image File) Integration with HPC Limited Excellent Common in DevOps, cloud platforms Research, bioinformatics, academia Most High-Performance Computing (HPC) systems do not allow Docker because it requires root privileges. Instead, they use Singularity, which can pull Docker images and convert them into a format that\u2019s safe for HPC environments. Why Use Containers in Bioinformatics? Bioinformatics tools often require: Complex dependencies (e.g., different versions of glibc, python, boost, etc.) Conflicting library versions Long installation times Using containers solves these issues. For example: You can use Biocontainers \u2014 prebuilt containers with thousands of bioinformatics tools. Each container is tested and version-controlled. No need to install software manually. Example: Using Singularity to Run TrimGalore TrimGalore is a widely used tool for quality-control sequencing data. It combines Cutadapt and FastQC to trim adapters and assess read quality. Instead of manually installing it, we can use a pre-built Biocontainer. Step 1. Load Singularity on the HPC On most HPC systems, Singularity is provided as a module: module load singularity Step 2. Build a Singularity Image from a Docker Container The BioContainers project provides many pre-built Docker images for bioinformatics tools. Singularity can directly convert these Docker images into a Singularity Image File (.sif) suitable for HPC use: singularity build trimgalore_v0.6.10.sif docker://quay.io/biocontainers/trim-galore:0.6.10--hdfd78af_0 This command downloads the Docker image from Quay.io and converts it into a local .sif file. Step 3. Run TrimGalore from the Container You can run commands inside the container using singularity exec . For example, to check that TrimGalore is available: singularity exec trimgalore_v0.6.10.sif trim_galore --help If you want to run the tool on data located in your project directory, bind-mount the directory so that it\u2019s accessible inside the container: singularity exec -B /scratch/zt1/project/bioi611/ trimgalore_v0.6.10.sif trim_galore --help The -B option (short for bind ) makes the specified directory available inside the container. Step 4. (Optional) Enter the Container for an Interactive Session singularity exec -B /scratch/zt1/project/bioi611/ trimgalore_v0.6.10.sif /bin/bash From there, you can directly run commands as if TrimGalore were installed on your system. Step Action Command Example 1 Load Singularity module load singularity 2 Build the image singularity build trimgalore_v0.6.10.sif docker://quay.io/biocontainers/trim-galore:0.6.10--hdfd78af_0 3 Run the tool singularity exec trimgalore_v0.6.10.sif trim_galore --help 4 Interactive mode singularity exec -B /scratch/... trimgalore_v0.6.10.sif /bin/bash Text editor in Linux In Linux, we sometimes need to create or edit a text file like writing a new perl script. So we need to use text editor. As a newbie, someone would prefer a basic, GUI-based text editor with menus and traditional CUA key bindings. Here we recommend Sublime , ATOM and Notepad++ . But GUI-based text editor is not always available in Linux. A powerful screen text editor vi (pronounced \u201cvee-eye\u201d) is available on nearly all Linux system. We highly recommend vi as a text editor, because something we\u2019ll have to edit a text file on a system without a friendlier text editor. Once we get familiar with vi , we\u2019ll find that it\u2019s very fast and powerful. But remember, it\u2019s OK if you think this part is too difficult at the beginning. You can use either Sublime , ATOM or Notepad++ . If you are connecting to a Linux system without Sublime , ATOM and Notepad++ , you can write the file in a local computer and then upload the file onto Linux system. Basic vi skills As vi uses a lot of combination of keystrokes, it may be not easy for newbies to remember all the combinations in one fell swoop. Considering this, we\u2019ll first introduce the basic skills someone needs to know to use vi . We need to first understand how three modes of vi work and then try to remember a few basic vi commonds. Then we can use these skills to write Perl or R scripts in the following chaptors for Perl and R (Figure \\@ref(fig:workingModeVi)). Three modes of vi : Create new text file with vi mkdir test_vi ## generate a new folder cd test_vi ## go into the new folder echo \"Using \\`ls\\` we don't expect files in this folder.\" ls echo \"No file displayed!\" Using the code above, we made a new directory named test_vi . We didn't see any file. If we type vi test.py , an empty file and screen are created into which you may enter text because the file does not exist((Figure \\@ref(fig:ViNewFile))). vi test.py A screentshot of the vi test.py . Now if you are in vi mode . To go to Input mode , you can type i , 'a' or 'o' (Figure \\@ref(fig:ViInpuMode)). Now you can type the content (codes or other information) (\\@ref(fig:ViInpuType)). Once you are done typing. You need to go to Command mode (Figure \\@ref(fig:workingModeVi)) if you want to save and exit the file. To do this, you need to press ESC button on the keyboard. Now we just wrote a Perl script. We can run this script. python test.py High-Performance Computing (HPC) for Bioinformatics HPC resources enable bioinformatics analyses that require significant computational power and memory. Basics of HPC clusters and job schedulers (SLURM). An example of an job file ( s1_star.sh ): #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH -n 1 #SBATCH -c 20 #SBATCH --job-name=s1_star_aln #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out conda activate bioi611 mkdir -p STAR_align/ STAR --genomeDir STAR_ref \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix STAR_align/N2_day1_rep1. \\ --runThreadN 20 \\ --readFilesIn raw_data/N2_day1_rep1.fastq.gz To submit this job, run: sbatch s1_star.sh Check quota infomation %%bash scratch_quota # shell_quota # Group quotas Group name Space used Space quota % quota used zt-bioi611 285.811 MB 4.000 TB 0.01% zt-bioi611_mgr 98.163 GB unlimited 0 total 98.449 GB unlimited 0 # User quotas User name Space used Space quota % quota used % of GrpTotal xie186 98.449 GB unlimited 0 100.00% View information about Slurm nodes and partitions. %%bash sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST debug up 15:00 1 maint compute-b8-60 debug up 15:00 1 drng compute-b8-57 debug up 15:00 1 mix compute-b8-59 debug up 15:00 1 alloc compute-b8-58 scavenger up 14-00:00:0 1 inval compute-b8-48 scavenger up 14-00:00:0 4 drain$ compute-b8-[53-56] scavenger up 14-00:00:0 84 maint compute-a7-[5,9,14-16,28,49],compute-a8-[2-4,8-9,15,18,22,24,29,37,44,51],compute-b5-[4,16,26,29-30,33,44,51-52],compute-b6-[7,12,21,28-29,32,34,43-46,50-51,59],compute-b7-[12-13,19-22,25,27,29,31,35,37,39,42,45-46,49-50,54,56-59],compute-b8-[16,19,21,23-24,29,32,35-37,39-45,60] scavenger up 14-00:00:0 2 drain* compute-a7-[13,43] scavenger up 14-00:00:0 13 drng compute-a8-[7,14],compute-b7-[14-15,18,38,43-44],compute-b8-[2,20,51,57],gpu-b9-5 scavenger up 14-00:00:0 2 drain compute-a7-8,gpu-b10-5 scavenger up 14-00:00:0 182 mix bigmem-a9-[1-2,4-5],compute-a5-[3-11],compute-a7-[2-3,6-7,10,12,17-19,21-22,30,38-40,45-46,48,54-56,60],compute-a8-[5-6,10-12,16-17,19-21,25,28,31-35,39,41,45,47,50,52,54,57-59],compute-b5-[1-3,5-8,11,13-15,17-25,27-28,31-32,34-43,45-50,53-55,57-58],compute-b6-[1-5,14-15,17-20,22-24,35-36,48-49,52,54],compute-b7-[1,7-8,16-17,23-24,26,28,30,32-34,36,40-41,47-48,51-52,55,60],compute-b8-[1,15,17-18,22,25-27,30-31,33,46-47,49-50,59],gpu-b9-[1-4,6-7],gpu-b10-[1-3,6-7],gpu-b11-[1-6] scavenger up 14-00:00:0 93 alloc bigmem-a9-[3,6],compute-a7-[1,4,11,20,23-27,29,31-37,41-42,44,47,50-53,57-59],compute-a8-[1,13,23,26-27,30,36,38,40,42-43,46,48-49,53,55-56,60],compute-b5-[9-10,12,56,59-60],compute-b6-[6,8-11,13,16,27,30-31,58,60],compute-b7-[2-6,9-11,53],compute-b8-[3-14,28,34,38,52,58],gpu-b10-4 scavenger up 14-00:00:0 14 idle compute-b6-[25-26,33,37-42,47,53,55-57] standard* up 7-00:00:00 1 inval compute-b8-48 standard* up 7-00:00:00 4 drain$ compute-b8-[53-56] standard* up 7-00:00:00 82 maint compute-a7-[5,9,14-16,28,49],compute-a8-[2-4,8-9,15,18,22,24,29,37,44,51],compute-b5-[4,16,26,29-30,33,44,51-52],compute-b6-[7,12,21,28-29,32,34,43-46,50-51],compute-b7-[12-13,19-22,25,27,29,31,35,37,39,42,45-46,49-50,54,56-59],compute-b8-[16,19,21,23-24,29,32,35-37,39-45] standard* up 7-00:00:00 2 drain* compute-a7-[13,43] standard* up 7-00:00:00 11 drng compute-a8-[7,14],compute-b7-[14-15,18,38,43-44],compute-b8-[2,20,51] standard* up 7-00:00:00 1 drain compute-a7-8 standard* up 7-00:00:00 159 mix compute-a5-[3-11],compute-a7-[2-3,6-7,10,12,17-19,21-22,30,38-40,45-46,48,54-56,60],compute-a8-[5-6,10-12,16-17,19-21,25,28,31-35,39,41,45,47,50,52,54,57-59],compute-b5-[1-3,5-8,11,13-15,17-25,27-28,31-32,34-43,45-50,53-55,57-58],compute-b6-[1-5,14-15,17-20,22-24,35-36,48-49,52],compute-b7-[1,7-8,16-17,23-24,26,28,30,32-34,36,40-41,47-48,51-52,55,60],compute-b8-[1,15,17-18,22,25-27,30-31,33,46-47,49-50] standard* up 7-00:00:00 87 alloc compute-a7-[1,4,11,20,23-27,29,31-37,41-42,44,47,50-53,57-59],compute-a8-[1,13,23,26-27,30,36,38,40,42-43,46,48-49,53,55-56,60],compute-b5-[9-10,12,56,59-60],compute-b6-[6,8-11,13,16,27,30-31],compute-b7-[2-6,9-11,53],compute-b8-[3-14,28,34,38,52] standard* up 7-00:00:00 10 idle compute-b6-[25-26,33,37-42,47] serial up 14-00:00:0 1 maint compute-b6-59 serial up 14-00:00:0 1 mix compute-b6-54 serial up 14-00:00:0 2 alloc compute-b6-[58,60] serial up 14-00:00:0 4 idle compute-b6-[53,55-57] gpu up 7-00:00:00 1 down$ gpu-a6-3 gpu up 7-00:00:00 1 drng gpu-b9-5 gpu up 7-00:00:00 1 drain gpu-b10-5 gpu up 7-00:00:00 19 mix gpu-a6-[6,8],gpu-b9-[1-4,6-7],gpu-b10-[1-3,6-7],gpu-b11-[1-6] gpu up 7-00:00:00 1 alloc gpu-b10-4 gpu up 7-00:00:00 6 idle gpu-a5-1,gpu-a6-[2,4-5,7,9] bigmem up 7-00:00:00 4 mix bigmem-a9-[1-2,4-5] bigmem up 7-00:00:00 2 alloc bigmem-a9-[3,6] Check partitial information %%bash scontrol show partition standard PartitionName=standard AllowGroups=ALL AllowAccounts=ALL AllowQos=ALL AllocNodes=ALL Default=YES QoS=N/A DefaultTime=00:15:00 DisableRootJobs=NO ExclusiveUser=NO GraceTime=0 Hidden=NO MaxNodes=UNLIMITED MaxTime=7-00:00:00 MinNodes=0 LLN=NO MaxCPUsPerNode=UNLIMITED MaxCPUsPerSocket=UNLIMITED Nodes=compute-a5-[3-11],compute-a7-[1-60],compute-a8-[1-60],compute-b5-[1-60],compute-b6-[1-52],compute-b7-[1-60],compute-b8-[1-56] PriorityJobFactor=1 PriorityTier=1 RootOnly=NO ReqResv=NO OverSubscribe=YES:4 OverTimeLimit=NONE PreemptMode=REQUEUE State=UP TotalCPUs=45696 TotalNodes=357 SelectTypeParameters=NONE JobDefaults=(null) DefMemPerNode=UNLIMITED MaxMemPerNode=UNLIMITED TRES=cpu=45696,mem=178500G,node=357,billing=45696 TRESBillingWeights=CPU=1.0,Mem=0.25G Display node config information %%bash scontrol show node compute-a5-3 NodeName=compute-a5-3 Arch=x86_64 CoresPerSocket=64 CPUAlloc=71 CPUEfctv=128 CPUTot=128 CPULoad=68.89 AvailableFeatures=rhel8,amd,epyc_7702,ib ActiveFeatures=rhel8,amd,epyc_7702,ib Gres=(null) NodeAddr=compute-a5-3 NodeHostName=compute-a5-3 Version=23.11.9 OS=Linux 4.18.0-553.5.1.el8_10.x86_64 #1 SMP Tue May 21 03:13:04 EDT 2024 RealMemory=512000 AllocMem=296960 FreeMem=326630 Sockets=2 Boards=1 State=MIXED ThreadsPerCore=1 TmpDisk=300000 Weight=1 Owner=N/A MCS_label=N/A Partitions=scavenger,standard BootTime=2024-08-08T18:32:48 SlurmdStartTime=2024-08-12T17:43:23 LastBusyTime=2024-08-12T17:43:19 ResumeAfterTime=None CfgTRES=cpu=128,mem=500G,billing=128 AllocTRES=cpu=71,mem=290G CapWatts=n/a CurrentWatts=630 AveWatts=294 ExtSensorsJoules=n/a ExtSensorsWatts=0 ExtSensorsTemp=n/a CPU Details: * Total CPUs: 128 * Allocated CPUs: 71 Memory: * Total Memory: 500 GB * Allocated Memory: 290 GB * Free Memory: ~319 GB View information about jobs located in the Slurm scheduling queue. %%bash squeue -u $USER JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 7563417 standard sys/dash xie186 R 48:15 1 compute-a5-5 Cancel a job %%bash scancel <JOBID>","title":"Basic Linux"},{"location":"basic_linux/#linux-for-bioinformatics","text":"","title":"Linux for Bioinformatics"},{"location":"basic_linux/#navigating-in-linux-file-system","text":"You are in your home directory after you log into the system and are directed to the shell command prompt. This section will show you hot to explore Linux file system using shell commands.","title":"Navigating in Linux file system"},{"location":"basic_linux/#path","text":"To understand Linux file system, you can image it as a tree structure. In Linux, a path is a unique location of a file or a directory in the file system. For convenience, Linux file system is usually thought of in a tree structure. On a standard Linux system you will find the layout generally follows the scheme presented below. The tree of the file system starts at the trunk or slash, indicated by a forward slash ( / ). This directory, containing all underlying directories and files, is also called the root directory or \u201cthe root\u201d of the file system. %%bash ## In your account, you will see a folder ## with you account ID as the name cd ~ echo $HOME /home/xie186","title":"Path"},{"location":"basic_linux/#relative-and-absolute-path","text":"Absolute path An absolute path is defined as the location of a file or directory from the root directory(/). An absolute path starts from the root of the tree ( / ). Here are some examples: /home/xie186 /home/xie186/.bashrc Relative path Relative path is a path related to the present working directory: data/sample1/ and ../doc/ . If you want to get the absolute path based on relative path , you can use readlink with parameter -f : pwd readlink -f ../ Once we enter into a Linux file system, we need to 1) know where we are; 2) how to get where we want; 3) how to know what files or directories we have in a particular path.","title":"Relative and absolute path"},{"location":"basic_linux/#check-where-you-are-using-command-pwd","text":"In order to know where we are, we need to use pwd command. The command pwd is short for \u201cprint name of current/working directory\u201d. It will return the full path of current directory. Command pwd is almost always used by itself. This means you only need to type pwd and press ENTER %%bash pwd","title":"Check where you are using command pwd"},{"location":"basic_linux/#listing-the-contents-using-command-ls","text":"After you know where you are, then you want to know what you have in that directory, we can use command ls to list directory contents Its syntax is: ls [option]... [file]... ls with no option will list files and directories in bare format. Bare format means the detailed information (type, size, modified date and time, permissions and links etc) won\u2019t be viewed. When you use ls by itself, it will list files and directories in the current directory. ls ~/ ls -a ls -ld Linux command options can be combined without a space between them and with a single - (dash). The following command is a faster way to use the l and a options and gives the same output as the Linux command shown above. ls -lt ~/.bashrc -rw-r--r--. 1 xie186 zt-bioi611 1067 Aug 22 22:27 /home/xie186/.bashrc","title":"Listing the contents using command ls"},{"location":"basic_linux/#change-directory-using-command-cd","text":"Unlike pwd , when you use cd you usually need to provide the path (either absolute or relative path) which we want to enter. If you didn\u2019t provide any path information, you will change to home directory by default. Path Shortcuts Description Single dot . The current folder Double dots .. The folder above the current folder Tilde character ~ Home directory (normally the directory:/home/my_login_name) Dash - Your last working directory Here are some examples: cd ~ pwd ls ls ../ ## pwd cd ../ pwd cd ./ pwd Each directory has two entries in it at the start, with names . (a link to itself) and .. (a link to its parent directory). The exception, of course, is the root directory, where the .. directory also refers to the root directory. Sometimes you go to a new directory and do something, then you remember that you need to go to the previous working direcotry. To get back instantly, use a dash. %%bash # This is our current directory pwd # Let us go our home diretory cd ~ # Check where we are pwd # Let us go to your previous working directory cd - # Check where we are now pwd /home/xie186/BIOI611_lab/docs /home/xie186 /home/xie186/BIOI611_lab/docs /home/xie186/BIOI611_lab/docs","title":"Change directory using command cd"},{"location":"basic_linux/#manipulations-of-files-and-directories","text":"In Linux, manipulations of files and directories are the most frequent work. In this section, you will learn how to copy, rename, remove, and create files and directories.","title":"Manipulations of files and directories"},{"location":"basic_linux/#command-line-cp","text":"In Linux, command cp can help you copy files and directories into a target directory.","title":"Command line cp"},{"location":"basic_linux/#command-line-mv","text":"Move files/folders and rename file/folders using mv : # move file from one location to another mv file1 target_direcotry/ # rename mv file1 file2 mv file1 file2 file3 target_direcotry/","title":"Command line mv"},{"location":"basic_linux/#command-mkdir","text":"The syntax is shown as below: mkdir [OPTION ...] DIRECTORY ... Multiple directories can be specified when calling mkdir mkdir directory1 directory2 mkdir -p foo/bar/baz How to defining complex directory trees with one command: mkdir -p project/{software,results,doc/{html,info,pdf},scripts} Then you can view the directory using tree .","title":"Command mkdir"},{"location":"basic_linux/#command-rm","text":"You can use rm to remove both files and directories. ## You can remove one file. rm file1 ## `rm` can remove multiple files simutaneously rm file2 file3 You can also use 'rm' to remove a folder. If a folder is empty, you can remove it using rm with -r . rm -r FOLDER If a folder is not empty, you can remove it using rm with -r and -f . mkdir test_folder rm -r test_folder","title":"Command rm"},{"location":"basic_linux/#view-text-files-in-linux","text":"","title":"View text files in Linux"},{"location":"basic_linux/#commands-cat-more-and-less","text":"The command cat is short for concatenate files and print on the standard output. The syntax is shown as below: cat [OPTION]... [FILE]... For small text file, cat can be used to view the files on the standard output. The command more is old utility. When the text passed to it is too large to fit on one screen, it pages it. You can scroll down but not up. The syntaxt of more is shown below: more [options] file [...] The command less was written by a man who was fed up with more\u2019s inability to scroll backwards through a file. He turned less into an open source project and over time, various individuals added new features to it. less is massive now. That\u2019s why some small embedded systems have more but not less. For comparison, less\u2019s source is over 27000 lines long. more implementations are generally only a little over 2000 lines long. The syntaxt of less is shown below: less [options] file [...]","title":"Commands cat, more and less"},{"location":"basic_linux/#command-head-and-tail","text":"The command head is used to output the first part of files. By default, it outputs the first 10 lines of the file. head [OPTION]... [FILE]... Here is an exmaple of printing the first 5 files of the file: head -n 5 code_perl/variable_assign.pl In fact, the letter n does not even need to be used at all. Just the hyphen and the integer (with no intervening space) are sufficient to tell head how many lines to return. Thus, the following would produce the same result as the above commands: head -5 target_file.txt The command tail is used to output the last part of files. By default, it prints the last 10 lines of the file to standard output. The syntax is shown below: tail [OPTION]... [FILE]... Here is an exmaple of printing the last 5 files of the file: tail -5 target_file.txt To view lines from a specific point in a file, you can use -n +NUMBER with the tail command. For example, here is an example of viewing the file from the 2nd line of the line. tail -n +2 target_file.txt","title":"Command head and tail"},{"location":"basic_linux/#auto-completion","text":"In most Shell environment, programmable completion feature will also improve your speed of typing. It permits typing a partial name of command or a partial file (or directory), then pressing TAB key to auto-complete the command. If there are more than one possible completions, then TAB will list all of them. A handy autocomplete feature also exists. Type one or more letters, press the Tab key twice, and then a list of functions starting with these letters appears. For example: type so , press the Tab key twice, and then you get the list as: soelim sort sotruss soundstretch source Demonstration of programmable completion feature.","title":"Auto-completion"},{"location":"basic_linux/#file-permissions","text":"In Linux, file permissions are a vital aspect of system security and resource management. This is particularly important in bioinformatics, where large datasets and scripts are often shared across teams. Permissions determine who can read, write, or execute a file, ensuring that critical data is not accidentally modified or deleted. Three Permission Categories : User (u): The owner of the file. Group (g): A group of users who share access to the file. Other (o): All other users on the system. Permission Types : Read (r): Ability to view the contents of a file. Write (w): Ability to modify or delete the file. Execute (x): Ability to run the file as a program (for scripts or executables). %%bash groups $USER animako eunal gstewar1 mjames17 mjeakle nmilza rahooper xie186 : zt-bioi611 zt-bioi611_mgr animako : zt-bioi611 eunal : zt-bioi611 gstewar1 : zt-bioi611 mjames17 : zt-bioi611 mjeakle : zt-bioi611 nmilza : zt-bioi611 rahooper : zt-bioi611 %%bash mkdir -p ~/test_permission/ touch ~/test_permission/test.txt ls -l ~/test_permission/ rm -rf ~/test_permission/ total 0 -rw-r--r--. 1 xie186 zt-bioi611 0 Sep 8 22:52 test.txt Here, the first character represents the type of file (e.g., - for a regular file or d for a directory), followed by three groups of three characters, each representing the permissions for the user , group , and others , respectively. Examples: -rwxr-xr-- : The owner has read , write , and execute permissions. The group has read and execute permissions, while others can only read the file. drwxr-x--- : A directory where the owner can read, write, and access (execute). The group can only read and access, while others have no permissions. Modify file permissions using the chmod command. Permissions can be set in two ways: Symbolic Mode: In symbolic mode, you modify permissions by referencing the categories (user, group, other) and specifying whether you're adding (+), removing (-), or setting (=) permissions. # Add execute permission for the user: chmod u+x filename # Remove write permission for the group: chmod g-w filename # Set read-only permission for others: chmod o=r filename Symbolic mode is intuitive and flexible, especially when you want to make precise adjustments to permissions without affecting other categories. This is useful for common file-sharing tasks in bioinformatics where you need to tweak access for specific collaborators. Numeric Mode (Octal representation): In numeric mode, file permissions are set using a three-digit number. Each digit represents the permissions for user , group , and other , respectively. The digits are calculated by adding the values of the read , write , and execute` permissions: Read (r) = 4 Write (w) = 2 Execute (x) = 1 Example Permission Breakdown: Read (r), Write (w), and Execute (x) for user = 7 Read (r) and Execute (x) for group = 5 Read (r) only for others = 4 chmod 754 filename An example to help you understand executable : %%bash printf '#!/user/bin/python\\nprint(\"Hello, Welcome to Course BIOI611!\")' > ~/test.py %%bash ls -l ~/test.py python ~/test.py -rw-r--r--. 1 xie186 zt-bioi611 61 Sep 8 23:06 /home/xie186/test.py Hello, Welcome to Course BIOI611! Error message below will be thrown out if you consider ~/test.py as a program: bash: line 1: /home/xie186/test.py: No such file or directory %%bash chmod u+x ~/test.py ls -l ~/test.py python ~/test.py rm ~/test.py -rwxr--r--. 1 xie186 zt-bioi611 61 Sep 8 23:06 /home/xie186/test.py Hello, Welcome to Course BIOI611!","title":"File permissions"},{"location":"basic_linux/#disk-usage-of-files-and-directories","text":"The Linux du (short for Disk Usage) is a standard Unix/Linux command, used to check the information of disk usage of files and directories on a machine. The du command has many parameter options that can be used to get the results in many formats. The du command also displays the files and directory sizes in a recursively manner. %%bash du -h ~/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref 2.5G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref %%bash du -ah ~/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref 2.9M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/sjdbList.fromGTF.out.tab 7.5K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/Log.out 936M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/SA 1.5G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/SAindex 3.0M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/transcriptInfo.tab 2.3M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/sjdbList.out.tab 1.5M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/geneInfo.tab 1.0K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/genomeParameters.txt 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/chrLength.txt 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/chrNameLength.txt 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/chrStart.txt 7.6M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/exonGeTrInfo.tab 3.1M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/exonInfo.tab 2.8M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/sjdbInfo.txt 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/chrName.txt 119M /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref/Genome 2.5G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref %%bash du -csh /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/* 19G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/raw_data 0 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/raw_data_smart_seq 1.5K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s1_download_data.sub 575K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s1_download_smart_seq-7478223-xie186.err 0 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s1_download_smart_seq-7478223-xie186.out 8.5K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s1_download_smart_seq.sub 2.5K /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/s2_star.sub 34G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_align 2.5G /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/STAR_ref 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/test.sub 512 /home/xie186/scratch.bioi611/Analysis/bulk_RNAseq/test.txt 55G total","title":"Disk Usage of Files and Directories"},{"location":"basic_linux/#symbolic-link","text":"Symbolic link, similar to shortcuts, can point to another file/folder. ln -s <path_to_files/folder_to_be_linked> <symlink_to_be_created> ls -l <symlink> unlink <symlink>","title":"Symbolic link"},{"location":"basic_linux/#file-management-and-data-handling","text":"","title":"File Management and Data Handling"},{"location":"basic_linux/#compressing-and-decompressing-files-gzip-gunzip-tar","text":"Compress one file: %%bash perl -e 'for($i=0; $i<10000; ++$i){ print \"test\\n\";}' > test.txt du -h test.txt gzip test.txt du -h test.txt.gz gunzip test.txt ls test.txt rm test.txt 52K test.txt 4.0K test.txt.gz test.txt Compress multiple files: %%bash perl -e 'for($i=0; $i<10000; ++$i){ print \"test\\n\";}' > test1.txt perl -e 'for($i=0; $i<10000; ++$i){ print \"test\\n\";}' > test2.txt du -h test1.txt test2.txt tar zcvf test.tar.gz test1.txt test2.txt du -sh test.tar.gz ls test1.txt test2.txt 52K test1.txt 52K test2.txt test1.txt test2.txt 4.0K test.tar.gz test1.txt test2.txt z : This option tells tar to compress the archive using gzip. The resulting archive will have a .gz extension to indicate that it has been compressed with the gzip utility. c : This option stands for create. It instructs tar to create a new archive. v : This stands for verbose. When used, tar will display detailed information about the files being added to the archive, such as their names. f : This stands for file. It tells tar that the next argument (test.tar.gz) is the name of the archive file to create. %%bash tar tvf test.tar.gz rm test.tar.gz test1.txt test2.txt -rw-r--r-- xie186/zt-bioi611 50000 2024-08-25 21:52 test1.txt -rw-r--r-- xie186/zt-bioi611 50000 2024-08-25 21:52 test2.txt t : List the contents of archive.tar. v : Display additional details about each file (like file permissions, size, and modification date). f : Specifies that archive.tar is the archive file to operate on. To uncompress a tar.gz file, use tar zxvf : tar zxvf test.tar.gz","title":"Compressing and decompressing files (gzip, gunzip, tar)."},{"location":"basic_linux/#transferring-files-within-the-network","text":"Basic Syntax of scp : scp [options] source destination Copy a Local File to a Remote Server scp file.txt username@remote_host:/path/to/destination/ Alternative command is rsync .","title":"Transferring files within the network"},{"location":"basic_linux/#file-searching-filtering-and-text-processing","text":"","title":"File searching, filtering, and text processing"},{"location":"basic_linux/#command-find","text":"The find command is designed for comprehensive file and directory sesarches. find [path] [options] [expression] %%bash find /home/xie186/scratch/bioi611/bulk_RNAseq -name \"*.fastq.gz\" /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day7_rep3.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day1_rep3.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day1_rep1.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day7_rep1.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day1_rep2.fastq.gz /home/xie186/scratch/bioi611/bulk_RNAseq/raw_data/N2_day7_rep2.fastq.gz","title":"Command find"},{"location":"basic_linux/#text-data-counts-wc","text":"%%bash find /home/xie186/scratch/bioi611/bulk_RNAseq -name \"*.fastq.gz\" |wc -l 6","title":"Text data counts wc"},{"location":"basic_linux/#pipe","text":"In Linux and Unix-based systems, the pipe ( | ) is used in the command line to redirect the output of one command as the input to another command. This allows you to chain commands together and perform more complex tasks in a single line. %%bash grep '>' ~/scratch/bioi611/reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa |wc -l 7","title":"Pipe |"},{"location":"basic_linux/#column-filering","text":"Command cut can be used to print selected parts of lines from each FILE to standard output. %%bash wget -O GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz \"https://ncbi.nlm.nih.gov/geo/download/?type=rnaseq_counts&acc=GSE102537&format=file&file=GSE102537_raw_counts_GRCh38.p13_NCBI.tsv.gz\" --2024-08-25 21:08:03-- https://ncbi.nlm.nih.gov/geo/download/?type=rnaseq_counts&acc=GSE102537&format=file&file=GSE102537_raw_counts_GRCh38.p13_NCBI.tsv.gz Resolving ncbi.nlm.nih.gov (ncbi.nlm.nih.gov)... 2607:f220:41e:4290::110, 130.14.29.110 Connecting to ncbi.nlm.nih.gov (ncbi.nlm.nih.gov)|2607:f220:41e:4290::110|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 349584 (341K) [application/octet-stream] Saving to: \u2018GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz\u2019 0K .......... .......... .......... .......... .......... 14% 6.66M 0s 50K .......... .......... .......... .......... .......... 29% 16.9M 0s 100K .......... .......... .......... .......... .......... 43% 27.5M 0s 150K .......... .......... .......... .......... .......... 58% 10.1M 0s 200K .......... .......... .......... .......... .......... 73% 17.2M 0s 250K .......... .......... .......... .......... .......... 87% 37.6M 0s 300K .......... .......... .......... .......... . 100% 10.5M=0.02s 2024-08-25 21:08:04 (13.4 MB/s) - \u2018GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz\u2019 saved [349584/349584] %%bash zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |head GeneID GSM2740270 GSM2740272 GSM2740273 GSM2740274 GSM2740275 100287102 9 17 14 14 19 653635 336 470 467 310 370 102466751 8 56 46 31 31 107985730 0 2 2 3 3 100302278 0 1 0 0 2 645520 0 3 8 4 7 79501 0 2 2 1 4 100996442 16 25 34 20 28 729737 19 39 33 22 26 %%bash zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |cut -f1,2,3 |head GeneID GSM2740270 GSM2740272 100287102 9 17 653635 336 470 102466751 8 56 107985730 0 2 100302278 0 1 645520 0 3 79501 0 2 100996442 16 25 729737 19 39","title":"Column filering"},{"location":"basic_linux/#row-filtering","text":"%%bash grep '>' ~/scratch/bioi611/reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa >I dna:chromosome chromosome:WBcel235:I:1:15072434:1 REF >II dna:chromosome chromosome:WBcel235:II:1:15279421:1 REF >III dna:chromosome chromosome:WBcel235:III:1:13783801:1 REF >IV dna:chromosome chromosome:WBcel235:IV:1:17493829:1 REF >V dna:chromosome chromosome:WBcel235:V:1:20924180:1 REF >X dna:chromosome chromosome:WBcel235:X:1:17718942:1 REF >MtDNA dna:chromosome chromosome:WBcel235:MtDNA:1:13794:1 REF %%bash zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |wc -l zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |awk '$2>500' |wc -l zcat GSE164073_raw_counts_GRCh38.p13_NCBI.tsv.gz |awk '$2>500 && $3>500' |wc -l 39377 8773 3820","title":"Row filtering"},{"location":"basic_linux/#text-processing","text":"%%bash grep '>' ~/scratch/bioi611/reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa |sed 's/>//' |sed 's/ .*//' I II III IV V X MtDNA","title":"Text processing"},{"location":"basic_linux/#regular-expressions","text":"Regular expressions are sequences of characters that define search patterns. They are commonly used for string matching, searching, and text processing. Regex is used in text editors, programming languages, command-line tools (like grep and sed ), and many bioinformatics tools to search, replace, or extract data from text. Metacharacters: Special characters that have specific meanings in regex syntax. . (dot): Matches any single character except a newline. Example: A.G matches \"AAG\", \"ATG\", \"ACG\", etc. ^ : Matches the start of a line. Example: ^A matches any line starting with \"A\". $ : Matches the end of a line. Example: end$ matches any line ending with \"end\". * : Matches 0 or more occurrences of the preceding character. Example: ca*t matches \"ct\", \"cat\", \"caat\", \"caaat\", etc. + : Matches 1 or more occurrences of the preceding character. Example: ca+t matches \"cat\", \"caat\", \"caaat\", etc. ? : Matches 0 or 1 occurrence of the preceding character. Example: colou?r matches both \"color\" and \"colour\". [] : Matches any one of the characters inside the brackets. Example: [aeiou] matches any vowel. | : Alternation (OR) operator. Example: cat|dog matches either \"cat\" or \"dog\". Character Classes: Represents a set of characters. \\d : Matches any digit (equivalent to [0-9]). \\w : Matches any word character (alphanumeric or underscore). \\s : Matches any whitespace character (spaces, tabs, etc.). \\D : Matches any non-digit character. \\W : Matches any non-word character. \\S : Matches any non-whitespace character. Quantifiers: Specify the number of occurrences to match {n} : Matches exactly n occurrences. Example: A{3} matches \"AAA\". {n,} : Matches n or more occurrences. Example: T{2,} matches \"TT\", \"TTT\", \"TTTT\", etc. {n,m} : Matches between n and m occurrences. Example: G{1,3} matches \"G\", \"GG\", or \"GGG\".","title":"Regular Expressions"},{"location":"basic_linux/#an-example-of-the-command-line-used","text":"%%bash grep -v '#' ~/scratch/bioi611/reference/Caenorhabditis_elegans.WBcel235.111.gtf \\ |awk '$3==\"gene\"' \\ |sed 's/.*gene_biotype \"//' \\ |sed 's/\";//'|sort |uniq -c \\ | sort -k1,1n 22 rRNA 100 antisense_RNA 129 snRNA 194 lincRNA 261 miRNA 346 snoRNA 634 tRNA 2128 pseudogene 7764 ncRNA 15363 piRNA 19985 protein_coding","title":"An example of the command line used"},{"location":"basic_linux/#environment-variables","text":"Environment variables are dynamic values that affect the behavior of processes and programs in Linux. They are commonly used to store configuration data and are essential in bioinformatics workflows for defining paths to software, libraries, and datasets.","title":"Environment variables"},{"location":"basic_linux/#commonly-used-environment-variables","text":"PATH : The PATH variable specifies directories where the system looks for executable files when a command is run. %%bash echo $PATH /cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/texlive/bin/x86_64-linux:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/imagemagick/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/graphviz/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/ghostscript/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/ffmpeg/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/mpi-nocuda/linux-rhel8-zen2/gcc/11.3.0/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/nompi-nocuda/linux-rhel8-zen2/gcc/11.3.0/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/compiler/linux-rhel8-zen2/gcc/11.3.0/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/linux-rhel8-x86_64/gcc-rh8-8.5.0/gcc-11.3.0-oedkmii7vhd6rbnqm6xufmg7d3jx4w6l/bin:/cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/linux-rhel8-zen2/gcc-11.3.0/py-jupyter-1.0.0-trwwgzwljql55mhmaygcuxb3nvaevjsu/bin:/software/acigs-utilities/bin:/home/xie186/miniforge3/bin:/home/xie186/miniforge3/condabin:/home/xie186/SHELL.bioi611/software/STAR_2.7.11b/Linux_x86_64_static:/home/xie186/.local/bin:/home/xie186/bin:/software/acigs-utilities/bin:/usr/share/Modules/bin:/usr/lib/heimdal/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/symas/bin:/opt/dell/srvadmin/bin HOME : The HOME variable stores the path to the user\u2019s home directory. %%bash echo $HOME /home/xie186 %%bash echo $SHELL /bin/bash","title":"Commonly Used Environment Variables:"},{"location":"basic_linux/#setting-environment-variables","text":"Temporarily setting a variable (valid only for the current shell session): export PATH=value:PATH Permanently setting a variable: To make the environment variable persistent across sessions, it needs to be added to configuration files like .bashrc or .bash_profile . Example: Add the following line to .bashrc :","title":"Setting Environment Variables:"},{"location":"basic_linux/#software-installation","text":"","title":"Software installation"},{"location":"basic_linux/#installation-via-conda","text":"Conda is a popular package management system, especially in bioinformatics, due to its ability to create isolated environments. This is crucial when working with tools that have conflicting dependencies. Install conda/miniforge Go to: https://github.com/conda-forge/miniforge/releases Download the corresponding installtion file %%bash uname -m x86_64 wget https://github.com/conda-forge/miniforge/releases/download/24.7.1-0/Mambaforge-24.7.1-0-Linux-x86_64.sh Create conda environment and install software conda create -n bioi611 conda activate bioi611 conda install bioconda::fastqc==0.11.8","title":"Installation via Conda"},{"location":"basic_linux/#installation-via-source-code-manual-compilation","text":"git clone https://github.com/lh3/bwa.git cd bwa; make ./bwa index ref.fa","title":"Installation via Source Code (Manual Compilation)"},{"location":"basic_linux/#using-container-for-bioinformatics-tools","text":"","title":"Using Container for Bioinformatics Tools"},{"location":"basic_linux/#understanding-containers-and-using-singularity","text":"What Are Containers? Containers are lightweight, portable environments that bundle software and all its dependencies so that it runs consistently on any system. Think of a container as a \"self-contained laboratory\" \u2014 it has all the reagents (software, libraries, dependencies) you need, already prepared. In Bioinformatics, where different tools depend on specific versions of Python, R, or system libraries, containers ensure: Reproducibility: The same tool produces the same results on any computer or HPC. Portability: You can run the same environment locally, in the cloud, or on a supercomputer. Isolation: Tools run in separate environments, avoiding conflicts between software packages. Docker vs. Singularity Feature Docker Singularity Designed for Cloud, local systems HPC, clusters Requires root privileges Yes No (runs safely in user space) Image format .tar / .img (Docker images) .sif (Singularity Image File) Integration with HPC Limited Excellent Common in DevOps, cloud platforms Research, bioinformatics, academia Most High-Performance Computing (HPC) systems do not allow Docker because it requires root privileges. Instead, they use Singularity, which can pull Docker images and convert them into a format that\u2019s safe for HPC environments. Why Use Containers in Bioinformatics? Bioinformatics tools often require: Complex dependencies (e.g., different versions of glibc, python, boost, etc.) Conflicting library versions Long installation times Using containers solves these issues. For example: You can use Biocontainers \u2014 prebuilt containers with thousands of bioinformatics tools. Each container is tested and version-controlled. No need to install software manually. Example: Using Singularity to Run TrimGalore TrimGalore is a widely used tool for quality-control sequencing data. It combines Cutadapt and FastQC to trim adapters and assess read quality. Instead of manually installing it, we can use a pre-built Biocontainer. Step 1. Load Singularity on the HPC On most HPC systems, Singularity is provided as a module: module load singularity Step 2. Build a Singularity Image from a Docker Container The BioContainers project provides many pre-built Docker images for bioinformatics tools. Singularity can directly convert these Docker images into a Singularity Image File (.sif) suitable for HPC use: singularity build trimgalore_v0.6.10.sif docker://quay.io/biocontainers/trim-galore:0.6.10--hdfd78af_0 This command downloads the Docker image from Quay.io and converts it into a local .sif file. Step 3. Run TrimGalore from the Container You can run commands inside the container using singularity exec . For example, to check that TrimGalore is available: singularity exec trimgalore_v0.6.10.sif trim_galore --help If you want to run the tool on data located in your project directory, bind-mount the directory so that it\u2019s accessible inside the container: singularity exec -B /scratch/zt1/project/bioi611/ trimgalore_v0.6.10.sif trim_galore --help The -B option (short for bind ) makes the specified directory available inside the container. Step 4. (Optional) Enter the Container for an Interactive Session singularity exec -B /scratch/zt1/project/bioi611/ trimgalore_v0.6.10.sif /bin/bash From there, you can directly run commands as if TrimGalore were installed on your system. Step Action Command Example 1 Load Singularity module load singularity 2 Build the image singularity build trimgalore_v0.6.10.sif docker://quay.io/biocontainers/trim-galore:0.6.10--hdfd78af_0 3 Run the tool singularity exec trimgalore_v0.6.10.sif trim_galore --help 4 Interactive mode singularity exec -B /scratch/... trimgalore_v0.6.10.sif /bin/bash","title":"Understanding Containers and Using Singularity"},{"location":"basic_linux/#text-editor-in-linux","text":"In Linux, we sometimes need to create or edit a text file like writing a new perl script. So we need to use text editor. As a newbie, someone would prefer a basic, GUI-based text editor with menus and traditional CUA key bindings. Here we recommend Sublime , ATOM and Notepad++ . But GUI-based text editor is not always available in Linux. A powerful screen text editor vi (pronounced \u201cvee-eye\u201d) is available on nearly all Linux system. We highly recommend vi as a text editor, because something we\u2019ll have to edit a text file on a system without a friendlier text editor. Once we get familiar with vi , we\u2019ll find that it\u2019s very fast and powerful. But remember, it\u2019s OK if you think this part is too difficult at the beginning. You can use either Sublime , ATOM or Notepad++ . If you are connecting to a Linux system without Sublime , ATOM and Notepad++ , you can write the file in a local computer and then upload the file onto Linux system.","title":"Text editor in Linux"},{"location":"basic_linux/#basic-vi-skills","text":"As vi uses a lot of combination of keystrokes, it may be not easy for newbies to remember all the combinations in one fell swoop. Considering this, we\u2019ll first introduce the basic skills someone needs to know to use vi . We need to first understand how three modes of vi work and then try to remember a few basic vi commonds. Then we can use these skills to write Perl or R scripts in the following chaptors for Perl and R (Figure \\@ref(fig:workingModeVi)). Three modes of vi :","title":"Basic vi skills"},{"location":"basic_linux/#create-new-text-file-with-vi","text":"mkdir test_vi ## generate a new folder cd test_vi ## go into the new folder echo \"Using \\`ls\\` we don't expect files in this folder.\" ls echo \"No file displayed!\" Using the code above, we made a new directory named test_vi . We didn't see any file. If we type vi test.py , an empty file and screen are created into which you may enter text because the file does not exist((Figure \\@ref(fig:ViNewFile))). vi test.py A screentshot of the vi test.py . Now if you are in vi mode . To go to Input mode , you can type i , 'a' or 'o' (Figure \\@ref(fig:ViInpuMode)). Now you can type the content (codes or other information) (\\@ref(fig:ViInpuType)). Once you are done typing. You need to go to Command mode (Figure \\@ref(fig:workingModeVi)) if you want to save and exit the file. To do this, you need to press ESC button on the keyboard. Now we just wrote a Perl script. We can run this script. python test.py","title":"Create new text file with vi"},{"location":"basic_linux/#high-performance-computing-hpc-for-bioinformatics","text":"HPC resources enable bioinformatics analyses that require significant computational power and memory.","title":"High-Performance Computing (HPC) for Bioinformatics"},{"location":"basic_linux/#basics-of-hpc-clusters-and-job-schedulers-slurm","text":"An example of an job file ( s1_star.sh ): #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH -n 1 #SBATCH -c 20 #SBATCH --job-name=s1_star_aln #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out conda activate bioi611 mkdir -p STAR_align/ STAR --genomeDir STAR_ref \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix STAR_align/N2_day1_rep1. \\ --runThreadN 20 \\ --readFilesIn raw_data/N2_day1_rep1.fastq.gz To submit this job, run: sbatch s1_star.sh","title":"Basics of HPC clusters and job schedulers (SLURM)."},{"location":"basic_linux/#check-quota-infomation","text":"%%bash scratch_quota # shell_quota # Group quotas Group name Space used Space quota % quota used zt-bioi611 285.811 MB 4.000 TB 0.01% zt-bioi611_mgr 98.163 GB unlimited 0 total 98.449 GB unlimited 0 # User quotas User name Space used Space quota % quota used % of GrpTotal xie186 98.449 GB unlimited 0 100.00%","title":"Check quota infomation"},{"location":"basic_linux/#view-information-about-slurm-nodes-and-partitions","text":"%%bash sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST debug up 15:00 1 maint compute-b8-60 debug up 15:00 1 drng compute-b8-57 debug up 15:00 1 mix compute-b8-59 debug up 15:00 1 alloc compute-b8-58 scavenger up 14-00:00:0 1 inval compute-b8-48 scavenger up 14-00:00:0 4 drain$ compute-b8-[53-56] scavenger up 14-00:00:0 84 maint compute-a7-[5,9,14-16,28,49],compute-a8-[2-4,8-9,15,18,22,24,29,37,44,51],compute-b5-[4,16,26,29-30,33,44,51-52],compute-b6-[7,12,21,28-29,32,34,43-46,50-51,59],compute-b7-[12-13,19-22,25,27,29,31,35,37,39,42,45-46,49-50,54,56-59],compute-b8-[16,19,21,23-24,29,32,35-37,39-45,60] scavenger up 14-00:00:0 2 drain* compute-a7-[13,43] scavenger up 14-00:00:0 13 drng compute-a8-[7,14],compute-b7-[14-15,18,38,43-44],compute-b8-[2,20,51,57],gpu-b9-5 scavenger up 14-00:00:0 2 drain compute-a7-8,gpu-b10-5 scavenger up 14-00:00:0 182 mix bigmem-a9-[1-2,4-5],compute-a5-[3-11],compute-a7-[2-3,6-7,10,12,17-19,21-22,30,38-40,45-46,48,54-56,60],compute-a8-[5-6,10-12,16-17,19-21,25,28,31-35,39,41,45,47,50,52,54,57-59],compute-b5-[1-3,5-8,11,13-15,17-25,27-28,31-32,34-43,45-50,53-55,57-58],compute-b6-[1-5,14-15,17-20,22-24,35-36,48-49,52,54],compute-b7-[1,7-8,16-17,23-24,26,28,30,32-34,36,40-41,47-48,51-52,55,60],compute-b8-[1,15,17-18,22,25-27,30-31,33,46-47,49-50,59],gpu-b9-[1-4,6-7],gpu-b10-[1-3,6-7],gpu-b11-[1-6] scavenger up 14-00:00:0 93 alloc bigmem-a9-[3,6],compute-a7-[1,4,11,20,23-27,29,31-37,41-42,44,47,50-53,57-59],compute-a8-[1,13,23,26-27,30,36,38,40,42-43,46,48-49,53,55-56,60],compute-b5-[9-10,12,56,59-60],compute-b6-[6,8-11,13,16,27,30-31,58,60],compute-b7-[2-6,9-11,53],compute-b8-[3-14,28,34,38,52,58],gpu-b10-4 scavenger up 14-00:00:0 14 idle compute-b6-[25-26,33,37-42,47,53,55-57] standard* up 7-00:00:00 1 inval compute-b8-48 standard* up 7-00:00:00 4 drain$ compute-b8-[53-56] standard* up 7-00:00:00 82 maint compute-a7-[5,9,14-16,28,49],compute-a8-[2-4,8-9,15,18,22,24,29,37,44,51],compute-b5-[4,16,26,29-30,33,44,51-52],compute-b6-[7,12,21,28-29,32,34,43-46,50-51],compute-b7-[12-13,19-22,25,27,29,31,35,37,39,42,45-46,49-50,54,56-59],compute-b8-[16,19,21,23-24,29,32,35-37,39-45] standard* up 7-00:00:00 2 drain* compute-a7-[13,43] standard* up 7-00:00:00 11 drng compute-a8-[7,14],compute-b7-[14-15,18,38,43-44],compute-b8-[2,20,51] standard* up 7-00:00:00 1 drain compute-a7-8 standard* up 7-00:00:00 159 mix compute-a5-[3-11],compute-a7-[2-3,6-7,10,12,17-19,21-22,30,38-40,45-46,48,54-56,60],compute-a8-[5-6,10-12,16-17,19-21,25,28,31-35,39,41,45,47,50,52,54,57-59],compute-b5-[1-3,5-8,11,13-15,17-25,27-28,31-32,34-43,45-50,53-55,57-58],compute-b6-[1-5,14-15,17-20,22-24,35-36,48-49,52],compute-b7-[1,7-8,16-17,23-24,26,28,30,32-34,36,40-41,47-48,51-52,55,60],compute-b8-[1,15,17-18,22,25-27,30-31,33,46-47,49-50] standard* up 7-00:00:00 87 alloc compute-a7-[1,4,11,20,23-27,29,31-37,41-42,44,47,50-53,57-59],compute-a8-[1,13,23,26-27,30,36,38,40,42-43,46,48-49,53,55-56,60],compute-b5-[9-10,12,56,59-60],compute-b6-[6,8-11,13,16,27,30-31],compute-b7-[2-6,9-11,53],compute-b8-[3-14,28,34,38,52] standard* up 7-00:00:00 10 idle compute-b6-[25-26,33,37-42,47] serial up 14-00:00:0 1 maint compute-b6-59 serial up 14-00:00:0 1 mix compute-b6-54 serial up 14-00:00:0 2 alloc compute-b6-[58,60] serial up 14-00:00:0 4 idle compute-b6-[53,55-57] gpu up 7-00:00:00 1 down$ gpu-a6-3 gpu up 7-00:00:00 1 drng gpu-b9-5 gpu up 7-00:00:00 1 drain gpu-b10-5 gpu up 7-00:00:00 19 mix gpu-a6-[6,8],gpu-b9-[1-4,6-7],gpu-b10-[1-3,6-7],gpu-b11-[1-6] gpu up 7-00:00:00 1 alloc gpu-b10-4 gpu up 7-00:00:00 6 idle gpu-a5-1,gpu-a6-[2,4-5,7,9] bigmem up 7-00:00:00 4 mix bigmem-a9-[1-2,4-5] bigmem up 7-00:00:00 2 alloc bigmem-a9-[3,6]","title":"View information about Slurm nodes and partitions."},{"location":"basic_linux/#check-partitial-information","text":"%%bash scontrol show partition standard PartitionName=standard AllowGroups=ALL AllowAccounts=ALL AllowQos=ALL AllocNodes=ALL Default=YES QoS=N/A DefaultTime=00:15:00 DisableRootJobs=NO ExclusiveUser=NO GraceTime=0 Hidden=NO MaxNodes=UNLIMITED MaxTime=7-00:00:00 MinNodes=0 LLN=NO MaxCPUsPerNode=UNLIMITED MaxCPUsPerSocket=UNLIMITED Nodes=compute-a5-[3-11],compute-a7-[1-60],compute-a8-[1-60],compute-b5-[1-60],compute-b6-[1-52],compute-b7-[1-60],compute-b8-[1-56] PriorityJobFactor=1 PriorityTier=1 RootOnly=NO ReqResv=NO OverSubscribe=YES:4 OverTimeLimit=NONE PreemptMode=REQUEUE State=UP TotalCPUs=45696 TotalNodes=357 SelectTypeParameters=NONE JobDefaults=(null) DefMemPerNode=UNLIMITED MaxMemPerNode=UNLIMITED TRES=cpu=45696,mem=178500G,node=357,billing=45696 TRESBillingWeights=CPU=1.0,Mem=0.25G","title":"Check partitial information"},{"location":"basic_linux/#display-node-config-information","text":"%%bash scontrol show node compute-a5-3 NodeName=compute-a5-3 Arch=x86_64 CoresPerSocket=64 CPUAlloc=71 CPUEfctv=128 CPUTot=128 CPULoad=68.89 AvailableFeatures=rhel8,amd,epyc_7702,ib ActiveFeatures=rhel8,amd,epyc_7702,ib Gres=(null) NodeAddr=compute-a5-3 NodeHostName=compute-a5-3 Version=23.11.9 OS=Linux 4.18.0-553.5.1.el8_10.x86_64 #1 SMP Tue May 21 03:13:04 EDT 2024 RealMemory=512000 AllocMem=296960 FreeMem=326630 Sockets=2 Boards=1 State=MIXED ThreadsPerCore=1 TmpDisk=300000 Weight=1 Owner=N/A MCS_label=N/A Partitions=scavenger,standard BootTime=2024-08-08T18:32:48 SlurmdStartTime=2024-08-12T17:43:23 LastBusyTime=2024-08-12T17:43:19 ResumeAfterTime=None CfgTRES=cpu=128,mem=500G,billing=128 AllocTRES=cpu=71,mem=290G CapWatts=n/a CurrentWatts=630 AveWatts=294 ExtSensorsJoules=n/a ExtSensorsWatts=0 ExtSensorsTemp=n/a CPU Details: * Total CPUs: 128 * Allocated CPUs: 71 Memory: * Total Memory: 500 GB * Allocated Memory: 290 GB * Free Memory: ~319 GB","title":"Display node config information"},{"location":"basic_linux/#view-information-about-jobs-located-in-the-slurm-scheduling-queue","text":"%%bash squeue -u $USER JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 7563417 standard sys/dash xie186 R 48:15 1 compute-a5-5","title":"View information about jobs located in the Slurm scheduling queue."},{"location":"basic_linux/#cancel-a-job","text":"%%bash scancel <JOBID>","title":"Cancel a job"},{"location":"bioi611_monocle_cele/","text":"Why single cell trajectory analysis The development of cells in multicellular organisms is a tightly regulated process that unfolds through a series of lineage decisions and differentiation events. These processes result in a diverse array of specialized cell types, each with distinct functional roles. Understanding the dynamics of cell development is crucial for elucidating fundamental biological mechanisms, and single-cell RNA sequencing (scRNA-seq) has emerged as a powerful tool for studying these processes at an unprecedented resolution. Trajectory analysis, combined with pseudotime reconstruction, provides a framework for investigating the temporal and developmental progression of cells within a dataset. Using computational tools like Monocle3, researchers can infer cell trajectories based on the high-dimensional expression profiles of genes, identifying how undifferentiated cells transition through intermediate states toward terminal fates. Trajectory Reconstruction: Tools like Monocle3 organize single cells into trajectories by arranging them along a developmental axis, reflecting the continuum of cellular states. These trajectories are inferred without prior knowledge of time or lineage markers, making them especially powerful for systems where developmental pathways are not fully mapped. Pseudotime Analysis: Pseudotime represents an inferred temporal ordering of cells along a trajectory. It enables the identification of genes and pathways that are dynamically regulated as cells transition through developmental states. Developmental process of the cell types in C. elegans The developmental process of the cell types involves a progression through various stages, starting from neuroblasts (progenitor cells) and leading to differentiated neuron types, as described below: Neuroblasts (Progenitors): The process begins with neuroblasts, which are multipotent progenitor cells. Examples include: * Neuroblast_ADF_AWB: Precursor to the ADF and AWB neurons. * Neuroblast_AFD_RMD: Precursor to the AFD and RMD neurons. * Neuroblast_ASE_ASJ_AUA: Precursor to the ASE, ASJ, and AUA neurons. * Neuroblast_ASG_AWA: Precursor to the ASG and AWA neurons. Parent Cells: Some intermediate stages are represented by parent cell types, such as: * ADL_parent: Gives rise to ADL neurons. * ASI_parent: Gives rise to ASI neurons. * ASE_parent: Gives rise to ASEL and ASER neurons. * ASK_parent: Gives rise to ASK neurons. Differentiated Neurons: Fully differentiated neurons emerge from the parent cells and neuroblasts, including: ADF (Amphid Dorsal Left) ADL (Amphid Dorsal Left) AFD (Amphid Fan-shaped Dorsal) ASE (Amphid Sensory neurons), with subtypes ASEL (Left) and ASER (Right). ASG (Amphid Sensory neurons Group) ASH (Amphid Sensory neurons Hypodermal) ASI (Amphid Sensory neurons Inner) ASJ (Amphid Sensory neurons Junction) ASK (Amphid Sensory neurons King) AWA (Amphid Wing-shaped neurons A) AWB (Amphid Wing-shaped neurons B) AWC (Amphid Wing-shaped neurons C), with subtype AWC_ON. AUA (Amphid Unpaired A neuron) The neuroblasts differentiate into parent cell types or directly into specific neuron subtypes. Parent cells serve as intermediate stages, further dividing or maturing into various functional neuron types. This hierarchical process ensures the development of diverse neuronal subtypes specialized for distinct sensory and functional roles. R package installation Installation of the required packages may take more than 1.5 hours. Same as other lab notes, a .tar.gz file includes all the library files will be downloaded and uncompressed for preparing the R environment. #if (!requireNamespace(\"BiocManager\", quietly = TRUE)) #install.packages(\"BiocManager\") #BiocManager::install(version = \"3.20\") ## required by scater package system(\"apt-get install libx11-dev libcairo2-dev\") #, intern = TRUE) #BiocManager::install(c('BiocGenerics', 'DelayedArray', 'DelayedMatrixStats', # 'limma', 'lme4', 'S4Vectors', 'SingleCellExperiment', # 'SummarizedExperiment', 'batchelor', 'HDF5Array', # 'terra', 'ggrastr')) #install.packages(\"devtools\") #devtools::install_github('cole-trapnell-lab/monocle3') #system(\"tar zcvf R_lib_monocle3.tar.gz /usr/local/lib/R/site-library\") Configure the environment using existing library files # https://drive.google.com/file/d/1wCqb1oCfxeplWR7jf3vkPWDavVsGAQzZ/view?usp=sharing system(\"gdown 1wCqb1oCfxeplWR7jf3vkPWDavVsGAQzZ\") system(\"md5sum R_lib_monocle3.tar.gz\", intern = TRUE) '74998728fb9870f0e3e728c7c6449532 R_lib_monocle3.tar.gz' system(\"tar zxvf R_lib_monocle3.tar.gz\") .libPaths(c(\"/content/usr/local/lib/R/site-library\", .libPaths())) .libPaths() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '/content/usr/local/lib/R/site-library' '/usr/local/lib/R/site-library' '/usr/lib/R/site-library' '/usr/lib/R/library' Load required R packages library(monocle3) library(dplyr) Loading required package: Biobase Loading required package: BiocGenerics Attaching package: \u2018BiocGenerics\u2019 The following objects are masked from \u2018package:stats\u2019: IQR, mad, sd, var, xtabs The following objects are masked from \u2018package:base\u2019: anyDuplicated, aperm, append, as.data.frame, basename, cbind, colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rownames, sapply, saveRDS, setdiff, table, tapply, union, unique, unsplit, which.max, which.min Welcome to Bioconductor Vignettes contain introductory material; view with 'browseVignettes()'. To cite Bioconductor, see 'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'. Loading required package: SingleCellExperiment Loading required package: SummarizedExperiment Loading required package: MatrixGenerics Loading required package: matrixStats Attaching package: \u2018matrixStats\u2019 The following objects are masked from \u2018package:Biobase\u2019: anyMissing, rowMedians Attaching package: \u2018MatrixGenerics\u2019 The following objects are masked from \u2018package:matrixStats\u2019: colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse, colCounts, colCummaxs, colCummins, colCumprods, colCumsums, colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs, colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats, colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds, colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads, colWeightedMeans, colWeightedMedians, colWeightedSds, colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet, rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods, rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps, rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins, rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks, rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars, rowWeightedMads, rowWeightedMeans, rowWeightedMedians, rowWeightedSds, rowWeightedVars The following object is masked from \u2018package:Biobase\u2019: rowMedians Loading required package: GenomicRanges Loading required package: stats4 Loading required package: S4Vectors Attaching package: \u2018S4Vectors\u2019 The following object is masked from \u2018package:utils\u2019: findMatches The following objects are masked from \u2018package:base\u2019: expand.grid, I, unname Loading required package: IRanges Loading required package: GenomeInfoDb Attaching package: \u2018monocle3\u2019 The following objects are masked from \u2018package:Biobase\u2019: exprs, fData, fData<-, pData, pData<- Attaching package: \u2018dplyr\u2019 The following objects are masked from \u2018package:GenomicRanges\u2019: intersect, setdiff, union The following object is masked from \u2018package:GenomeInfoDb\u2019: intersect The following objects are masked from \u2018package:IRanges\u2019: collapse, desc, intersect, setdiff, slice, union The following objects are masked from \u2018package:S4Vectors\u2019: first, intersect, rename, setdiff, setequal, union The following object is masked from \u2018package:matrixStats\u2019: count The following object is masked from \u2018package:Biobase\u2019: combine The following objects are masked from \u2018package:BiocGenerics\u2019: combine, intersect, setdiff, union The following objects are masked from \u2018package:stats\u2019: filter, lag The following objects are masked from \u2018package:base\u2019: intersect, setdiff, setequal, union When we were working on the scRNA-seq data in C. elegans, we didn't perform cell type annotation because of limited time. expression_matrix <- readRDS(url(\"https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_expression.rds\")) cell_metadata <- readRDS(url(\"https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_colData.rds\")) gene_annotation <- readRDS(url(\"https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_rowData.rds\")) cds <- new_cell_data_set(expression_matrix, cell_metadata = cell_metadata, gene_metadata = gene_annotation) cds class: cell_data_set dim: 20222 6188 metadata(1): cds_version assays(1): counts rownames(20222): WBGene00010957 WBGene00010958 ... WBGene00021594 WBGene00007064 rowData names(3): id gene_short_name num_cells_expressed colnames(6188): AAACCTGCAAGACGTG-300.1.1 AAACCTGGTGTGAATA-300.1.1 ... TGCGGGTAGTACTTGC-b02 TTTGTCAAGTACACCT-b02 colData names(19): cell n.umi ... bg.b01.loading bg.b02.loading reducedDimNames(0): mainExpName: NULL altExpNames(0): class(expression_matrix) dim(expression_matrix) 'dgCMatrix' .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 20222 6188 head(cell_metadata, 4) A data.frame: 4 \u00d7 19 cell n.umi time.point batch Size_Factor raw.embryo.time embryo.time embryo.time.bin raw.embryo.time.bin lineage num_genes_expressed cell.type bg.300.loading bg.400.loading bg.500.1.loading bg.500.2.loading bg.r17.loading bg.b01.loading bg.b02.loading <chr> <dbl> <fct> <fct> <dbl> <int> <dbl> <fct> <fct> <chr> <int> <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> AAACCTGCAAGACGTG-300.1.1 AAACCTGCAAGACGTG-300.1.1 1003 300_minutes Waterston_300_minutes 0.7795692 350 350 330-390 330-390 ABalpppapav/ABpraaaapav 646 AFD 0.808794 0.2324676 -2.000489 -2.425965 -0.5436492 -2.2848042 -2.1302609 AAACCTGGTGTGAATA-300.1.1 AAACCTGGTGTGAATA-300.1.1 1458 300_minutes Waterston_300_minutes 1.1332123 190 190 170-210 170-210 ABalppppa/ABpraaapa 857 NA 9.220938 3.9429037 -3.420859 -3.479376 4.8987977 1.6406862 0.1534805 AAACCTGTCGGCCGAT-300.1.1 AAACCTGTCGGCCGAT-300.1.1 1633 300_minutes Waterston_300_minutes 1.2692289 260 245 210-270 210-270 ABpxpaaaaa 865 NA 6.008029 2.2257000 -3.630310 -3.828569 1.9894965 -0.1370570 -0.5189810 AAAGATGGTTCGTTGA-300.1.1 AAAGATGGTTCGTTGA-300.1.1 1716 300_minutes Waterston_300_minutes 1.3337396 220 225 210-270 210-270 NA 873 NA 7.518360 3.0385123 -3.932011 -4.290579 1.9108642 -0.9612141 -2.2660029 If you work on your own dataset, the meta data information will be created/collected by yourself. In this notebook, the metadata has been created/collected by the authors. In Seurat object, metadata information is stored in @metadata dataframe. Column cell.type : Cell type annotation performed by the authors in the Science paper Column embryo.time.bin : For each cell, the age of the embryo that it came from was estimated by correlating its transcriptome with a bulk RNA-seq time series. The bulk RNA-seq time series are from the paper here . table(cell_metadata$cell.type) ADF ADF_AWB ADL 170 102 477 ADL_parent AFD ASE 148 326 205 ASE_parent ASEL ASER 149 38 39 ASG ASG_AWA ASH 173 99 345 ASI ASI_parent ASJ 212 187 320 ASK ASK_parent AUA 233 150 98 AWA AWB AWC 236 212 309 AWC_ON Neuroblast_ADF_AWB Neuroblast_AFD_RMD 9 131 147 Neuroblast_ASE_ASJ_AUA Neuroblast_ASG_AWA Neuroblast_ASJ_AUA 103 142 123 head(gene_annotation) A data.frame: 6 \u00d7 3 id gene_short_name num_cells_expressed <chr> <chr> <int> WBGene00010957 WBGene00010957 nduo-6 6038 WBGene00010958 WBGene00010958 ndfl-4 1597 WBGene00010959 WBGene00010959 nduo-1 5342 WBGene00010960 WBGene00010960 atp-6 5921 WBGene00010961 WBGene00010961 nduo-2 2686 WBGene00000829 WBGene00000829 ctb-1 5079 Pre-process the data Most analyses (including trajectory inference, and clustering) in Monocle3, require various normalization and preprocessing steps. preprocess_cds executes and stores these preprocessing steps. Specifically, depending on the options selected, preprocess_cds first normalizes the data by log and size factor to address depth differences, or by size factor only. Next, preprocess_cds calculates a lower dimensional space that will be used as the input for further dimensionality reduction like tSNE and UMAP. In monocle3, cds is short for cell_data_set (CDS) object. cds <- preprocess_cds(cds, num_dim = 50) Data sets that contain cells from different groups often benefit from alignment to subtract differences between them. Alignment can be used to remove batch effects, subtract the effects of treatments, or even potentially compare across species. align_cds executes alignment and stores these adjusted coordinates. This function can be used to subtract both continuous and discrete batch effects. \u26a0\ufe0f Important Your own dataset might not include the batch-loading information demonstrated here. You will need to address batch effects using the batch information specific to your data. For instance, if your data were collected at different locations, the location data could be used as a factor to correct for batch effects. cds <- align_cds(cds, alignment_group = \"batch\", residual_model_formula_str = \"~ bg.300.loading + bg.400.loading + bg.500.1.loading + bg.500.2.loading + bg.r17.loading + bg.b01.loading + bg.b02.loading\") Aligning cells from different batches using Batchelor. Please remember to cite: Haghverdi L, Lun ATL, Morgan MD, Marioni JC (2018). 'Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors.' Nat. Biotechnol., 36(5), 421-427. doi: 10.1038/nbt.4091 Reduce dimensionality and visualize the results cds <- reduce_dimension(cds) No preprocess_method specified, and aligned coordinates have been computed previously. Using preprocess_method = 'Aligned' plot_cells(cds, label_groups_by_cluster=FALSE, color_cells_by = \"cell.type\") No trajectory to plot. Has learn_graph() been called yet? Warning message: \u201c\u001b[1m\u001b[22mRemoved 1 row containing missing values or values outside the scale range (`geom_text_repel()`).\u201d You can use plot_cells() to visualize the variation of individual genes along the trajectory. Let's examine a few genes that exhibit intriguing expression patterns in ciliated neurons: ciliated_genes <- c(\"che-1\", \"hlh-17\", \"nhr-6\", \"dmd-6\", \"ceh-36\", \"ham-1\") plot_cells(cds, genes=ciliated_genes, label_cell_groups=FALSE, show_trajectory_graph=FALSE) The C. elegans che-1 gene encodes a zinc finger transcription factor required for specification of the ASE chemosensory neurons. Cluster your cells This function takes a cell_data_set as input, clusters the cells using Louvain or Leiden community detection, and returns a cell_data_set with internally stored cluster assignments. In addition to clustering, the function calculates partitions, representing superclusters of the Louvain or Leiden communities, identified through a kNN pruning method. Cluster assignments can be accessed via the clusters function, and partition assignments can be accessed via the partitions function. cds <- cluster_cells(cds) plot_cells(cds, color_cells_by = \"partition\") No trajectory to plot. Has learn_graph() been called yet? Learn the trajectory graph Monocle3 aims to learn how cells transition through a biological program of gene expression changes in an experiment. Each cell can be viewed as a point in a high-dimensional space, where each dimension describes the expression of a different gene. Identifying the program of gene expression changes is equivalent to learning a trajectory that the cells follow through this space. However, the more dimensions there are in the analysis, the harder the trajectory is to learn. Fortunately, many genes typically co-vary with one another, and so the dimensionality of the data can be reduced with a wide variety of different algorithms. Monocle3 provides two different algorithms for dimensionality reduction via reduce_dimension (UMAP and tSNE). Both take a cell_data_set object and a number of dimensions allowed for the reduced space. You can also provide a model formula indicating some variables (e.g. batch ID or other technical factors) to \"subtract\" from the data so it doesn't contribute to the trajectory. The function learn_graph is the fourth step in the trajectory building process after preprocess_cds, reduce_dimension, and cluster_cells. After learn_graph, order_cells is typically called. Principal graph Monocle uses reverse graph embedding (RGE) to map the cells to a lower-dimensional latent space, i.e. each cell \\(\\boldsymbol{x}_i, i=1, \\ldots, N\\) has a corresponding latent point \\(\\boldsymbol{z}_i\\) . These latent points are clustered in a way similar to k-means by iteratively fitting of a small set of centroids, \\(\\boldsymbol{y}_k, k=1, \\ldots, K(K \\leq N)\\) . The principal graph is then built on these centroids. Finally the latent points are mapped on the nearest point on this qraph to obtain their pseudotimes cds <- learn_graph(cds) plot_cells(cds, color_cells_by = \"cell.type\", label_groups_by_cluster=FALSE, label_leaves=FALSE, label_branch_points=FALSE) |======================================================================| 100% |======================================================================| 100% Warning message: \u201c\u001b[1m\u001b[22mRemoved 1 row containing missing values or values outside the scale range (`geom_text_repel()`).\u201d plot_cells(cds, color_cells_by = \"embryo.time.bin\", label_cell_groups=FALSE, label_leaves=TRUE, label_branch_points=TRUE, graph_label_size=1.5) principal_graph(cds) List of length 1 names(1): UMAP p_graph <- principal_graph(cds)[[\"UMAP\"]] igraph::V(p_graph) # V(): graph -> vertices + 343/343 vertices, named, from 446a6a2: [1] Y_1 Y_2 Y_3 Y_4 Y_5 Y_6 Y_7 Y_8 Y_9 Y_10 Y_11 Y_12 [13] Y_13 Y_14 Y_15 Y_16 Y_17 Y_18 Y_19 Y_20 Y_21 Y_22 Y_23 Y_24 [25] Y_25 Y_26 Y_27 Y_28 Y_29 Y_30 Y_31 Y_32 Y_33 Y_34 Y_35 Y_36 [37] Y_37 Y_38 Y_39 Y_40 Y_41 Y_42 Y_43 Y_44 Y_45 Y_46 Y_47 Y_48 [49] Y_49 Y_50 Y_51 Y_52 Y_53 Y_54 Y_55 Y_56 Y_57 Y_58 Y_59 Y_60 [61] Y_61 Y_62 Y_63 Y_64 Y_65 Y_66 Y_67 Y_68 Y_69 Y_70 Y_71 Y_72 [73] Y_73 Y_74 Y_75 Y_76 Y_77 Y_78 Y_79 Y_80 Y_81 Y_82 Y_83 Y_84 [85] Y_85 Y_86 Y_87 Y_88 Y_89 Y_90 Y_91 Y_92 Y_93 Y_94 Y_95 Y_96 [97] Y_97 Y_98 Y_99 Y_100 Y_101 Y_102 Y_103 Y_104 Y_105 Y_106 Y_107 Y_108 [109] Y_109 Y_110 Y_111 Y_112 Y_113 Y_114 Y_115 Y_116 Y_117 Y_118 Y_119 Y_120 + ... omitted several vertices plot_cells(cds, color_cells_by = \"embryo.time.bin\", label_cell_groups=FALSE, label_leaves=TRUE, label_branch_points=TRUE, graph_label_size=1.5) plot_cells(cds, color_cells_by = \"embryo.time.bin\", label_cell_groups=FALSE, label_groups_by_cluster=FALSE, label_leaves=FALSE, label_branch_points=TRUE, label_principal_points = TRUE, # set this to TRUE graph_label_size=3) Order cells Assigns cells a pseudotime value based on their projection on the principal graph learned in the learn_graph function and the position of chosen root states. This function takes as input a cell_data_set and returns it with pseudotime information stored internally. order_cells() optionally takes \"root\" state(s) in the form of cell or principal graph node IDs, which you can use to specify the start of the trajectory. If you don't provide a root state, an plot will be generated where you can choose the root state(s) interactively. # a helper function to identify the root principal points: get_earliest_principal_node <- function(cds, time_bin=\"130-170\"){ cell_ids <- which(colData(cds)[, \"embryo.time.bin\"] == time_bin) # vertex is also called node in a graph closest_vertex <- cds@principal_graph_aux[[\"UMAP\"]]$pr_graph_cell_proj_closest_vertex closest_vertex <- as.matrix(closest_vertex[colnames(cds), ]) root_pr_nodes <- igraph::V(principal_graph(cds)[[\"UMAP\"]])$name[as.numeric(names (which.max(table(closest_vertex[cell_ids,]))))] root_pr_nodes } The function above, get_earliest_principal_node , helps find the \"starting point\" in a path that cells follow as they change or develop, based on some time-related information. get_earliest_principal_node(cds) 'Y_62' cds <- order_cells(cds, root_pr_nodes = get_earliest_principal_node(cds)) plot_cells(cds, color_cells_by = \"pseudotime\", label_cell_groups=FALSE, label_leaves=FALSE, label_branch_points=FALSE, graph_label_size=1.5) Finding genes that change as a function of pseudotime Identifying the genes that change as cells progress along a trajectory is a core objective of this type of analysis. Knowing the order in which genes go on and off can inform new models of development. Let's return to the embryo data, which we processed using the commands You can use graph_test() to find genes that are differentially expressed on the different path through the trajectory. The parameter, neighbor_graph=\"principal_graph\", tells graph_test() to test whether cells at similar positions on the trajectory have correlated expression: ciliated_cds_pr_test_res <- graph_test(cds, neighbor_graph=\"principal_graph\", cores=4) pr_deg_ids <- row.names(subset(ciliated_cds_pr_test_res, q_value < 0.05)) |===========================================================================| 100%, Elapsed 10:03 pr_deg_ids[1:10] .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'WBGene00010957' 'WBGene00010958' 'WBGene00010959' 'WBGene00010960' 'WBGene00010961' 'WBGene00000829' 'WBGene00010962' 'WBGene00010963' 'WBGene00010964' 'WBGene00010965' Here are a couple of interesting genes that score as highly significant according to graph_test() : plot_cells(cds, genes=c(\"hlh-4\", \"gcy-8\", \"dac-1\", \"oig-8\"), show_trajectory_graph=FALSE, label_cell_groups=FALSE, label_leaves=FALSE) We can then collect the trajectory-variable genes into modules: gene_module_df <- find_gene_modules(cds[pr_deg_ids,], resolution=c(10^seq(-6,-1))) dim(gene_module_df) head(gene_module_df) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 8065 5 A tibble: 6 \u00d7 5 id module supermodule dim_1 dim_2 <chr> <fct> <fct> <dbl> <dbl> WBGene00010957 7 1 -4.377187 -1.642148 WBGene00010958 7 1 -4.623665 -1.831054 WBGene00010959 7 1 -4.359261 -1.622316 WBGene00010960 7 1 -4.383083 -1.655990 WBGene00010961 7 1 -4.393384 -1.639716 WBGene00000829 7 1 -4.366506 -1.660363 cell_group_df <- tibble::tibble(cell=row.names(colData(cds)), cell_group=colData(cds)$cell.type) agg_mat <- aggregate_gene_expression(cds, gene_module_df, cell_group_df) row.names(agg_mat) <- stringr::str_c(\"Module \", row.names(agg_mat)) pheatmap::pheatmap(agg_mat, scale=\"column\", clustering_method=\"ward.D2\") gene_module_df <- find_gene_modules(cds[pr_deg_ids,], resolution=c(10^seq(-6,-1))) You can also use plot_cells() on gene_module_df : plot_cells(cds, genes=gene_module_df %>% dplyr::filter(module %in% c(27, 10, 7, 30)), label_cell_groups=FALSE, show_trajectory_graph=FALSE) Monocle offers another plotting function that can sometimes give a clearer view of a gene's dynamics along a single path. You can select a path with choose_cells() or by subsetting the cell data set by cluster, cell type, or other annotation that's restricted to the path. Let's pick one such path, the AFD cells: # Error: `choose_cells` only works in interactive mode. # Not working in Jupyter notebook or colab # May try this function in R studio or # use new kernel `xeus-r` # choose_cells(cds) AFD_genes <- c(\"gcy-8\", \"dac-1\", \"oig-8\") AFD_lineage_cds <- cds[rowData(cds)$gene_short_name %in% AFD_genes, colData(cds)$cell.type %in% c(\"AFD\")] AFD_lineage_cds class: cell_data_set dim: 3 326 metadata(2): cds_version citations assays(1): counts rownames(3): WBGene00001535 WBGene00000895 WBGene00020582 rowData names(3): id gene_short_name num_cells_expressed colnames(326): AAACCTGCAAGACGTG-300.1.1 ACCAGTATCGTAGGTT-300.1.1 ... GCTGCGATCTTCTGGC-b02 GGGCACTAGCCTTGAT-b02 colData names(19): cell n.umi ... bg.b01.loading bg.b02.loading reducedDimNames(3): PCA Aligned UMAP mainExpName: NULL altExpNames(0): The function plot_genes_in_pseudotime() takes a small set of genes and shows you their dynamics as a function of pseudotime: plot_genes_in_pseudotime(AFD_lineage_cds, min_expr=0.5) As you can see, gene dac-1 is activated before the other two genes. Reference https://colab.research.google.com/drive/10fqFG9UVbazqeaZwbzpSAJ3I79tSoSYG#scrollTo=1onUusVNBvAr&line=1&uniqifier=1 https://cole-trapnell-lab.github.io/monocle3/docs/differential/#pseudo-dep https://github.com/cole-trapnell-lab/monocle3/issues/179#issuecomment-2145687700","title":"Downstream analysis - trajectory analysis using Monocle3"},{"location":"bioi611_monocle_cele/#_1","text":"","title":""},{"location":"bioi611_monocle_cele/#why-single-cell-trajectory-analysis","text":"The development of cells in multicellular organisms is a tightly regulated process that unfolds through a series of lineage decisions and differentiation events. These processes result in a diverse array of specialized cell types, each with distinct functional roles. Understanding the dynamics of cell development is crucial for elucidating fundamental biological mechanisms, and single-cell RNA sequencing (scRNA-seq) has emerged as a powerful tool for studying these processes at an unprecedented resolution. Trajectory analysis, combined with pseudotime reconstruction, provides a framework for investigating the temporal and developmental progression of cells within a dataset. Using computational tools like Monocle3, researchers can infer cell trajectories based on the high-dimensional expression profiles of genes, identifying how undifferentiated cells transition through intermediate states toward terminal fates. Trajectory Reconstruction: Tools like Monocle3 organize single cells into trajectories by arranging them along a developmental axis, reflecting the continuum of cellular states. These trajectories are inferred without prior knowledge of time or lineage markers, making them especially powerful for systems where developmental pathways are not fully mapped. Pseudotime Analysis: Pseudotime represents an inferred temporal ordering of cells along a trajectory. It enables the identification of genes and pathways that are dynamically regulated as cells transition through developmental states.","title":"Why single cell trajectory analysis"},{"location":"bioi611_monocle_cele/#developmental-process-of-the-cell-types-in-c-elegans","text":"The developmental process of the cell types involves a progression through various stages, starting from neuroblasts (progenitor cells) and leading to differentiated neuron types, as described below: Neuroblasts (Progenitors): The process begins with neuroblasts, which are multipotent progenitor cells. Examples include: * Neuroblast_ADF_AWB: Precursor to the ADF and AWB neurons. * Neuroblast_AFD_RMD: Precursor to the AFD and RMD neurons. * Neuroblast_ASE_ASJ_AUA: Precursor to the ASE, ASJ, and AUA neurons. * Neuroblast_ASG_AWA: Precursor to the ASG and AWA neurons. Parent Cells: Some intermediate stages are represented by parent cell types, such as: * ADL_parent: Gives rise to ADL neurons. * ASI_parent: Gives rise to ASI neurons. * ASE_parent: Gives rise to ASEL and ASER neurons. * ASK_parent: Gives rise to ASK neurons. Differentiated Neurons: Fully differentiated neurons emerge from the parent cells and neuroblasts, including: ADF (Amphid Dorsal Left) ADL (Amphid Dorsal Left) AFD (Amphid Fan-shaped Dorsal) ASE (Amphid Sensory neurons), with subtypes ASEL (Left) and ASER (Right). ASG (Amphid Sensory neurons Group) ASH (Amphid Sensory neurons Hypodermal) ASI (Amphid Sensory neurons Inner) ASJ (Amphid Sensory neurons Junction) ASK (Amphid Sensory neurons King) AWA (Amphid Wing-shaped neurons A) AWB (Amphid Wing-shaped neurons B) AWC (Amphid Wing-shaped neurons C), with subtype AWC_ON. AUA (Amphid Unpaired A neuron) The neuroblasts differentiate into parent cell types or directly into specific neuron subtypes. Parent cells serve as intermediate stages, further dividing or maturing into various functional neuron types. This hierarchical process ensures the development of diverse neuronal subtypes specialized for distinct sensory and functional roles.","title":"Developmental process of the cell types in C. elegans"},{"location":"bioi611_monocle_cele/#r-package-installation","text":"Installation of the required packages may take more than 1.5 hours. Same as other lab notes, a .tar.gz file includes all the library files will be downloaded and uncompressed for preparing the R environment. #if (!requireNamespace(\"BiocManager\", quietly = TRUE)) #install.packages(\"BiocManager\") #BiocManager::install(version = \"3.20\") ## required by scater package system(\"apt-get install libx11-dev libcairo2-dev\") #, intern = TRUE) #BiocManager::install(c('BiocGenerics', 'DelayedArray', 'DelayedMatrixStats', # 'limma', 'lme4', 'S4Vectors', 'SingleCellExperiment', # 'SummarizedExperiment', 'batchelor', 'HDF5Array', # 'terra', 'ggrastr')) #install.packages(\"devtools\") #devtools::install_github('cole-trapnell-lab/monocle3') #system(\"tar zcvf R_lib_monocle3.tar.gz /usr/local/lib/R/site-library\")","title":"R package installation"},{"location":"bioi611_monocle_cele/#configure-the-environment-using-existing-library-files","text":"# https://drive.google.com/file/d/1wCqb1oCfxeplWR7jf3vkPWDavVsGAQzZ/view?usp=sharing system(\"gdown 1wCqb1oCfxeplWR7jf3vkPWDavVsGAQzZ\") system(\"md5sum R_lib_monocle3.tar.gz\", intern = TRUE) '74998728fb9870f0e3e728c7c6449532 R_lib_monocle3.tar.gz' system(\"tar zxvf R_lib_monocle3.tar.gz\") .libPaths(c(\"/content/usr/local/lib/R/site-library\", .libPaths())) .libPaths() .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} '/content/usr/local/lib/R/site-library' '/usr/local/lib/R/site-library' '/usr/lib/R/site-library' '/usr/lib/R/library'","title":"Configure the environment using existing library files"},{"location":"bioi611_monocle_cele/#load-required-r-packages","text":"library(monocle3) library(dplyr) Loading required package: Biobase Loading required package: BiocGenerics Attaching package: \u2018BiocGenerics\u2019 The following objects are masked from \u2018package:stats\u2019: IQR, mad, sd, var, xtabs The following objects are masked from \u2018package:base\u2019: anyDuplicated, aperm, append, as.data.frame, basename, cbind, colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rownames, sapply, saveRDS, setdiff, table, tapply, union, unique, unsplit, which.max, which.min Welcome to Bioconductor Vignettes contain introductory material; view with 'browseVignettes()'. To cite Bioconductor, see 'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'. Loading required package: SingleCellExperiment Loading required package: SummarizedExperiment Loading required package: MatrixGenerics Loading required package: matrixStats Attaching package: \u2018matrixStats\u2019 The following objects are masked from \u2018package:Biobase\u2019: anyMissing, rowMedians Attaching package: \u2018MatrixGenerics\u2019 The following objects are masked from \u2018package:matrixStats\u2019: colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse, colCounts, colCummaxs, colCummins, colCumprods, colCumsums, colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs, colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats, colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds, colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads, colWeightedMeans, colWeightedMedians, colWeightedSds, colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet, rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods, rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps, rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins, rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks, rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars, rowWeightedMads, rowWeightedMeans, rowWeightedMedians, rowWeightedSds, rowWeightedVars The following object is masked from \u2018package:Biobase\u2019: rowMedians Loading required package: GenomicRanges Loading required package: stats4 Loading required package: S4Vectors Attaching package: \u2018S4Vectors\u2019 The following object is masked from \u2018package:utils\u2019: findMatches The following objects are masked from \u2018package:base\u2019: expand.grid, I, unname Loading required package: IRanges Loading required package: GenomeInfoDb Attaching package: \u2018monocle3\u2019 The following objects are masked from \u2018package:Biobase\u2019: exprs, fData, fData<-, pData, pData<- Attaching package: \u2018dplyr\u2019 The following objects are masked from \u2018package:GenomicRanges\u2019: intersect, setdiff, union The following object is masked from \u2018package:GenomeInfoDb\u2019: intersect The following objects are masked from \u2018package:IRanges\u2019: collapse, desc, intersect, setdiff, slice, union The following objects are masked from \u2018package:S4Vectors\u2019: first, intersect, rename, setdiff, setequal, union The following object is masked from \u2018package:matrixStats\u2019: count The following object is masked from \u2018package:Biobase\u2019: combine The following objects are masked from \u2018package:BiocGenerics\u2019: combine, intersect, setdiff, union The following objects are masked from \u2018package:stats\u2019: filter, lag The following objects are masked from \u2018package:base\u2019: intersect, setdiff, setequal, union When we were working on the scRNA-seq data in C. elegans, we didn't perform cell type annotation because of limited time. expression_matrix <- readRDS(url(\"https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_expression.rds\")) cell_metadata <- readRDS(url(\"https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_colData.rds\")) gene_annotation <- readRDS(url(\"https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_rowData.rds\")) cds <- new_cell_data_set(expression_matrix, cell_metadata = cell_metadata, gene_metadata = gene_annotation) cds class: cell_data_set dim: 20222 6188 metadata(1): cds_version assays(1): counts rownames(20222): WBGene00010957 WBGene00010958 ... WBGene00021594 WBGene00007064 rowData names(3): id gene_short_name num_cells_expressed colnames(6188): AAACCTGCAAGACGTG-300.1.1 AAACCTGGTGTGAATA-300.1.1 ... TGCGGGTAGTACTTGC-b02 TTTGTCAAGTACACCT-b02 colData names(19): cell n.umi ... bg.b01.loading bg.b02.loading reducedDimNames(0): mainExpName: NULL altExpNames(0): class(expression_matrix) dim(expression_matrix) 'dgCMatrix' .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 20222 6188 head(cell_metadata, 4) A data.frame: 4 \u00d7 19 cell n.umi time.point batch Size_Factor raw.embryo.time embryo.time embryo.time.bin raw.embryo.time.bin lineage num_genes_expressed cell.type bg.300.loading bg.400.loading bg.500.1.loading bg.500.2.loading bg.r17.loading bg.b01.loading bg.b02.loading <chr> <dbl> <fct> <fct> <dbl> <int> <dbl> <fct> <fct> <chr> <int> <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> AAACCTGCAAGACGTG-300.1.1 AAACCTGCAAGACGTG-300.1.1 1003 300_minutes Waterston_300_minutes 0.7795692 350 350 330-390 330-390 ABalpppapav/ABpraaaapav 646 AFD 0.808794 0.2324676 -2.000489 -2.425965 -0.5436492 -2.2848042 -2.1302609 AAACCTGGTGTGAATA-300.1.1 AAACCTGGTGTGAATA-300.1.1 1458 300_minutes Waterston_300_minutes 1.1332123 190 190 170-210 170-210 ABalppppa/ABpraaapa 857 NA 9.220938 3.9429037 -3.420859 -3.479376 4.8987977 1.6406862 0.1534805 AAACCTGTCGGCCGAT-300.1.1 AAACCTGTCGGCCGAT-300.1.1 1633 300_minutes Waterston_300_minutes 1.2692289 260 245 210-270 210-270 ABpxpaaaaa 865 NA 6.008029 2.2257000 -3.630310 -3.828569 1.9894965 -0.1370570 -0.5189810 AAAGATGGTTCGTTGA-300.1.1 AAAGATGGTTCGTTGA-300.1.1 1716 300_minutes Waterston_300_minutes 1.3337396 220 225 210-270 210-270 NA 873 NA 7.518360 3.0385123 -3.932011 -4.290579 1.9108642 -0.9612141 -2.2660029 If you work on your own dataset, the meta data information will be created/collected by yourself. In this notebook, the metadata has been created/collected by the authors. In Seurat object, metadata information is stored in @metadata dataframe. Column cell.type : Cell type annotation performed by the authors in the Science paper Column embryo.time.bin : For each cell, the age of the embryo that it came from was estimated by correlating its transcriptome with a bulk RNA-seq time series. The bulk RNA-seq time series are from the paper here . table(cell_metadata$cell.type) ADF ADF_AWB ADL 170 102 477 ADL_parent AFD ASE 148 326 205 ASE_parent ASEL ASER 149 38 39 ASG ASG_AWA ASH 173 99 345 ASI ASI_parent ASJ 212 187 320 ASK ASK_parent AUA 233 150 98 AWA AWB AWC 236 212 309 AWC_ON Neuroblast_ADF_AWB Neuroblast_AFD_RMD 9 131 147 Neuroblast_ASE_ASJ_AUA Neuroblast_ASG_AWA Neuroblast_ASJ_AUA 103 142 123 head(gene_annotation) A data.frame: 6 \u00d7 3 id gene_short_name num_cells_expressed <chr> <chr> <int> WBGene00010957 WBGene00010957 nduo-6 6038 WBGene00010958 WBGene00010958 ndfl-4 1597 WBGene00010959 WBGene00010959 nduo-1 5342 WBGene00010960 WBGene00010960 atp-6 5921 WBGene00010961 WBGene00010961 nduo-2 2686 WBGene00000829 WBGene00000829 ctb-1 5079","title":"Load required R packages"},{"location":"bioi611_monocle_cele/#pre-process-the-data","text":"Most analyses (including trajectory inference, and clustering) in Monocle3, require various normalization and preprocessing steps. preprocess_cds executes and stores these preprocessing steps. Specifically, depending on the options selected, preprocess_cds first normalizes the data by log and size factor to address depth differences, or by size factor only. Next, preprocess_cds calculates a lower dimensional space that will be used as the input for further dimensionality reduction like tSNE and UMAP. In monocle3, cds is short for cell_data_set (CDS) object. cds <- preprocess_cds(cds, num_dim = 50) Data sets that contain cells from different groups often benefit from alignment to subtract differences between them. Alignment can be used to remove batch effects, subtract the effects of treatments, or even potentially compare across species. align_cds executes alignment and stores these adjusted coordinates. This function can be used to subtract both continuous and discrete batch effects. \u26a0\ufe0f Important Your own dataset might not include the batch-loading information demonstrated here. You will need to address batch effects using the batch information specific to your data. For instance, if your data were collected at different locations, the location data could be used as a factor to correct for batch effects. cds <- align_cds(cds, alignment_group = \"batch\", residual_model_formula_str = \"~ bg.300.loading + bg.400.loading + bg.500.1.loading + bg.500.2.loading + bg.r17.loading + bg.b01.loading + bg.b02.loading\") Aligning cells from different batches using Batchelor. Please remember to cite: Haghverdi L, Lun ATL, Morgan MD, Marioni JC (2018). 'Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors.' Nat. Biotechnol., 36(5), 421-427. doi: 10.1038/nbt.4091","title":"Pre-process the data"},{"location":"bioi611_monocle_cele/#reduce-dimensionality-and-visualize-the-results","text":"cds <- reduce_dimension(cds) No preprocess_method specified, and aligned coordinates have been computed previously. Using preprocess_method = 'Aligned' plot_cells(cds, label_groups_by_cluster=FALSE, color_cells_by = \"cell.type\") No trajectory to plot. Has learn_graph() been called yet? Warning message: \u201c\u001b[1m\u001b[22mRemoved 1 row containing missing values or values outside the scale range (`geom_text_repel()`).\u201d You can use plot_cells() to visualize the variation of individual genes along the trajectory. Let's examine a few genes that exhibit intriguing expression patterns in ciliated neurons: ciliated_genes <- c(\"che-1\", \"hlh-17\", \"nhr-6\", \"dmd-6\", \"ceh-36\", \"ham-1\") plot_cells(cds, genes=ciliated_genes, label_cell_groups=FALSE, show_trajectory_graph=FALSE) The C. elegans che-1 gene encodes a zinc finger transcription factor required for specification of the ASE chemosensory neurons.","title":"Reduce dimensionality and visualize the results"},{"location":"bioi611_monocle_cele/#cluster-your-cells","text":"This function takes a cell_data_set as input, clusters the cells using Louvain or Leiden community detection, and returns a cell_data_set with internally stored cluster assignments. In addition to clustering, the function calculates partitions, representing superclusters of the Louvain or Leiden communities, identified through a kNN pruning method. Cluster assignments can be accessed via the clusters function, and partition assignments can be accessed via the partitions function. cds <- cluster_cells(cds) plot_cells(cds, color_cells_by = \"partition\") No trajectory to plot. Has learn_graph() been called yet?","title":"Cluster your cells"},{"location":"bioi611_monocle_cele/#learn-the-trajectory-graph","text":"Monocle3 aims to learn how cells transition through a biological program of gene expression changes in an experiment. Each cell can be viewed as a point in a high-dimensional space, where each dimension describes the expression of a different gene. Identifying the program of gene expression changes is equivalent to learning a trajectory that the cells follow through this space. However, the more dimensions there are in the analysis, the harder the trajectory is to learn. Fortunately, many genes typically co-vary with one another, and so the dimensionality of the data can be reduced with a wide variety of different algorithms. Monocle3 provides two different algorithms for dimensionality reduction via reduce_dimension (UMAP and tSNE). Both take a cell_data_set object and a number of dimensions allowed for the reduced space. You can also provide a model formula indicating some variables (e.g. batch ID or other technical factors) to \"subtract\" from the data so it doesn't contribute to the trajectory. The function learn_graph is the fourth step in the trajectory building process after preprocess_cds, reduce_dimension, and cluster_cells. After learn_graph, order_cells is typically called. Principal graph Monocle uses reverse graph embedding (RGE) to map the cells to a lower-dimensional latent space, i.e. each cell \\(\\boldsymbol{x}_i, i=1, \\ldots, N\\) has a corresponding latent point \\(\\boldsymbol{z}_i\\) . These latent points are clustered in a way similar to k-means by iteratively fitting of a small set of centroids, \\(\\boldsymbol{y}_k, k=1, \\ldots, K(K \\leq N)\\) . The principal graph is then built on these centroids. Finally the latent points are mapped on the nearest point on this qraph to obtain their pseudotimes cds <- learn_graph(cds) plot_cells(cds, color_cells_by = \"cell.type\", label_groups_by_cluster=FALSE, label_leaves=FALSE, label_branch_points=FALSE) |======================================================================| 100% |======================================================================| 100% Warning message: \u201c\u001b[1m\u001b[22mRemoved 1 row containing missing values or values outside the scale range (`geom_text_repel()`).\u201d plot_cells(cds, color_cells_by = \"embryo.time.bin\", label_cell_groups=FALSE, label_leaves=TRUE, label_branch_points=TRUE, graph_label_size=1.5) principal_graph(cds) List of length 1 names(1): UMAP p_graph <- principal_graph(cds)[[\"UMAP\"]] igraph::V(p_graph) # V(): graph -> vertices + 343/343 vertices, named, from 446a6a2: [1] Y_1 Y_2 Y_3 Y_4 Y_5 Y_6 Y_7 Y_8 Y_9 Y_10 Y_11 Y_12 [13] Y_13 Y_14 Y_15 Y_16 Y_17 Y_18 Y_19 Y_20 Y_21 Y_22 Y_23 Y_24 [25] Y_25 Y_26 Y_27 Y_28 Y_29 Y_30 Y_31 Y_32 Y_33 Y_34 Y_35 Y_36 [37] Y_37 Y_38 Y_39 Y_40 Y_41 Y_42 Y_43 Y_44 Y_45 Y_46 Y_47 Y_48 [49] Y_49 Y_50 Y_51 Y_52 Y_53 Y_54 Y_55 Y_56 Y_57 Y_58 Y_59 Y_60 [61] Y_61 Y_62 Y_63 Y_64 Y_65 Y_66 Y_67 Y_68 Y_69 Y_70 Y_71 Y_72 [73] Y_73 Y_74 Y_75 Y_76 Y_77 Y_78 Y_79 Y_80 Y_81 Y_82 Y_83 Y_84 [85] Y_85 Y_86 Y_87 Y_88 Y_89 Y_90 Y_91 Y_92 Y_93 Y_94 Y_95 Y_96 [97] Y_97 Y_98 Y_99 Y_100 Y_101 Y_102 Y_103 Y_104 Y_105 Y_106 Y_107 Y_108 [109] Y_109 Y_110 Y_111 Y_112 Y_113 Y_114 Y_115 Y_116 Y_117 Y_118 Y_119 Y_120 + ... omitted several vertices plot_cells(cds, color_cells_by = \"embryo.time.bin\", label_cell_groups=FALSE, label_leaves=TRUE, label_branch_points=TRUE, graph_label_size=1.5) plot_cells(cds, color_cells_by = \"embryo.time.bin\", label_cell_groups=FALSE, label_groups_by_cluster=FALSE, label_leaves=FALSE, label_branch_points=TRUE, label_principal_points = TRUE, # set this to TRUE graph_label_size=3)","title":"Learn the trajectory graph"},{"location":"bioi611_monocle_cele/#order-cells","text":"Assigns cells a pseudotime value based on their projection on the principal graph learned in the learn_graph function and the position of chosen root states. This function takes as input a cell_data_set and returns it with pseudotime information stored internally. order_cells() optionally takes \"root\" state(s) in the form of cell or principal graph node IDs, which you can use to specify the start of the trajectory. If you don't provide a root state, an plot will be generated where you can choose the root state(s) interactively. # a helper function to identify the root principal points: get_earliest_principal_node <- function(cds, time_bin=\"130-170\"){ cell_ids <- which(colData(cds)[, \"embryo.time.bin\"] == time_bin) # vertex is also called node in a graph closest_vertex <- cds@principal_graph_aux[[\"UMAP\"]]$pr_graph_cell_proj_closest_vertex closest_vertex <- as.matrix(closest_vertex[colnames(cds), ]) root_pr_nodes <- igraph::V(principal_graph(cds)[[\"UMAP\"]])$name[as.numeric(names (which.max(table(closest_vertex[cell_ids,]))))] root_pr_nodes } The function above, get_earliest_principal_node , helps find the \"starting point\" in a path that cells follow as they change or develop, based on some time-related information. get_earliest_principal_node(cds) 'Y_62' cds <- order_cells(cds, root_pr_nodes = get_earliest_principal_node(cds)) plot_cells(cds, color_cells_by = \"pseudotime\", label_cell_groups=FALSE, label_leaves=FALSE, label_branch_points=FALSE, graph_label_size=1.5) Finding genes that change as a function of pseudotime Identifying the genes that change as cells progress along a trajectory is a core objective of this type of analysis. Knowing the order in which genes go on and off can inform new models of development. Let's return to the embryo data, which we processed using the commands You can use graph_test() to find genes that are differentially expressed on the different path through the trajectory. The parameter, neighbor_graph=\"principal_graph\", tells graph_test() to test whether cells at similar positions on the trajectory have correlated expression: ciliated_cds_pr_test_res <- graph_test(cds, neighbor_graph=\"principal_graph\", cores=4) pr_deg_ids <- row.names(subset(ciliated_cds_pr_test_res, q_value < 0.05)) |===========================================================================| 100%, Elapsed 10:03 pr_deg_ids[1:10] .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 'WBGene00010957' 'WBGene00010958' 'WBGene00010959' 'WBGene00010960' 'WBGene00010961' 'WBGene00000829' 'WBGene00010962' 'WBGene00010963' 'WBGene00010964' 'WBGene00010965' Here are a couple of interesting genes that score as highly significant according to graph_test() : plot_cells(cds, genes=c(\"hlh-4\", \"gcy-8\", \"dac-1\", \"oig-8\"), show_trajectory_graph=FALSE, label_cell_groups=FALSE, label_leaves=FALSE) We can then collect the trajectory-variable genes into modules: gene_module_df <- find_gene_modules(cds[pr_deg_ids,], resolution=c(10^seq(-6,-1))) dim(gene_module_df) head(gene_module_df) .list-inline {list-style: none; margin:0; padding: 0} .list-inline>li {display: inline-block} .list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex} 8065 5 A tibble: 6 \u00d7 5 id module supermodule dim_1 dim_2 <chr> <fct> <fct> <dbl> <dbl> WBGene00010957 7 1 -4.377187 -1.642148 WBGene00010958 7 1 -4.623665 -1.831054 WBGene00010959 7 1 -4.359261 -1.622316 WBGene00010960 7 1 -4.383083 -1.655990 WBGene00010961 7 1 -4.393384 -1.639716 WBGene00000829 7 1 -4.366506 -1.660363 cell_group_df <- tibble::tibble(cell=row.names(colData(cds)), cell_group=colData(cds)$cell.type) agg_mat <- aggregate_gene_expression(cds, gene_module_df, cell_group_df) row.names(agg_mat) <- stringr::str_c(\"Module \", row.names(agg_mat)) pheatmap::pheatmap(agg_mat, scale=\"column\", clustering_method=\"ward.D2\") gene_module_df <- find_gene_modules(cds[pr_deg_ids,], resolution=c(10^seq(-6,-1))) You can also use plot_cells() on gene_module_df : plot_cells(cds, genes=gene_module_df %>% dplyr::filter(module %in% c(27, 10, 7, 30)), label_cell_groups=FALSE, show_trajectory_graph=FALSE) Monocle offers another plotting function that can sometimes give a clearer view of a gene's dynamics along a single path. You can select a path with choose_cells() or by subsetting the cell data set by cluster, cell type, or other annotation that's restricted to the path. Let's pick one such path, the AFD cells: # Error: `choose_cells` only works in interactive mode. # Not working in Jupyter notebook or colab # May try this function in R studio or # use new kernel `xeus-r` # choose_cells(cds) AFD_genes <- c(\"gcy-8\", \"dac-1\", \"oig-8\") AFD_lineage_cds <- cds[rowData(cds)$gene_short_name %in% AFD_genes, colData(cds)$cell.type %in% c(\"AFD\")] AFD_lineage_cds class: cell_data_set dim: 3 326 metadata(2): cds_version citations assays(1): counts rownames(3): WBGene00001535 WBGene00000895 WBGene00020582 rowData names(3): id gene_short_name num_cells_expressed colnames(326): AAACCTGCAAGACGTG-300.1.1 ACCAGTATCGTAGGTT-300.1.1 ... GCTGCGATCTTCTGGC-b02 GGGCACTAGCCTTGAT-b02 colData names(19): cell n.umi ... bg.b01.loading bg.b02.loading reducedDimNames(3): PCA Aligned UMAP mainExpName: NULL altExpNames(0): The function plot_genes_in_pseudotime() takes a small set of genes and shows you their dynamics as a function of pseudotime: plot_genes_in_pseudotime(AFD_lineage_cds, min_expr=0.5) As you can see, gene dac-1 is activated before the other two genes.","title":"Order cells"},{"location":"bioi611_monocle_cele/#reference","text":"https://colab.research.google.com/drive/10fqFG9UVbazqeaZwbzpSAJ3I79tSoSYG#scrollTo=1onUusVNBvAr&line=1&uniqifier=1 https://cole-trapnell-lab.github.io/monocle3/docs/differential/#pseudo-dep https://github.com/cole-trapnell-lab/monocle3/issues/179#issuecomment-2145687700","title":"Reference"},{"location":"bioi611_prep_monocle_env/","text":"if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(version = \"3.20\") Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.20 (BiocManager 1.30.25), R 4.4.2 (2024-10-31) Installing package(s) 'BiocVersion' ## required by scater package system(\"apt-get install libx11-dev libcairo2-dev\") #, intern = TRUE) BiocManager::install(c('BiocGenerics', 'DelayedArray', 'DelayedMatrixStats', 'limma', 'lme4', 'S4Vectors', 'SingleCellExperiment', 'SummarizedExperiment', 'batchelor', 'HDF5Array', 'terra', 'ggrastr')) 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: https://cran.rstudio.com Bioconductor version 3.20 (BiocManager 1.30.25), R 4.4.2 (2024-10-31) Installing package(s) 'BiocGenerics', 'DelayedArray', 'DelayedMatrixStats', 'limma', 'lme4', 'S4Vectors', 'SingleCellExperiment', 'SummarizedExperiment', 'batchelor', 'HDF5Array', 'terra', 'ggrastr' also installing the dependencies \u2018formatR\u2019, \u2018zlibbioc\u2019, \u2018lambda.r\u2019, \u2018futile.options\u2019, \u2018matrixStats\u2019, \u2018abind\u2019, \u2018XVector\u2019, \u2018UCSC.utils\u2019, \u2018GenomeInfoDbData\u2019, \u2018assorthead\u2019, \u2018irlba\u2019, \u2018rsvd\u2019, \u2018futile.logger\u2019, \u2018snow\u2019, \u2018BH\u2019, \u2018beeswarm\u2019, \u2018vipor\u2019, \u2018MatrixGenerics\u2019, \u2018IRanges\u2019, \u2018S4Arrays\u2019, \u2018SparseArray\u2019, \u2018sparseMatrixStats\u2019, \u2018statmod\u2019, \u2018minqa\u2019, \u2018nloptr\u2019, \u2018RcppEigen\u2019, \u2018GenomicRanges\u2019, \u2018Biobase\u2019, \u2018GenomeInfoDb\u2019, \u2018igraph\u2019, \u2018BiocNeighbors\u2019, \u2018BiocSingular\u2019, \u2018BiocParallel\u2019, \u2018scuttle\u2019, \u2018ResidualMatrix\u2019, \u2018ScaledMatrix\u2019, \u2018beachmat\u2019, \u2018rhdf5\u2019, \u2018rhdf5filters\u2019, \u2018Rhdf5lib\u2019, \u2018Cairo\u2019, \u2018ggbeeswarm\u2019, \u2018png\u2019 install.packages(\"devtools\") devtools::install_github('cole-trapnell-lab/monocle3') Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) Downloading GitHub repo cole-trapnell-lab/monocle3@HEAD sitmo (NA -> 2.0.2 ) [CRAN] bitops (NA -> 1.0-9 ) [CRAN] RCurl (NA -> 1.98-1.16) [CRAN] proxy (NA -> 0.4-27 ) [CRAN] wk (NA -> 0.9.4 ) [CRAN] e1071 (NA -> 1.7-16 ) [CRAN] units (NA -> 0.8-5 ) [CRAN] s2 (NA -> 1.1.7 ) [CRAN] classInt (NA -> 0.4-10 ) [CRAN] sp (NA -> 2.1-4 ) [CRAN] warp (NA -> 0.2.1 ) [CRAN] parallelly (NA -> 1.39.0 ) [CRAN] listenv (NA -> 0.9.1 ) [CRAN] globals (NA -> 0.16.3 ) [CRAN] future (NA -> 1.34.0 ) [CRAN] lazyeval (NA -> 0.2.2 ) [CRAN] RcppHNSW (NA -> 0.6.0 ) [CRAN] gridExtra (NA -> 2.3 ) [CRAN] RcppProgress (NA -> 0.4.2 ) [CRAN] dqrng (NA -> 0.4.1 ) [CRAN] RSpectra (NA -> 0.16-2 ) [CRAN] RcppAnnoy (NA -> 0.0.22 ) [CRAN] FNN (NA -> 1.1.4.1 ) [CRAN] biglm (NA -> 0.9-3 ) [CRAN] deldir (NA -> 2.0-4 ) [CRAN] sf (NA -> 1.0-19 ) [CRAN] spData (NA -> 2.3.3 ) [CRAN] slider (NA -> 0.3.2 ) [CRAN] furrr (NA -> 0.3.1 ) [CRAN] plyr (NA -> 1.8.9 ) [CRAN] crosstalk (NA -> 1.2.1 ) [CRAN] zoo (NA -> 1.8-12 ) [CRAN] viridis (NA -> 0.6.5 ) [CRAN] uwot (NA -> 0.2.2 ) [CRAN] speedglm (NA -> 0.3-5 ) [CRAN] spdep (NA -> 1.3-6 ) [CRAN] slam (NA -> 0.1-55 ) [CRAN] Rtsne (NA -> 0.17 ) [CRAN] RhpcBLASctl (NA -> 0.23-42 ) [CRAN] rsample (NA -> 1.2.1 ) [CRAN] reshape2 (NA -> 1.4.4 ) [CRAN] RANN (NA -> 2.6.2 ) [CRAN] pscl (NA -> 1.5.9 ) [CRAN] plotly (NA -> 4.10.4 ) [CRAN] pheatmap (NA -> 1.0.12 ) [CRAN] pbmcapply (NA -> 1.5.1 ) [CRAN] pbapply (NA -> 1.7-2 ) [CRAN] lmtest (NA -> 0.9-40 ) [CRAN] leidenbase (NA -> 0.1.31 ) [CRAN] grr (NA -> 0.9.5 ) [CRAN] ggrepel (NA -> 0.9.6 ) [CRAN] assertthat (NA -> 0.2.1 ) [CRAN] Skipping 30 packages ahead of CRAN: zlibbioc, XVector, SparseArray, S4Arrays, IRanges, S4Vectors, MatrixGenerics, BiocGenerics, GenomeInfoDbData, GenomeInfoDb, Rhdf5lib, rhdf5filters, DelayedArray, Biobase, sparseMatrixStats, beachmat, DelayedMatrixStats, SummarizedExperiment, GenomicRanges, BiocParallel, SingleCellExperiment, ScaledMatrix, rhdf5, ResidualMatrix, scuttle, BiocSingular, BiocNeighbors, limma, HDF5Array, batchelor Installing 52 packages: sitmo, bitops, RCurl, proxy, wk, e1071, units, s2, classInt, sp, warp, parallelly, listenv, globals, future, lazyeval, RcppHNSW, gridExtra, RcppProgress, dqrng, RSpectra, RcppAnnoy, FNN, biglm, deldir, sf, spData, slider, furrr, plyr, crosstalk, zoo, viridis, uwot, speedglm, spdep, slam, Rtsne, RhpcBLASctl, rsample, reshape2, RANN, pscl, plotly, pheatmap, pbmcapply, pbapply, lmtest, leidenbase, grr, ggrepel, assertthat Installing packages into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) \u001b[36m\u2500\u2500\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m * checking for file \u2018/tmp/RtmpNviskA/remotesfa163c8a18/cole-trapnell-lab-monocle3-98402ed/DESCRIPTION\u2019 ... OK * preparing \u2018monocle3\u2019: * checking DESCRIPTION meta-information ... OK * cleaning src * checking for LF line-endings in source and make files and shell scripts * checking for empty or unneeded directories Omitted \u2018LazyData\u2019 from DESCRIPTION * building \u2018monocle3_1.3.7.tar.gz\u2019 Installing package into \u2018/usr/local/lib/R/site-library\u2019 (as \u2018lib\u2019 is unspecified) library(monocle3) Loading required package: Biobase Loading required package: BiocGenerics Attaching package: \u2018BiocGenerics\u2019 The following objects are masked from \u2018package:stats\u2019: IQR, mad, sd, var, xtabs The following objects are masked from \u2018package:base\u2019: anyDuplicated, aperm, append, as.data.frame, basename, cbind, colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rownames, sapply, saveRDS, setdiff, table, tapply, union, unique, unsplit, which.max, which.min Welcome to Bioconductor Vignettes contain introductory material; view with 'browseVignettes()'. To cite Bioconductor, see 'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'. Loading required package: SingleCellExperiment Loading required package: SummarizedExperiment Loading required package: MatrixGenerics Loading required package: matrixStats Attaching package: \u2018matrixStats\u2019 The following objects are masked from \u2018package:Biobase\u2019: anyMissing, rowMedians Attaching package: \u2018MatrixGenerics\u2019 The following objects are masked from \u2018package:matrixStats\u2019: colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse, colCounts, colCummaxs, colCummins, colCumprods, colCumsums, colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs, colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats, colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds, colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads, colWeightedMeans, colWeightedMedians, colWeightedSds, colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet, rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods, rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps, rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins, rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks, rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars, rowWeightedMads, rowWeightedMeans, rowWeightedMedians, rowWeightedSds, rowWeightedVars The following object is masked from \u2018package:Biobase\u2019: rowMedians Loading required package: GenomicRanges Loading required package: stats4 Loading required package: S4Vectors Attaching package: \u2018S4Vectors\u2019 The following object is masked from \u2018package:utils\u2019: findMatches The following objects are masked from \u2018package:base\u2019: expand.grid, I, unname Loading required package: IRanges Loading required package: GenomeInfoDb Attaching package: \u2018monocle3\u2019 The following objects are masked from \u2018package:Biobase\u2019: exprs, fData, fData<-, pData, pData<- system(\"tar zcvf R_lib_monocle3.tar.gz /usr/local/lib/R/site-library\")","title":"Bioi611 prep monocle env"},{"location":"bulkRNAseq_lab/","text":"Analysis of RNA-seq data: read QC and alignment Download reference genome To download the reference for this lab, we use ENSEMBL database . In ENSEMBL database, each species may have different releases of genome build. We use release-111 in this project. The genome sequences can be obtained from the link below: https://ftp.ensembl.org/pub/release-111/fasta/caenorhabditis_elegans/dna/ The genoe anntation file in gtf format can be obtained here: https://ftp.ensembl.org/pub/release-111/gtf/caenorhabditis_elegans/ %%bash wget -O Caenorhabditis_elegans.WBcel235.dna.toplevel.fa.gz https://ftp.ensembl.org/pub/release-111/fasta/caenorhabditis_elegans/dna/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa.gz gunzip Caenorhabditis_elegans.WBcel235.dna.toplevel.fa.gz %%bash ## A *fai file will be generated samtools faidx ref/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa %%bash wget -O Caenorhabditis_elegans.WBcel235.111.gtf.gz -nv https://ftp.ensembl.org/pub/release-111/gtf/caenorhabditis_elegans/Caenorhabditis_elegans.WBcel235.111.gtf.gz gunzip Caenorhabditis_elegans.WBcel235.111.gtf.gz In this course, the reference files have been downloaded and stored in shared folder for BIOI611: /scratch/zt1/project/bioi611/shared/reference/ As you already leart, you can create a symbolic link for you to use in your scratch folder: %%bash cd /scratch/zt1/project/bioi611/user/$USER ln -s /scratch/zt1/project/bioi611/shared/reference/ . How many chromsomes there are %%bash cd /scratch/zt1/project/bioi611/user/$USER grep '>' reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa >I dna:chromosome chromosome:WBcel235:I:1:15072434:1 REF >II dna:chromosome chromosome:WBcel235:II:1:15279421:1 REF >III dna:chromosome chromosome:WBcel235:III:1:13783801:1 REF >IV dna:chromosome chromosome:WBcel235:IV:1:17493829:1 REF >V dna:chromosome chromosome:WBcel235:V:1:20924180:1 REF >X dna:chromosome chromosome:WBcel235:X:1:17718942:1 REF >MtDNA dna:chromosome chromosome:WBcel235:MtDNA:1:13794:1 REF How many genes there are %%bash cd /scratch/zt1/project/bioi611/user/$USER grep -v '#' reference/Caenorhabditis_elegans.WBcel235.111.gtf \\ |awk '$3==\"gene\"' \\ |sed 's/.*gene_biotype \"//' \\ |sed 's/\";//'|sort |uniq -c \\ | sort -k1,1n 22 rRNA 100 antisense_RNA 129 snRNA 194 lincRNA 261 miRNA 346 snoRNA 634 tRNA 2128 pseudogene 7764 ncRNA 15363 piRNA 19985 protein_coding Source: https://useast.ensembl.org/Help/Faq?id=468eudogene Download raw fastq files When scientists publish their results based on NGS data, they are required to deposit the raw data in public database, e.g. NCBI GEO/SRA database. In the manuscript, the accession number is included for the community to search and download the data. Majority of the times, the information will be included in a section called 'Data Availability'. Depending on whether GEO or SRA numbers are provided. You can go to either GEO or SRA database: https://www.ncbi.nlm.nih.gov/sra https://www.ncbi.nlm.nih.gov/geo/ An alternative way is that you can use third party tool which will help you quick generate the command lines that you can use to download the data. One example is SRA explorer: https://sra-explorer.info/ %%bash mkdir -p raw_data/ curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/002/SRR15694102/SRR15694102.fastq.gz -o raw_data/N2_day7_rep1.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/001/SRR15694101/SRR15694101.fastq.gz -o raw_data/N2_day7_rep2.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/000/SRR15694100/SRR15694100.fastq.gz -o raw_data/N2_day7_rep3.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/099/SRR15694099/SRR15694099.fastq.gz -o raw_data/N2_day1_rep1.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/098/SRR15694098/SRR15694098.fastq.gz -o raw_data/N2_day1_rep2.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/097/SRR15694097/SRR15694097.fastq.gz -o raw_data/N2_day1_rep3.fastq.gz Quality control Use FastQC to check the quality of fastq files: %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s1_fastqc.sub Use trim galore to remove adaptors, low quality bases and low quality reads. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s2_trim_galore.sub The command lines to run trim_galore were listed below. In the jobs between, trim_galore is executed in container built by singularity . The input and output folders are all under /scratch/zt1/project/bioi611/ . When you run trim_galore inside the container, you need to make sure trim_galore has access to the input and output files. In the job below, the STAR index files are located in the shared folder (two levels up). So you need to bind the folder that includes both $PWD and the STAR index folder. That's the reason we specify SIF_BIND=\"/scratch/zt1/project/bioi611/\" . %%bash cd /scratch/zt1/project/bioi611/user/$USER cat ../../shared/scripts/bulkRNA_SE_s2_trim_galore.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH --nodes=1 #SBATCH --ntasks=6 #SBATCH --cpus-per-task=12 #SBATCH --job-name=bulkRNA_SE_s2_trim_galore #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out module load singularity ## Binding path and singularity image file SIF_BIND=\"/scratch/zt1/project/bioi611/\" SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\" ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" FASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\" cd $WORKDIR date singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day1_rep1.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day1_rep2.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day1_rep3.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day7_rep1.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day7_rep2.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day7_rep3.fastq.gz & wait date Read alignment using STAR Generate genome index During this step, the reference genome (FASTA file) and annotations (GTF files) are supplied. The genome index are saved to disk and only need to be generated once. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_s1_star_idx.sub Here is the content in `bulkRNA_s1_star_idx.sub`: %%bash cd /scratch/zt1/project/bioi611/user/$USER cat ../../shared/scripts/bulkRNA_s1_star_idx.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=2 #SBATCH --job-name=bulkRNA_s1_star_idx #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out PATH=\"/scratch/zt1/project/bioi611/shared/software/STAR_2.7.11b/Linux_x86_64_static/:$PATH\" WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" FASTA=\"/scratch/zt1/project/bioi611/shared/reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa\" GTF=\"/scratch/zt1/project/bioi611/shared/reference/Caenorhabditis_elegans.WBcel235.111.gtf\" cd $WORKDIR mkdir STAR_index STAR --runThreadN 2 --runMode genomeGenerate \\ --genomeDir STAR_index \\ --genomeFastaFiles $FASTA \\ --sjdbGTFfile $GTF The genome files will be outputted into STAR_index/ : %%bash cd /scratch/zt1/project/bioi611/user/$USER ls STAR_index/ chrLength.txt chrNameLength.txt chrName.txt chrStart.txt exonGeTrInfo.tab exonInfo.tab geneInfo.tab Genome genomeParameters.txt SA SAindex sjdbInfo.txt sjdbList.fromGTF.out.tab sjdbList.out.tab transcriptInfo.tab Important things to keep in mind: STAR is a splicing aware mapper which is required for RNA-seq read alignment Genome index only need to be built one Make sure the reference file and annotation file match each other. For a particular species, there might be reference genomes built for different strains/ecotypes. Even for the same strain/ecotype, there could be different versions. Human Genome Assemblies, hg19 and hg38 are two different versions of the human genome, which is the complete set of DNA in an individual's cells. Hg19 is the older of the two assemblies and was released in 2002. Hg38 , also known as GRCh38 , is the more recent assembly and was released in 2013. It is a more accurate and detailed version of the human genome and includes additional data that was not available when HG19 was released. After ethe reference genome is built, you can start to align the RNA-seq reads using the command lines below. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s3_STAR_align.sub sbatch ../../shared/scripts/bulkRNA_SE_s4_bam_index.sub %%bash cd /scratch/zt1/project/bioi611/user/$USER cat ../../shared/scripts/bulkRNA_SE_s3_STAR_align.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH --nodes=1 #SBATCH --ntasks=6 #SBATCH --cpus-per-task=10 #SBATCH --job-name=bulkRNA_SE_STAR_align #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out PATH=\"/scratch/zt1/project/bioi611/shared/software/STAR_2.7.11b/Linux_x86_64_static/:$PATH\" INDIR=bulk_RNAseq_SE_trim_galore/ OUTDIR=bulkRNA_SE_STAR_align/ mkdir -p $OUTDIR STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day1_rep1. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day1_rep1_trimmed.fq.gz > $OUTDIR/N2_day1_rep1.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day1_rep2. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day1_rep2_trimmed.fq.gz > $OUTDIR/N2_day1_rep2.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day1_rep3. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day1_rep3_trimmed.fq.gz > $OUTDIR/N2_day1_rep3.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day7_rep1. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day7_rep1_trimmed.fq.gz > $OUTDIR/N2_day7_rep1.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day7_rep2. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day7_rep2_trimmed.fq.gz > $OUTDIR/N2_day7_rep2.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day7_rep3. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day7_rep3_trimmed.fq.gz > $OUTDIR/N2_day7_rep3.log.txt 2>&1 & wait In the STAR command lines, the following parameters are used --genomeDir STAR_index --genomeDir is required. The name of the parameter is self-explanatory. --outSAMtype BAM SortedByCoordinate This parameter is optional. If not specified, 'SAM' will be used: SAM : output SAM without sorting BAM format is the binary format for SAM file. To understand the details of BAM/SAM format, refer to the link here . --twopassMode Basic Wil the parameter above, STAR will perform the 1st pass mapping, then it will automatically extract junctions, insert them into the genome index, and, finally, re-map all reads in the 2nd mapping pass. This option can be used with annotations, which can be included either at the run-time, or at the genome generation step --quantMode TranscriptomeSAM GeneCounts With parameters above, STAR produces both the Aligned.toTranscriptome.out.bam and ReadsPerGene.out.tab outputs --readFilesCommand zcat The parameter specifies the command line ( None , zcat or bzcat ) to execute for each of the input file --outFileNamePrefix $OUTDIR/N2_day7_rep2. : output files name prefix (including full or relative path) --runThreadN 10 : number of threads to run STAR --readFilesIn $INDIR/N2_day7_rep3_trimmed.fq.gz : paths to files that contain input read1 (and, if needed, read2) The step below is optional. After alignment, it is good practice to index the sorted BAM file so that downstream tools (such as IGV, featureCounts, or samtools view) can quickly access specific genomic regions. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s4_bam_index.sub ```bash %%bash cd /scratch/zt1/project/bioi611/user/$USER grep 'samtools' ../../shared/scripts/bulkRNA_SE_s4_bam_index.sub module load samtools samtools index bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day1_rep2.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day1_rep3.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day7_rep1.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day7_rep2.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day7_rep3.Aligned.sortedByCoord.out.bam & After the job is finished, each BAM file will have a *.bai file generated: %%bash cd /scratch/zt1/project/bioi611/user/$USER ls bulkRNA_SE_STAR_align/*.bai bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day1_rep2.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day1_rep3.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day7_rep1.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day7_rep2.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day7_rep3.Aligned.sortedByCoord.out.bam.bai Use MultiQC to generate report MultiQC is a reporting tool that parses results and statistics from bioinformatics tool outputs, such as log files and console outputs. It helps to summarise experiments containing multiple samples and multiple analysis steps. It\u2019s designed to be placed at the end of pipelines or to be run manually when you\u2019ve finished running your tools. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s5_multiqc.sub %%bash cd /scratch/zt1/project/bioi611/user/$USER grep -v 'SBATCH' ../../shared/scripts/bulkRNA_SE_s5_multiqc.sub #!/bin/bash module load singularity ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" cd $WORKDIR singularity exec -B $PWD /scratch/zt1/project/bioi611/shared/software/multiqc_v1.25.sif multiqc -f -o bulk_RNAseq_SE_multiqc ./bulk_RNAseq_SE_fastqc/ bulk_RNAseq_SE_trim_galore/ bulkRNA_SE_STAR_align/ In the command line above, you will again run multiqc in singularity container. This time, -B $PWD is used. $PWD is a dynamic environmental variable that stores the current working directory in which the input and output of multiqc will be store. Use RSeQC to generate QC plots RSeQC package provides a number of useful modules that can comprehensively evaluate RNA-seq data. In this lecture, we are going to use one of the modules geneBody_coverage.py . This module is used to check if read coverage is uniform and if there is any 5'/3' bias. This module scales all transcripts to 100 nt and calculates the number of reads covering each nucleotide position. Finally, it generates plots illustrating the coverage profile along the gene body. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s6_RSeQC_genebody_cov.sub %%bash cd /scratch/zt1/project/bioi611/user/$USER cat ../../shared/scripts/bulkRNA_SE_s6_RSeQC_genebody_cov.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --job-name=bulkRNA_SE_s6_RSeQC_genebody_cov.sub #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out module load singularity ## Binding path and singularity image file SIF_BIND=\"/scratch/zt1/project/bioi611/\" SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/rseqc_v5.0.3.sif\" SIF_BEDOPS=\"/scratch/zt1/project/bioi611/shared/software/bedops_v2.4.39.sif\" ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" cd $WORKDIR mkdir -p bulk_RNAseq_SE_RSeQC/ singularity exec -B $SIF_BIND $SIF_TRIMGALORE geneBody_coverage.py -r /scratch/zt1/project/bioi611/shared/reference/Caenorhabditis_elegans.WBcel235.111.bed -i bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam,bulkRNA_SE_STAR_align/N2_day7_rep1.Aligned.sortedByCoord.out.bam -o bulk_RNAseq_SE_RSeQC/geneBody_cov # Test command line which can be completed in less than 2 minutes # singularity exec -B $SIF_BIND $SIF_TRIMGALORE geneBody_coverage.py -r test_1000genes.bed -i bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam -o test_genebody_cov/test After the job above is completed, one of the output file is a PDF file. As you can see, in the two samples checked, the coverage over the gene body is quite uniform. Caenorhabditis_elegans.WBcel235.111.bed is used as one of the input for geneBody_coverage.py in RSeQC. To understand the bed file format, please refer to the link below: https://genome.ucsc.edu/FAQ/FAQformat.html#format1 The bed file can be genreated using GFF3 file. GFF3 format is a similar format as GTF. To generate bed file from GFF3 file, you can use the command line below: wget https://ftp.ensembl.org/pub/release-111/gff3/caenorhabditis_elegans/Caenorhabditis_elegans.WBcel235.111.gff3.gz export PATH=\"/scratch/zt1/project/bioi611/shared/software:$PATH\" gff3ToGenePred Caenorhabditis_elegans.WBcel235.111.gff3 Caenorhabditis_elegans.WBcel235.111.phred genePredToBed Caenorhabditis_elegans.WBcel235.111.phred Caenorhabditis_elegans.WBcel235.111.bed Advanced topcis Bind paths and mounts in sigularity Singularity allows you to map directories on your host system to directories within your container using bind mounts. This allows you to read and write data on the host system with ease. The system administrator has the ability to define what bind paths will be included automatically inside each container. Some bind paths are automatically derived (e.g. a user\u2019s home directory) and some are statically defined (e.g. bind paths in the Singularity configuration file). In the default configuration, the directories $HOME , /tmp , /proc , /sys , /dev , and $PWD are among the system-defined bind paths. On UMD HPC, $PWD is not defined. So you have to mount the path via the command line parameter -B/--bind . You can go into the singlarity container just as you are working in a linux system. %%bash module load singularity SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\" singularity exec $SIF_TRIMGALORE /bin/bash You will be in the container after you run the command lines above. You can then run the Linux commands you leart from previous classes. To exit the container, simply press ctrl+d on your keyborad. Running the commands below, you run ls $FASTQ_DIR inside the container to list the fastq files. %%bash module load singularity ## Binding path and singularity image file SIF_BIND=\"/scratch/zt1/project/bioi611/\" SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\" ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" FASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\" cd $WORKDIR singularity exec -B $SIF_BIND $SIF_TRIMGALORE ls $FASTQ_DIR N2_day1_rep1.fastq.gz N2_day1_rep2.fastq.gz N2_day1_rep3.fastq.gz N2_day7_rep1.fastq.gz N2_day7_rep2.fastq.gz N2_day7_rep3.fastq.gz Running the commands below, the command lines will fail because $WORKDIR is not mounted. %%bash module load singularity ## Binding path and singularity image file SIF_BIND=\"/scratch/zt1/project/bioi611/\" SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\" ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" FASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\" cd $WORKDIR singularity exec $SIF_TRIMGALORE ls $WORKDIR ls: /scratch/zt1/project/bioi611/user/xie186: No such file or directory --------------------------------------------------------------------------- CalledProcessError Traceback (most recent call last) Cell In[20], line 1 ----> 1 get_ipython().run_cell_magic('bash', '', 'module load singularity\\n## Binding path and singularity image file \\nSIF_BIND=\"/scratch/zt1/project/bioi611/\"\\nSIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\"\\n## Paths to working directory and input fastq files\\nWORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\"\\nFASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\"\\ncd $WORKDIR \\nsingularity exec $SIF_TRIMGALORE ls $WORKDIR\\n') File /cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/mpi-nocuda/linux-rhel8-zen2/gcc/11.3.0/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2430, in InteractiveShell.run_cell_magic(self, magic_name, line, cell) 2428 with self.builtin_trap: 2429 args = (magic_arg_s, cell) -> 2430 result = fn(*args, **kwargs) 2432 # The code below prevents the output from being displayed 2433 # when using magics with decodator @output_can_be_silenced 2434 # when the last Python token in the expression is a ';'. 2435 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False): File /cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/mpi-nocuda/linux-rhel8-zen2/gcc/11.3.0/lib/python3.10/site-packages/IPython/core/magics/script.py:153, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell) 151 else: 152 line = script --> 153 return self.shebang(line, cell) File /cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/mpi-nocuda/linux-rhel8-zen2/gcc/11.3.0/lib/python3.10/site-packages/IPython/core/magics/script.py:305, in ScriptMagics.shebang(self, line, cell) 300 if args.raise_error and p.returncode != 0: 301 # If we get here and p.returncode is still None, we must have 302 # killed it but not yet seen its return code. We don't wait for it, 303 # in case it's stuck in uninterruptible sleep. -9 = SIGKILL 304 rc = p.returncode or -9 --> 305 raise CalledProcessError(rc, cell) CalledProcessError: Command 'b'module load singularity\\n## Binding path and singularity image file \\nSIF_BIND=\"/scratch/zt1/project/bioi611/\"\\nSIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\"\\n## Paths to working directory and input fastq files\\nWORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\"\\nFASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\"\\ncd $WORKDIR \\nsingularity exec $SIF_TRIMGALORE ls $WORKDIR\\n'' returned non-zero exit status 1. Use samtools to display the content of BAM files Samtools is a powerful tool that can be used to display and manipulate SAM/BAM files. The command lines below shows you how to use samtools view to display the content: the headers and the alignments. %%bash module load samtools WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" samtools view -H $WORKDIR/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam @HD VN:1.4 SO:coordinate @SQ SN:I LN:15072434 @SQ SN:II LN:15279421 @SQ SN:III LN:13783801 @SQ SN:IV LN:17493829 @SQ SN:V LN:20924180 @SQ SN:X LN:17718942 @SQ SN:MtDNA LN:13794 @PG ID:STAR PN:STAR VN:2.7.11b CL:STAR --runThreadN 10 --genomeDir STAR_index --readFilesIn bulk_RNAseq_SE_trim_galore//N2_day1_rep1_trimmed.fq.gz --readFilesCommand zcat --outFileNamePrefix bulkRNA_SE_STAR_align//N2_day1_rep1. --outSAMtype BAM SortedByCoordinate --quantMode TranscriptomeSAM GeneCounts --twopassMode Basic @PG ID:samtools PN:samtools PP:STAR VN:1.17 CL:samtools view -H /scratch/zt1/project/bioi611/user/xie186/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam @CO user command line: STAR --genomeDir STAR_index --outSAMtype BAM SortedByCoordinate --twopassMode Basic --quantMode TranscriptomeSAM GeneCounts --readFilesCommand zcat --outFileNamePrefix bulkRNA_SE_STAR_align//N2_day1_rep1. --runThreadN 10 --readFilesIn bulk_RNAseq_SE_trim_galore//N2_day1_rep1_trimmed.fq.gz %%bash module load samtools WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" samtools view -h $WORKDIR/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam |head -14 @HD VN:1.4 SO:coordinate @SQ SN:I LN:15072434 @SQ SN:II LN:15279421 @SQ SN:III LN:13783801 @SQ SN:IV LN:17493829 @SQ SN:V LN:20924180 @SQ SN:X LN:17718942 @SQ SN:MtDNA LN:13794 @PG ID:STAR PN:STAR VN:2.7.11b CL:STAR --runThreadN 10 --genomeDir STAR_index --readFilesIn bulk_RNAseq_SE_trim_galore//N2_day1_rep1_trimmed.fq.gz --readFilesCommand zcat --outFileNamePrefix bulkRNA_SE_STAR_align//N2_day1_rep1. --outSAMtype BAM SortedByCoordinate --quantMode TranscriptomeSAM GeneCounts --twopassMode Basic @PG ID:samtools PN:samtools PP:STAR VN:1.17 CL:samtools view -h /scratch/zt1/project/bioi611/user/xie186/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam @CO user command line: STAR --genomeDir STAR_index --outSAMtype BAM SortedByCoordinate --twopassMode Basic --quantMode TranscriptomeSAM GeneCounts --readFilesCommand zcat --outFileNamePrefix bulkRNA_SE_STAR_align//N2_day1_rep1. --runThreadN 10 --readFilesIn bulk_RNAseq_SE_trim_galore//N2_day1_rep1_trimmed.fq.gz SRR15694099.8922190 256 I 2366 0 96M * 0 0 TGAAAATTTTGTGATTTTCGTAAATTTATTCCTATTTATTAATAAAAACAAAAACAATTCCATTAAATATCCCATTTTCAGCGCAAAATCGACTGG CCCFFFFFHHHHHJJJJJJJIJJJJJJJJJJJJJJJIJJJJJJJIJJIIIIJJJJJJJJJJJJJJJJJJJIJJJJIIJJHHGHFFDDDDCDDDDD@ NH:i:8 HI:i:8 AS:i:94 nM:i:0 SRR15694099.16768635 16 I 2481 1 95M * 0 0 GAGATAGAACGGATCAACAAGATTATTATTATATCATTAATAATATTTATCAATTTTCTTCTGAGAGTCTCATTGAGACTCTTATTTACGCCAAG ;>@EEAB@;B;EAA6.=7==>GEAGAGEGHF>F=FCHEFDBGBFD<D9GBBBBBB;;D?BF@DFEGDHFEIIIHEGIIFFDHFBFDD<DDDA@@@ NH:i:4 HI:i:1 AS:i:93 nM:i:0 SRR15694099.10859917 0 I 2602 255 71M * 0 0 ATTTTTGAAAAAAAAATAATTAAAAAAACACATTTTTTGGAAAAAAAAATAAATAAAAAAAATTGTCCTCG ?@@DDEDB?HHBDHGIIIGIIGCBBGEHAF?GIHIIIGGFBCCEBB@BBBCCCEECCCCBBBBCCC@CCC@ NH:i:1 HI:i:1 AS:i:69 nM:i:0 %%bash module load samtools WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" samtools view $WORKDIR/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam |head -4 SRR15694099.8922190 256 I 2366 0 96M * 0 0 TGAAAATTTTGTGATTTTCGTAAATTTATTCCTATTTATTAATAAAAACAAAAACAATTCCATTAAATATCCCATTTTCAGCGCAAAATCGACTGG CCCFFFFFHHHHHJJJJJJJIJJJJJJJJJJJJJJJIJJJJJJJIJJIIIIJJJJJJJJJJJJJJJJJJJIJJJJIIJJHHGHFFDDDDCDDDDD@ NH:i:8 HI:i:8 AS:i:94 nM:i:0 SRR15694099.16768635 16 I 2481 1 95M * 0 0 GAGATAGAACGGATCAACAAGATTATTATTATATCATTAATAATATTTATCAATTTTCTTCTGAGAGTCTCATTGAGACTCTTATTTACGCCAAG ;>@EEAB@;B;EAA6.=7==>GEAGAGEGHF>F=FCHEFDBGBFD<D9GBBBBBB;;D?BF@DFEGDHFEIIIHEGIIFFDHFBFDD<DDDA@@@ NH:i:4 HI:i:1 AS:i:93 nM:i:0 SRR15694099.10859917 0 I 2602 255 71M * 0 0 ATTTTTGAAAAAAAAATAATTAAAAAAACACATTTTTTGGAAAAAAAAATAAATAAAAAAAATTGTCCTCG ?@@DDEDB?HHBDHGIIIGIIGCBBGEHAF?GIHIIIGGFBCCEBB@BBBCCCEECCCCBBBBCCC@CCC@ NH:i:1 HI:i:1 AS:i:69 nM:i:0 SRR15694099.30104406 16 I 2611 255 40M1I55M * 0 0 AAAAAAATAATTAAAAAAACACATTTTTTGGAAAAAAAAAATAAATAAAAAAAATTGTCCTCGAGGATCCTCCGGAGCGCGTCGAATCAATGTTTC BBDDAB>>A>48BBDCCC@4((<5AA>4(43BDDDDDDACC@CCA?DBACDB?BHE=;EA;<EFB=81@F:BGHGBBA8BFBGBHHHBFFEDD?@@ NH:i:1 HI:i:1 AS:i:89 nM:i:0","title":"Read QC and alignment"},{"location":"bulkRNAseq_lab/#analysis-of-rna-seq-data-read-qc-and-alignment","text":"","title":"Analysis of RNA-seq data: read QC and alignment"},{"location":"bulkRNAseq_lab/#download-reference-genome","text":"To download the reference for this lab, we use ENSEMBL database . In ENSEMBL database, each species may have different releases of genome build. We use release-111 in this project. The genome sequences can be obtained from the link below: https://ftp.ensembl.org/pub/release-111/fasta/caenorhabditis_elegans/dna/ The genoe anntation file in gtf format can be obtained here: https://ftp.ensembl.org/pub/release-111/gtf/caenorhabditis_elegans/ %%bash wget -O Caenorhabditis_elegans.WBcel235.dna.toplevel.fa.gz https://ftp.ensembl.org/pub/release-111/fasta/caenorhabditis_elegans/dna/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa.gz gunzip Caenorhabditis_elegans.WBcel235.dna.toplevel.fa.gz %%bash ## A *fai file will be generated samtools faidx ref/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa %%bash wget -O Caenorhabditis_elegans.WBcel235.111.gtf.gz -nv https://ftp.ensembl.org/pub/release-111/gtf/caenorhabditis_elegans/Caenorhabditis_elegans.WBcel235.111.gtf.gz gunzip Caenorhabditis_elegans.WBcel235.111.gtf.gz In this course, the reference files have been downloaded and stored in shared folder for BIOI611: /scratch/zt1/project/bioi611/shared/reference/ As you already leart, you can create a symbolic link for you to use in your scratch folder: %%bash cd /scratch/zt1/project/bioi611/user/$USER ln -s /scratch/zt1/project/bioi611/shared/reference/ .","title":"Download reference genome"},{"location":"bulkRNAseq_lab/#how-many-chromsomes-there-are","text":"%%bash cd /scratch/zt1/project/bioi611/user/$USER grep '>' reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa >I dna:chromosome chromosome:WBcel235:I:1:15072434:1 REF >II dna:chromosome chromosome:WBcel235:II:1:15279421:1 REF >III dna:chromosome chromosome:WBcel235:III:1:13783801:1 REF >IV dna:chromosome chromosome:WBcel235:IV:1:17493829:1 REF >V dna:chromosome chromosome:WBcel235:V:1:20924180:1 REF >X dna:chromosome chromosome:WBcel235:X:1:17718942:1 REF >MtDNA dna:chromosome chromosome:WBcel235:MtDNA:1:13794:1 REF","title":"How many chromsomes there are"},{"location":"bulkRNAseq_lab/#how-many-genes-there-are","text":"%%bash cd /scratch/zt1/project/bioi611/user/$USER grep -v '#' reference/Caenorhabditis_elegans.WBcel235.111.gtf \\ |awk '$3==\"gene\"' \\ |sed 's/.*gene_biotype \"//' \\ |sed 's/\";//'|sort |uniq -c \\ | sort -k1,1n 22 rRNA 100 antisense_RNA 129 snRNA 194 lincRNA 261 miRNA 346 snoRNA 634 tRNA 2128 pseudogene 7764 ncRNA 15363 piRNA 19985 protein_coding Source: https://useast.ensembl.org/Help/Faq?id=468eudogene","title":"How many genes there are"},{"location":"bulkRNAseq_lab/#download-raw-fastq-files","text":"When scientists publish their results based on NGS data, they are required to deposit the raw data in public database, e.g. NCBI GEO/SRA database. In the manuscript, the accession number is included for the community to search and download the data. Majority of the times, the information will be included in a section called 'Data Availability'. Depending on whether GEO or SRA numbers are provided. You can go to either GEO or SRA database: https://www.ncbi.nlm.nih.gov/sra https://www.ncbi.nlm.nih.gov/geo/ An alternative way is that you can use third party tool which will help you quick generate the command lines that you can use to download the data. One example is SRA explorer: https://sra-explorer.info/ %%bash mkdir -p raw_data/ curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/002/SRR15694102/SRR15694102.fastq.gz -o raw_data/N2_day7_rep1.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/001/SRR15694101/SRR15694101.fastq.gz -o raw_data/N2_day7_rep2.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/000/SRR15694100/SRR15694100.fastq.gz -o raw_data/N2_day7_rep3.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/099/SRR15694099/SRR15694099.fastq.gz -o raw_data/N2_day1_rep1.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/098/SRR15694098/SRR15694098.fastq.gz -o raw_data/N2_day1_rep2.fastq.gz curl -L ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR156/097/SRR15694097/SRR15694097.fastq.gz -o raw_data/N2_day1_rep3.fastq.gz","title":"Download raw fastq files"},{"location":"bulkRNAseq_lab/#quality-control","text":"Use FastQC to check the quality of fastq files: %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s1_fastqc.sub Use trim galore to remove adaptors, low quality bases and low quality reads. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s2_trim_galore.sub The command lines to run trim_galore were listed below. In the jobs between, trim_galore is executed in container built by singularity . The input and output folders are all under /scratch/zt1/project/bioi611/ . When you run trim_galore inside the container, you need to make sure trim_galore has access to the input and output files. In the job below, the STAR index files are located in the shared folder (two levels up). So you need to bind the folder that includes both $PWD and the STAR index folder. That's the reason we specify SIF_BIND=\"/scratch/zt1/project/bioi611/\" . %%bash cd /scratch/zt1/project/bioi611/user/$USER cat ../../shared/scripts/bulkRNA_SE_s2_trim_galore.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH --nodes=1 #SBATCH --ntasks=6 #SBATCH --cpus-per-task=12 #SBATCH --job-name=bulkRNA_SE_s2_trim_galore #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out module load singularity ## Binding path and singularity image file SIF_BIND=\"/scratch/zt1/project/bioi611/\" SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\" ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" FASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\" cd $WORKDIR date singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day1_rep1.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day1_rep2.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day1_rep3.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day7_rep1.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day7_rep2.fastq.gz & singularity exec -B $SIF_BIND $SIF_TRIMGALORE trim_galore --fastqc --cores 4 --output_dir bulk_RNAseq_SE_trim_galore $FASTQ_DIR/N2_day7_rep3.fastq.gz & wait date","title":"Quality control"},{"location":"bulkRNAseq_lab/#read-alignment-using-star","text":"","title":"Read alignment using STAR"},{"location":"bulkRNAseq_lab/#generate-genome-index","text":"During this step, the reference genome (FASTA file) and annotations (GTF files) are supplied. The genome index are saved to disk and only need to be generated once. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_s1_star_idx.sub Here is the content in `bulkRNA_s1_star_idx.sub`: %%bash cd /scratch/zt1/project/bioi611/user/$USER cat ../../shared/scripts/bulkRNA_s1_star_idx.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=2 #SBATCH --job-name=bulkRNA_s1_star_idx #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out PATH=\"/scratch/zt1/project/bioi611/shared/software/STAR_2.7.11b/Linux_x86_64_static/:$PATH\" WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" FASTA=\"/scratch/zt1/project/bioi611/shared/reference/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa\" GTF=\"/scratch/zt1/project/bioi611/shared/reference/Caenorhabditis_elegans.WBcel235.111.gtf\" cd $WORKDIR mkdir STAR_index STAR --runThreadN 2 --runMode genomeGenerate \\ --genomeDir STAR_index \\ --genomeFastaFiles $FASTA \\ --sjdbGTFfile $GTF The genome files will be outputted into STAR_index/ : %%bash cd /scratch/zt1/project/bioi611/user/$USER ls STAR_index/ chrLength.txt chrNameLength.txt chrName.txt chrStart.txt exonGeTrInfo.tab exonInfo.tab geneInfo.tab Genome genomeParameters.txt SA SAindex sjdbInfo.txt sjdbList.fromGTF.out.tab sjdbList.out.tab transcriptInfo.tab Important things to keep in mind: STAR is a splicing aware mapper which is required for RNA-seq read alignment Genome index only need to be built one Make sure the reference file and annotation file match each other. For a particular species, there might be reference genomes built for different strains/ecotypes. Even for the same strain/ecotype, there could be different versions. Human Genome Assemblies, hg19 and hg38 are two different versions of the human genome, which is the complete set of DNA in an individual's cells. Hg19 is the older of the two assemblies and was released in 2002. Hg38 , also known as GRCh38 , is the more recent assembly and was released in 2013. It is a more accurate and detailed version of the human genome and includes additional data that was not available when HG19 was released. After ethe reference genome is built, you can start to align the RNA-seq reads using the command lines below. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s3_STAR_align.sub sbatch ../../shared/scripts/bulkRNA_SE_s4_bam_index.sub %%bash cd /scratch/zt1/project/bioi611/user/$USER cat ../../shared/scripts/bulkRNA_SE_s3_STAR_align.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH --nodes=1 #SBATCH --ntasks=6 #SBATCH --cpus-per-task=10 #SBATCH --job-name=bulkRNA_SE_STAR_align #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out PATH=\"/scratch/zt1/project/bioi611/shared/software/STAR_2.7.11b/Linux_x86_64_static/:$PATH\" INDIR=bulk_RNAseq_SE_trim_galore/ OUTDIR=bulkRNA_SE_STAR_align/ mkdir -p $OUTDIR STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day1_rep1. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day1_rep1_trimmed.fq.gz > $OUTDIR/N2_day1_rep1.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day1_rep2. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day1_rep2_trimmed.fq.gz > $OUTDIR/N2_day1_rep2.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day1_rep3. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day1_rep3_trimmed.fq.gz > $OUTDIR/N2_day1_rep3.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day7_rep1. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day7_rep1_trimmed.fq.gz > $OUTDIR/N2_day7_rep1.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day7_rep2. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day7_rep2_trimmed.fq.gz > $OUTDIR/N2_day7_rep2.log.txt 2>&1 & STAR --genomeDir STAR_index \\ --outSAMtype BAM SortedByCoordinate \\ --twopassMode Basic \\ --quantMode TranscriptomeSAM GeneCounts \\ --readFilesCommand zcat \\ --outFileNamePrefix $OUTDIR/N2_day7_rep3. \\ --runThreadN 10 \\ --readFilesIn $INDIR/N2_day7_rep3_trimmed.fq.gz > $OUTDIR/N2_day7_rep3.log.txt 2>&1 & wait In the STAR command lines, the following parameters are used --genomeDir STAR_index --genomeDir is required. The name of the parameter is self-explanatory. --outSAMtype BAM SortedByCoordinate This parameter is optional. If not specified, 'SAM' will be used: SAM : output SAM without sorting BAM format is the binary format for SAM file. To understand the details of BAM/SAM format, refer to the link here . --twopassMode Basic Wil the parameter above, STAR will perform the 1st pass mapping, then it will automatically extract junctions, insert them into the genome index, and, finally, re-map all reads in the 2nd mapping pass. This option can be used with annotations, which can be included either at the run-time, or at the genome generation step --quantMode TranscriptomeSAM GeneCounts With parameters above, STAR produces both the Aligned.toTranscriptome.out.bam and ReadsPerGene.out.tab outputs --readFilesCommand zcat The parameter specifies the command line ( None , zcat or bzcat ) to execute for each of the input file --outFileNamePrefix $OUTDIR/N2_day7_rep2. : output files name prefix (including full or relative path) --runThreadN 10 : number of threads to run STAR --readFilesIn $INDIR/N2_day7_rep3_trimmed.fq.gz : paths to files that contain input read1 (and, if needed, read2) The step below is optional. After alignment, it is good practice to index the sorted BAM file so that downstream tools (such as IGV, featureCounts, or samtools view) can quickly access specific genomic regions. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s4_bam_index.sub ```bash %%bash cd /scratch/zt1/project/bioi611/user/$USER grep 'samtools' ../../shared/scripts/bulkRNA_SE_s4_bam_index.sub module load samtools samtools index bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day1_rep2.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day1_rep3.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day7_rep1.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day7_rep2.Aligned.sortedByCoord.out.bam & samtools index bulkRNA_SE_STAR_align/N2_day7_rep3.Aligned.sortedByCoord.out.bam & After the job is finished, each BAM file will have a *.bai file generated: %%bash cd /scratch/zt1/project/bioi611/user/$USER ls bulkRNA_SE_STAR_align/*.bai bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day1_rep2.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day1_rep3.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day7_rep1.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day7_rep2.Aligned.sortedByCoord.out.bam.bai bulkRNA_SE_STAR_align/N2_day7_rep3.Aligned.sortedByCoord.out.bam.bai","title":"Generate genome index"},{"location":"bulkRNAseq_lab/#use-multiqc-to-generate-report","text":"MultiQC is a reporting tool that parses results and statistics from bioinformatics tool outputs, such as log files and console outputs. It helps to summarise experiments containing multiple samples and multiple analysis steps. It\u2019s designed to be placed at the end of pipelines or to be run manually when you\u2019ve finished running your tools. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s5_multiqc.sub %%bash cd /scratch/zt1/project/bioi611/user/$USER grep -v 'SBATCH' ../../shared/scripts/bulkRNA_SE_s5_multiqc.sub #!/bin/bash module load singularity ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" cd $WORKDIR singularity exec -B $PWD /scratch/zt1/project/bioi611/shared/software/multiqc_v1.25.sif multiqc -f -o bulk_RNAseq_SE_multiqc ./bulk_RNAseq_SE_fastqc/ bulk_RNAseq_SE_trim_galore/ bulkRNA_SE_STAR_align/ In the command line above, you will again run multiqc in singularity container. This time, -B $PWD is used. $PWD is a dynamic environmental variable that stores the current working directory in which the input and output of multiqc will be store.","title":"Use MultiQC to generate report"},{"location":"bulkRNAseq_lab/#use-rseqc-to-generate-qc-plots","text":"RSeQC package provides a number of useful modules that can comprehensively evaluate RNA-seq data. In this lecture, we are going to use one of the modules geneBody_coverage.py . This module is used to check if read coverage is uniform and if there is any 5'/3' bias. This module scales all transcripts to 100 nt and calculates the number of reads covering each nucleotide position. Finally, it generates plots illustrating the coverage profile along the gene body. %%bash cd /scratch/zt1/project/bioi611/user/$USER sbatch ../../shared/scripts/bulkRNA_SE_s6_RSeQC_genebody_cov.sub %%bash cd /scratch/zt1/project/bioi611/user/$USER cat ../../shared/scripts/bulkRNA_SE_s6_RSeQC_genebody_cov.sub #!/bin/bash #SBATCH --partition=standard #SBATCH -t 40:00:00 #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --job-name=bulkRNA_SE_s6_RSeQC_genebody_cov.sub #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out module load singularity ## Binding path and singularity image file SIF_BIND=\"/scratch/zt1/project/bioi611/\" SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/rseqc_v5.0.3.sif\" SIF_BEDOPS=\"/scratch/zt1/project/bioi611/shared/software/bedops_v2.4.39.sif\" ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" cd $WORKDIR mkdir -p bulk_RNAseq_SE_RSeQC/ singularity exec -B $SIF_BIND $SIF_TRIMGALORE geneBody_coverage.py -r /scratch/zt1/project/bioi611/shared/reference/Caenorhabditis_elegans.WBcel235.111.bed -i bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam,bulkRNA_SE_STAR_align/N2_day7_rep1.Aligned.sortedByCoord.out.bam -o bulk_RNAseq_SE_RSeQC/geneBody_cov # Test command line which can be completed in less than 2 minutes # singularity exec -B $SIF_BIND $SIF_TRIMGALORE geneBody_coverage.py -r test_1000genes.bed -i bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam -o test_genebody_cov/test After the job above is completed, one of the output file is a PDF file. As you can see, in the two samples checked, the coverage over the gene body is quite uniform. Caenorhabditis_elegans.WBcel235.111.bed is used as one of the input for geneBody_coverage.py in RSeQC. To understand the bed file format, please refer to the link below: https://genome.ucsc.edu/FAQ/FAQformat.html#format1 The bed file can be genreated using GFF3 file. GFF3 format is a similar format as GTF. To generate bed file from GFF3 file, you can use the command line below: wget https://ftp.ensembl.org/pub/release-111/gff3/caenorhabditis_elegans/Caenorhabditis_elegans.WBcel235.111.gff3.gz export PATH=\"/scratch/zt1/project/bioi611/shared/software:$PATH\" gff3ToGenePred Caenorhabditis_elegans.WBcel235.111.gff3 Caenorhabditis_elegans.WBcel235.111.phred genePredToBed Caenorhabditis_elegans.WBcel235.111.phred Caenorhabditis_elegans.WBcel235.111.bed","title":"Use RSeQC to generate QC plots"},{"location":"bulkRNAseq_lab/#advanced-topcis","text":"","title":"Advanced topcis"},{"location":"bulkRNAseq_lab/#bind-paths-and-mounts-in-sigularity","text":"Singularity allows you to map directories on your host system to directories within your container using bind mounts. This allows you to read and write data on the host system with ease. The system administrator has the ability to define what bind paths will be included automatically inside each container. Some bind paths are automatically derived (e.g. a user\u2019s home directory) and some are statically defined (e.g. bind paths in the Singularity configuration file). In the default configuration, the directories $HOME , /tmp , /proc , /sys , /dev , and $PWD are among the system-defined bind paths. On UMD HPC, $PWD is not defined. So you have to mount the path via the command line parameter -B/--bind . You can go into the singlarity container just as you are working in a linux system. %%bash module load singularity SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\" singularity exec $SIF_TRIMGALORE /bin/bash You will be in the container after you run the command lines above. You can then run the Linux commands you leart from previous classes. To exit the container, simply press ctrl+d on your keyborad. Running the commands below, you run ls $FASTQ_DIR inside the container to list the fastq files. %%bash module load singularity ## Binding path and singularity image file SIF_BIND=\"/scratch/zt1/project/bioi611/\" SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\" ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" FASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\" cd $WORKDIR singularity exec -B $SIF_BIND $SIF_TRIMGALORE ls $FASTQ_DIR N2_day1_rep1.fastq.gz N2_day1_rep2.fastq.gz N2_day1_rep3.fastq.gz N2_day7_rep1.fastq.gz N2_day7_rep2.fastq.gz N2_day7_rep3.fastq.gz Running the commands below, the command lines will fail because $WORKDIR is not mounted. %%bash module load singularity ## Binding path and singularity image file SIF_BIND=\"/scratch/zt1/project/bioi611/\" SIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\" ## Paths to working directory and input fastq files WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" FASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\" cd $WORKDIR singularity exec $SIF_TRIMGALORE ls $WORKDIR ls: /scratch/zt1/project/bioi611/user/xie186: No such file or directory --------------------------------------------------------------------------- CalledProcessError Traceback (most recent call last) Cell In[20], line 1 ----> 1 get_ipython().run_cell_magic('bash', '', 'module load singularity\\n## Binding path and singularity image file \\nSIF_BIND=\"/scratch/zt1/project/bioi611/\"\\nSIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\"\\n## Paths to working directory and input fastq files\\nWORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\"\\nFASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\"\\ncd $WORKDIR \\nsingularity exec $SIF_TRIMGALORE ls $WORKDIR\\n') File /cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/mpi-nocuda/linux-rhel8-zen2/gcc/11.3.0/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2430, in InteractiveShell.run_cell_magic(self, magic_name, line, cell) 2428 with self.builtin_trap: 2429 args = (magic_arg_s, cell) -> 2430 result = fn(*args, **kwargs) 2432 # The code below prevents the output from being displayed 2433 # when using magics with decodator @output_can_be_silenced 2434 # when the last Python token in the expression is a ';'. 2435 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False): File /cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/mpi-nocuda/linux-rhel8-zen2/gcc/11.3.0/lib/python3.10/site-packages/IPython/core/magics/script.py:153, in ScriptMagics._make_script_magic.<locals>.named_script_magic(line, cell) 151 else: 152 line = script --> 153 return self.shebang(line, cell) File /cvmfs/hpcsw.umd.edu/spack-software/2023.11.20/views/2023/linux-rhel8-zen2/gcc@11.3.0/python-3.10.10/mpi-nocuda/linux-rhel8-zen2/gcc/11.3.0/lib/python3.10/site-packages/IPython/core/magics/script.py:305, in ScriptMagics.shebang(self, line, cell) 300 if args.raise_error and p.returncode != 0: 301 # If we get here and p.returncode is still None, we must have 302 # killed it but not yet seen its return code. We don't wait for it, 303 # in case it's stuck in uninterruptible sleep. -9 = SIGKILL 304 rc = p.returncode or -9 --> 305 raise CalledProcessError(rc, cell) CalledProcessError: Command 'b'module load singularity\\n## Binding path and singularity image file \\nSIF_BIND=\"/scratch/zt1/project/bioi611/\"\\nSIF_TRIMGALORE=\"/scratch/zt1/project/bioi611/shared/software/trimgalore_v0.6.10.sif\"\\n## Paths to working directory and input fastq files\\nWORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\"\\nFASTQ_DIR=\"/scratch/zt1/project/bioi611/shared/raw_data/bulk_RNAseq_SE/\"\\ncd $WORKDIR \\nsingularity exec $SIF_TRIMGALORE ls $WORKDIR\\n'' returned non-zero exit status 1.","title":"Bind paths and mounts in sigularity"},{"location":"bulkRNAseq_lab/#use-samtools-to-display-the-content-of-bam-files","text":"Samtools is a powerful tool that can be used to display and manipulate SAM/BAM files. The command lines below shows you how to use samtools view to display the content: the headers and the alignments. %%bash module load samtools WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" samtools view -H $WORKDIR/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam @HD VN:1.4 SO:coordinate @SQ SN:I LN:15072434 @SQ SN:II LN:15279421 @SQ SN:III LN:13783801 @SQ SN:IV LN:17493829 @SQ SN:V LN:20924180 @SQ SN:X LN:17718942 @SQ SN:MtDNA LN:13794 @PG ID:STAR PN:STAR VN:2.7.11b CL:STAR --runThreadN 10 --genomeDir STAR_index --readFilesIn bulk_RNAseq_SE_trim_galore//N2_day1_rep1_trimmed.fq.gz --readFilesCommand zcat --outFileNamePrefix bulkRNA_SE_STAR_align//N2_day1_rep1. --outSAMtype BAM SortedByCoordinate --quantMode TranscriptomeSAM GeneCounts --twopassMode Basic @PG ID:samtools PN:samtools PP:STAR VN:1.17 CL:samtools view -H /scratch/zt1/project/bioi611/user/xie186/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam @CO user command line: STAR --genomeDir STAR_index --outSAMtype BAM SortedByCoordinate --twopassMode Basic --quantMode TranscriptomeSAM GeneCounts --readFilesCommand zcat --outFileNamePrefix bulkRNA_SE_STAR_align//N2_day1_rep1. --runThreadN 10 --readFilesIn bulk_RNAseq_SE_trim_galore//N2_day1_rep1_trimmed.fq.gz %%bash module load samtools WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" samtools view -h $WORKDIR/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam |head -14 @HD VN:1.4 SO:coordinate @SQ SN:I LN:15072434 @SQ SN:II LN:15279421 @SQ SN:III LN:13783801 @SQ SN:IV LN:17493829 @SQ SN:V LN:20924180 @SQ SN:X LN:17718942 @SQ SN:MtDNA LN:13794 @PG ID:STAR PN:STAR VN:2.7.11b CL:STAR --runThreadN 10 --genomeDir STAR_index --readFilesIn bulk_RNAseq_SE_trim_galore//N2_day1_rep1_trimmed.fq.gz --readFilesCommand zcat --outFileNamePrefix bulkRNA_SE_STAR_align//N2_day1_rep1. --outSAMtype BAM SortedByCoordinate --quantMode TranscriptomeSAM GeneCounts --twopassMode Basic @PG ID:samtools PN:samtools PP:STAR VN:1.17 CL:samtools view -h /scratch/zt1/project/bioi611/user/xie186/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam @CO user command line: STAR --genomeDir STAR_index --outSAMtype BAM SortedByCoordinate --twopassMode Basic --quantMode TranscriptomeSAM GeneCounts --readFilesCommand zcat --outFileNamePrefix bulkRNA_SE_STAR_align//N2_day1_rep1. --runThreadN 10 --readFilesIn bulk_RNAseq_SE_trim_galore//N2_day1_rep1_trimmed.fq.gz SRR15694099.8922190 256 I 2366 0 96M * 0 0 TGAAAATTTTGTGATTTTCGTAAATTTATTCCTATTTATTAATAAAAACAAAAACAATTCCATTAAATATCCCATTTTCAGCGCAAAATCGACTGG CCCFFFFFHHHHHJJJJJJJIJJJJJJJJJJJJJJJIJJJJJJJIJJIIIIJJJJJJJJJJJJJJJJJJJIJJJJIIJJHHGHFFDDDDCDDDDD@ NH:i:8 HI:i:8 AS:i:94 nM:i:0 SRR15694099.16768635 16 I 2481 1 95M * 0 0 GAGATAGAACGGATCAACAAGATTATTATTATATCATTAATAATATTTATCAATTTTCTTCTGAGAGTCTCATTGAGACTCTTATTTACGCCAAG ;>@EEAB@;B;EAA6.=7==>GEAGAGEGHF>F=FCHEFDBGBFD<D9GBBBBBB;;D?BF@DFEGDHFEIIIHEGIIFFDHFBFDD<DDDA@@@ NH:i:4 HI:i:1 AS:i:93 nM:i:0 SRR15694099.10859917 0 I 2602 255 71M * 0 0 ATTTTTGAAAAAAAAATAATTAAAAAAACACATTTTTTGGAAAAAAAAATAAATAAAAAAAATTGTCCTCG ?@@DDEDB?HHBDHGIIIGIIGCBBGEHAF?GIHIIIGGFBCCEBB@BBBCCCEECCCCBBBBCCC@CCC@ NH:i:1 HI:i:1 AS:i:69 nM:i:0 %%bash module load samtools WORKDIR=\"/scratch/zt1/project/bioi611/user/$USER\" samtools view $WORKDIR/bulkRNA_SE_STAR_align/N2_day1_rep1.Aligned.sortedByCoord.out.bam |head -4 SRR15694099.8922190 256 I 2366 0 96M * 0 0 TGAAAATTTTGTGATTTTCGTAAATTTATTCCTATTTATTAATAAAAACAAAAACAATTCCATTAAATATCCCATTTTCAGCGCAAAATCGACTGG CCCFFFFFHHHHHJJJJJJJIJJJJJJJJJJJJJJJIJJJJJJJIJJIIIIJJJJJJJJJJJJJJJJJJJIJJJJIIJJHHGHFFDDDDCDDDDD@ NH:i:8 HI:i:8 AS:i:94 nM:i:0 SRR15694099.16768635 16 I 2481 1 95M * 0 0 GAGATAGAACGGATCAACAAGATTATTATTATATCATTAATAATATTTATCAATTTTCTTCTGAGAGTCTCATTGAGACTCTTATTTACGCCAAG ;>@EEAB@;B;EAA6.=7==>GEAGAGEGHF>F=FCHEFDBGBFD<D9GBBBBBB;;D?BF@DFEGDHFEIIIHEGIIFFDHFBFDD<DDDA@@@ NH:i:4 HI:i:1 AS:i:93 nM:i:0 SRR15694099.10859917 0 I 2602 255 71M * 0 0 ATTTTTGAAAAAAAAATAATTAAAAAAACACATTTTTTGGAAAAAAAAATAAATAAAAAAAATTGTCCTCG ?@@DDEDB?HHBDHGIIIGIIGCBBGEHAF?GIHIIIGGFBCCEBB@BBBCCCEECCCCBBBBCCC@CCC@ NH:i:1 HI:i:1 AS:i:69 nM:i:0 SRR15694099.30104406 16 I 2611 255 40M1I55M * 0 0 AAAAAAATAATTAAAAAAACACATTTTTTGGAAAAAAAAAATAAATAAAAAAAATTGTCCTCGAGGATCCTCCGGAGCGCGTCGAATCAATGTTTC BBDDAB>>A>48BBDCCC@4((<5AA>4(43BDDDDDDACC@CCA?DBACDB?BHE=;EA;<EFB=81@F:BGHGBBA8BFBGBHHHBFFEDD?@@ NH:i:1 HI:i:1 AS:i:89 nM:i:0","title":"Use samtools to display the content of BAM files"},{"location":"general-questions/","text":"To be added","title":"To be added"},{"location":"general-questions/#to-be-added","text":"","title":"To be added"},{"location":"license/","text":"To be added","title":"To be added"},{"location":"license/#to-be-added","text":"","title":"To be added"},{"location":"notes/","text":"SRR15675112 Neuron_D8_rep1 SRR15675111 Neuron_D8_rep2 SRR15675110 Neuron_D8_rep3 SRR15675135 Neuron D1 rep1 SRR15675134 Neuron D1 rep2 SRR15675123 Neuron D1 rep3 find . -type d -or -type f -exec touch {} + perl -ne 'chomp;($SRR, $name) = split(\"\\t\");$R1 = \"$SRR\".\"_1.fastq.gz\"; $R2 = \"$SRR\".\"_2.fastq.gz\"; print \"#$SRR\\t$ name\\nmv $R1 $name\".\"_1.fastq.gz\\nmv $R2 $name\".\"_2.fastq.gz\\n\"' test.txt","title":"Notes"},{"location":"ref/","text":"","title":"Ref"},{"location":"troubleshooting/","text":"To be added","title":"To be added"},{"location":"troubleshooting/#to-be-added","text":"","title":"To be added"}]}